{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kunal/Documents/speech project/improveai/env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyC0O4dCvtLxrXg3BMBciSzrXhO3Vkb5Irw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "UPLOAD_FOLDER = 'uploads'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile = genai.upload_file(UPLOAD_FOLDER + \"recorded_audio.mp3\")\n",
    "    \n",
    "# print(f\"{myfile=}\")\n",
    "\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "result = model.generate_content([myfile, \"Transcribthis audio clip, provide only plain text response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello I am Kunal what are you doing there \\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsond=[\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"parts\": [\n",
    "            \"You are the interviewers conducting an interview for a fresher backend developer position. Create three professional interviewers with distinct roles relevant to the interview. Initialize the interview by introducing the interviewers, and proceed with the questions in a conversational and realistic manner. Start with an introduction of all interviewers for example-  [\\n{\\n  \\\"interviewer_name\\\": \\\"Rajesh Sharma, Engineering Manager\\\",\\n  \\\"message\\\": \\\"Hello everyone, I'm Rajesh Sharma, the Engineering Manager for the backend team. I'll be leading this interview today.\\\",\\n  \\\"id\\\":0\\n\\n},\\n{\\n  \\\"interviewer_name\\\": \\\"Emily Patel, Senior Backend Developer\\\",\\n  \\\"message\\\": \\\"Hi, I'm Emily Patel, a Senior Backend Developer on the team. I'll be evaluating your technical skills and experience.\\\",\\n  \\\"id\\\":1\\n},\\n{\\n  \\\"interviewer_name\\\": \\\"David Lee, Technical Recruiter\\\",\\n  \\\"message\\\": \\\"Hello, I'm David Lee, the Technical Recruiter who worked with you to schedule this interview. I'll be taking notes and ensuring the process runs smoothly. Are You comfortable with the interview?\\\",\\n  \\\"id\\\":2\\n},\\n]\\n\\n\\n\\nProvide the output in the following JSON format\\n\\ngive output like - output={\\\"interviewer_name\\\": \\\"Rajesh Sharma, Engineering Manager\\\",\\\"message\\\": \\\"Hello\\\",\\\"id\\\":0}\\n\\nif want to pass the conversation to another interviewer also include the reply of the another interviewer\\n\\ntailor is for user preference - {'role': 'Software Developer', 'field': 'Python,JS', 'experience': '0-1', 'scenario': 'interview', 'purpose': 'Job', 'toimprove': ['technical', 'communication']}\"\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "jsond.append({\n",
    "        \"role\": \"bot\",\n",
    "        \"message\": \"response\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'parts': ['You are the interviewers conducting an interview for a fresher backend developer position. Create three professional interviewers with distinct roles relevant to the interview. Initialize the interview by introducing the interviewers, and proceed with the questions in a conversational and realistic manner. Start with an introduction of all interviewers for example-  [\\n{\\n  \"interviewer_name\": \"Rajesh Sharma, Engineering Manager\",\\n  \"message\": \"Hello everyone, I\\'m Rajesh Sharma, the Engineering Manager for the backend team. I\\'ll be leading this interview today.\",\\n  \"id\":0\\n\\n},\\n{\\n  \"interviewer_name\": \"Emily Patel, Senior Backend Developer\",\\n  \"message\": \"Hi, I\\'m Emily Patel, a Senior Backend Developer on the team. I\\'ll be evaluating your technical skills and experience.\",\\n  \"id\":1\\n},\\n{\\n  \"interviewer_name\": \"David Lee, Technical Recruiter\",\\n  \"message\": \"Hello, I\\'m David Lee, the Technical Recruiter who worked with you to schedule this interview. I\\'ll be taking notes and ensuring the process runs smoothly. Are You comfortable with the interview?\",\\n  \"id\":2\\n},\\n]\\n\\n\\n\\nProvide the output in the following JSON format\\n\\ngive output like - output={\"interviewer_name\": \"Rajesh Sharma, Engineering Manager\",\"message\": \"Hello\",\"id\":0}\\n\\nif want to pass the conversation to another interviewer also include the reply of the another interviewer\\n\\ntailor is for user preference - {\\'role\\': \\'Software Developer\\', \\'field\\': \\'Python,JS\\', \\'experience\\': \\'0-1\\', \\'scenario\\': \\'interview\\', \\'purpose\\': \\'Job\\', \\'toimprove\\': [\\'technical\\', \\'communication\\']}']},\n",
       " {'role': 'bot', 'message': 'response'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "HISTORY_FILE_PATH = 'session_data.json'\n",
    "import os,json\n",
    "def load_history():\n",
    "    \"\"\"Load conversation history from a JSON file.\"\"\"\n",
    "    if os.path.exists(HISTORY_FILE_PATH):\n",
    "        with open(HISTORY_FILE_PATH, 'r') as f:\n",
    "            return json.load(f)\n",
    "    return []  # Ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'message': ['You are the interviewers conducting an interview for a fresher backend developer position. Create three professional interviewers with distinct roles relevant to the interview. Initialize the interview by introducing the interviewers, and proceed with the questions in a conversational and realistic manner. Start with an introduction of all interviewers for example-  [\\n{\\n  \"interviewer_name\": \"Rajesh Sharma, Engineering Manager\",\\n  \"message\": \"Hello everyone, I\\'m Rajesh Sharma, the Engineering Manager for the backend team. I\\'ll be leading this interview today.\",\\n  \"id\":0\\n\\n},\\n{\\n  \"interviewer_name\": \"Emily Patel, Senior Backend Developer\",\\n  \"message\": \"Hi, I\\'m Emily Patel, a Senior Backend Developer on the team. I\\'ll be evaluating your technical skills and experience.\",\\n  \"id\":1\\n},\\n{\\n  \"interviewer_name\": \"David Lee, Technical Recruiter\",\\n  \"message\": \"Hello, I\\'m David Lee, the Technical Recruiter who worked with you to schedule this interview. I\\'ll be taking notes and ensuring the process runs smoothly. Are You comfortable with the interview?\",\\n  \"id\":2\\n},\\n]\\n\\n\\n\\nProvide the output in the following JSON format\\n\\ngive output like - output={\"interviewer_name\": \"Rajesh Sharma, Engineering Manager\",\"message\": \"Hello\",\"id\":0}\\n\\nif want to pass the conversation to another interviewer also include the reply of the another interviewer\\n\\ntailor is for user preference - {\\'role\\': \\'Software Developer\\', \\'field\\': \\'Python\\', \\'experience\\': \\'0-1\\', \\'scenario\\': \\'interview\\', \\'purpose\\': \\'Job\\', \\'toimprove\\': [\\'technical\\', \\'communication\\']}']},\n",
       " {'role': 'user', 'message': 'Hello'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h=load_history()\n",
    "type(h)\n",
    "h.append({\n",
    "    \"role\": \"user\",\n",
    "    \"message\": \"Hello\"\n",
    "})\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'interviewer_name': 'Rajesh Sharma, Engineering Manager',\n",
       "  'message': \"Hello everyone, I'm Rajesh Sharma, the Engineering Manager for the backend team. I'll be leading this interview today.\",\n",
       "  'id': 0},\n",
       " {'interviewer_name': 'Emily Patel, Senior Backend Developer',\n",
       "  'message': \"Hi, I'm Emily Patel, a Senior Backend Developer on the team. I'll be evaluating your technical skills and experience.\",\n",
       "  'id': 1},\n",
       " {'interviewer_name': 'David Lee, Technical Recruiter',\n",
       "  'message': \"Hello, I'm David Lee, the Technical Recruiter who worked with you to schedule this interview. I'll be taking notes and ensuring the process runs smoothly. Are you comfortable with the interview?\",\n",
       "  'id': 2}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d=\"[{\\\"interviewer_name\\\": \\\"Rajesh Sharma, Engineering Manager\\\", \\\"message\\\": \\\"Hello everyone, I'm Rajesh Sharma, the Engineering Manager for the backend team. I'll be leading this interview today.\\\", \\\"id\\\": 0}, {\\\"interviewer_name\\\": \\\"Emily Patel, Senior Backend Developer\\\", \\\"message\\\": \\\"Hi, I'm Emily Patel, a Senior Backend Developer on the team. I'll be evaluating your technical skills and experience.\\\", \\\"id\\\": 1}, {\\\"interviewer_name\\\": \\\"David Lee, Technical Recruiter\\\", \\\"message\\\": \\\"Hello, I'm David Lee, the Technical Recruiter who worked with you to schedule this interview. I'll be taking notes and ensuring the process runs smoothly. Are you comfortable with the interview?\\\", \\\"id\\\": 2}]\\n\"\n",
    "json_data = json.loads(d)\n",
    "json_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import edge_tts\n",
    "import asyncio\n",
    "\n",
    "async def text_to_speech(text, output_file, voice):\n",
    "    \"\"\"Converts text to speech using edge-tts and saves the audio as an MP3 file.\"\"\"\n",
    "    \n",
    "    # Initialize the TTS service with the provided voice\n",
    "    communicate = edge_tts.Communicate(text, voice)\n",
    "    \n",
    "    # Convert the text to speech and save it to the output file\n",
    "    await communicate.save(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def speakers():\n",
    "    reply_list=[]\n",
    "    for interviewer in json_data:\n",
    "\n",
    "        text=interviewer['message']\n",
    "        id=interviewer['id']\n",
    "        if id==0:\n",
    "            output_file=\"AUDIOS/0.mp3\"\n",
    "            await text_to_speech(text, output_file,voice=\"en-US-BrianNeural\")\n",
    "            reply_list.append(output_file)\n",
    "            \n",
    "\n",
    "        if id==1:\n",
    "            output_file=\"AUDIOS/1.mp3\"\n",
    "            await text_to_speech(text, output_file,voice=\"en-IN-NeerjaExpressiveNeural\")\n",
    "            reply_list.append(output_file)\n",
    "\n",
    "        if id==2:\n",
    "            output_file=\"AUDIOS/2.mp3\"\n",
    "            await text_to_speech(text, output_file,voice=\"en-US-ChristopherNeural\")\n",
    "            reply_list.append(output_file)\n",
    "    return reply_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AUDIOS/0.mp3', 'AUDIOS/1.mp3', 'AUDIOS/2.mp3']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "reply_list = await speakers()\n",
    "print(reply_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "text_to_speech() missing 1 required positional argument: 'voice'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;66;03m# If there's already an event loop running (e.g., in a Jupyter notebook)\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m main()\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m:\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;66;03m# Fallback for environments where asyncio.run() would work (non-notebook)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m         asyncio\u001b[38;5;241m.\u001b[39mrun(main())\n",
      "Cell \u001b[0;32mIn[59], line 10\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m output_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/AUDIOS/output_speech.mp3\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Run the asynchronous text-to-speech task\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[43mtext_to_speech\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: text_to_speech() missing 1 required positional argument: 'voice'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Main function to run the TTS asynchronously\n",
    "async def main():\n",
    "    # Text that you want to convert to speech\n",
    "    text = \"Take your content creation to the next level with our cutting-edge Text-to-Video Converter! Transform your words into stunning, professional-quality videos in just a few clicks.\"\n",
    "    \n",
    "    # Output file path (e.g., an MP3 file)\n",
    "    output_file = \"/AUDIOS/output_speech.mp3\"\n",
    "    \n",
    "    # Run the asynchronous text-to-speech task\n",
    "    await text_to_speech(text, output_file)\n",
    "\n",
    "# Check if running in an event loop\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # If there's already an event loop running (e.g., in a Jupyter notebook)\n",
    "        await main()\n",
    "    except RuntimeError:\n",
    "        # Fallback for environments where asyncio.run() would work (non-notebook)\n",
    "        asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<coroutine object main at 0x7bf9803979f0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "a={'interviewer_name': 'Rajesh Sharma, Engineering Manager', 'message': \"Great! Let's get started.  Since you have 1-2 years of experience, we'd like to understand your experience with Python. Can you tell us about a recent project where you used Python for backend development?\", 'id': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n"
     ]
    }
   ],
   "source": [
    "if type(a) is list:\n",
    "    print(\"yes\")\n",
    "if type(a) is dict:\n",
    "    print(\"no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tmp/hello.txt\", \"w\") as file:\n",
    "    # Write \"Hello\" to the file\n",
    "    file.write(\"Hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hello its v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import threading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "list1=[]\n",
    "\n",
    "def run1(s,e):\n",
    "    for i in range(s,e):\n",
    "        list1.append(i)   \n",
    "\n",
    "        print(i)\n",
    "\n",
    "\n",
    "thread = threading.Thread(target=run1, args=(0,10,))\n",
    "thread.start()\n",
    "\n",
    "thread = threading.Thread(target=run1, args=(10,20,))\n",
    "thread.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedWriter name='recording.wav'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_file = open(\"recording.wav\", \"wb\")\n",
    "audio_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not '_io.BufferedWriter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m audio_np \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrombuffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint16\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: a bytes-like object is required, not '_io.BufferedWriter'"
     ]
    }
   ],
   "source": [
    "audio_np = np.frombuffer(audio_file, dtype=np.int16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faker\n",
      "  Downloading Faker-33.1.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.4 in /home/kunal/Documents/speech project/improveai/env/lib/python3.12/site-packages (from faker) (2.9.0.post0)\n",
      "Requirement already satisfied: typing-extensions in /home/kunal/Documents/speech project/improveai/env/lib/python3.12/site-packages (from faker) (4.12.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/kunal/Documents/speech project/improveai/env/lib/python3.12/site-packages (from python-dateutil>=2.4->faker) (1.16.0)\n",
      "Downloading Faker-33.1.0-py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hInstalling collected packages: faker\n",
      "Successfully installed faker-33.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random number: 5539599\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Generate a random number between 1 and 10 (inclusive)\n",
    "random_number = random.randint(1, 9999999)\n",
    "\n",
    "print(\"Random number:\", random_number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.mp3', '1.mp3', '2.mp3']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# List contents of the current directory\n",
    "path = \"AUDIOS/\"\n",
    "\n",
    "contents = os.listdir(path)\n",
    "contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del arr[:3]\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyaudio\n",
      "  Using cached PyAudio-0.2.14-cp312-cp312-linux_x86_64.whl\n",
      "Installing collected packages: pyaudio\n",
      "Successfully installed pyaudio-0.2.14\n"
     ]
    }
   ],
   "source": [
    "!pip install pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib pcm_dsnoop.c:567:(snd_pcm_dsnoop_open) unable to open slave\n",
      "ALSA lib pcm_dmix.c:1000:(snd_pcm_dmix_open) unable to open slave\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "Cannot connect to server socket err = No such file or directory\n",
      "Cannot connect to server request channel\n",
      "jack server is not running or cannot be started\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
      "Cannot connect to server socket err = No such file or directory\n",
      "Cannot connect to server request channel\n",
      "jack server is not running or cannot be started\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib pcm_a52.c:1001:(_snd_pcm_a52_open) a52 is only for playback\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "ALSA lib pcm_dmix.c:1000:(snd_pcm_dmix_open) unable to open slave\n",
      "Cannot connect to server socket err = No such file or directory\n",
      "Cannot connect to server request channel\n",
      "jack server is not running or cannot be started\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m . . . . . .\u001b[0m\n",
      "\n",
      "\u001b[92m\u001b[0m\n",
      "\n",
      "\u001b[92m\u001b[0m\n",
      "\n",
      "\u001b[92m\u001b[0m\n",
      "\n",
      "\u001b[92m\u001b[0m\n",
      "\n",
      "\u001b[92m\u001b[0m\n",
      "\n",
      "\u001b[92m\u001b[0m\n",
      "\n",
      "\u001b[92m\u001b[0m\n",
      "\n",
      "\u001b[92m\u001b[0m\n",
      "\n",
      "Stopping...\n",
      "LOG: . . . . . .         \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import wave\n",
    "import pyaudio\n",
    "from faster_whisper import WhisperModel\n",
    "\n",
    "# Define colors for terminal output\n",
    "NEON_GREEN = \"\\033[92m\"\n",
    "RESET_COLOR = \"\\033[0m\"\n",
    "\n",
    "def record_chunk(p, stream, file_path, chunk_length=1):\n",
    "    \"\"\"\n",
    "    Records a chunk of audio and saves it to the specified file.\n",
    "\n",
    "    :param p: PyAudio object\n",
    "    :param stream: PyAudio stream object\n",
    "    :param file_path: Path to save the recorded audio\n",
    "    :param chunk_length: Length of the audio chunk in seconds\n",
    "    \"\"\"\n",
    "    frames = []\n",
    "    for _ in range(0, int(16000 / 1024 * chunk_length)):\n",
    "        data = stream.read(1024)\n",
    "        frames.append(data)\n",
    "\n",
    "    wf = wave.open(file_path, 'wb')\n",
    "    wf.setnchannels(1)\n",
    "    wf.setsampwidth(p.get_sample_size(pyaudio.paInt16))\n",
    "    wf.setframerate(16000)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "\n",
    "def transcribe_chunk(model, file_path):\n",
    "    \"\"\"\n",
    "    Transcribes the given audio file using the Whisper model.\n",
    "\n",
    "    :param model: WhisperModel object\n",
    "    :param file_path: Path to the audio file to transcribe\n",
    "    :return: Transcription of the audio file\n",
    "    \"\"\"\n",
    "    segments, _ = model.transcribe(file_path)\n",
    "    return ''.join(segment.text for segment in segments)\n",
    "\n",
    "def main2():\n",
    "    \"\"\"\n",
    "    Main function to record audio in chunks, transcribe it, and accumulate the transcription.\n",
    "    \"\"\"\n",
    "    model_size = \"base.en\"\n",
    "    model = WhisperModel(model_size,  compute_type=\"float32\")\n",
    "\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=pyaudio.paInt16, channels=1, rate=16000, input=True, frames_per_buffer=1024)\n",
    "\n",
    "    accumulated_transcription = \"\"  # Initialize an empty string to accumulate transcriptions\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            chunk_file = \"temp_chunk.wav\"\n",
    "            record_chunk(p, stream, chunk_file)\n",
    "            transcription = transcribe_chunk(model, chunk_file)\n",
    "\n",
    "            print(NEON_GREEN + transcription + RESET_COLOR)\n",
    "            print()\n",
    "            os.remove(chunk_file)\n",
    "\n",
    "            # Append the new transcription to the accumulated transcription\n",
    "            accumulated_transcription += transcription + \" \"\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Stopping...\")\n",
    "\n",
    "        # Write the accumulated transcription to the log file\n",
    "        with open(\"log.txt\", \"w\") as log_file:\n",
    "            log_file.write(accumulated_transcription)\n",
    "\n",
    "    finally:\n",
    "        print(\"LOG:\" + accumulated_transcription)\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "        p.terminate()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main2()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "a=1\n",
    "def add():\n",
    "    global a\n",
    "    a+=1\n",
    "\n",
    "add()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "add()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import edge_tts\n",
    "import asyncio\n",
    "\n",
    "async def text_to_speech(text, output_file, voice):\n",
    "    \"\"\"Converts text to speech using edge-tts and saves the audio as an MP3 file.\"\"\"\n",
    "    \n",
    "    # Initialize the TTS service with the provided voice\n",
    "    communicate = edge_tts.Communicate(text, voice)\n",
    "    \n",
    "    # Convert the text to speech and save it to the output file\n",
    "    await communicate.save(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"We inform you that you've been selected to be one of the talent pool candidates for Artificial Intelligence / Machine Learning, Full stack development, Back end development specialties. New international internship openings will be regularly shared in our private WhatsApp group, and you will have a chance to participate in the interview for 2 months, non-paid, remote, full-time internship conducted by one of the Callus's partner international companies. If you prove yourself to be valuable to the company, you will have a chance to secure a full-time remote paid position at the company at the end of the 2-months internship, with the starting median salary ranging from 50K INR to 100K INR / month.This email is a formal invitation for you to join the selected members-only private WhatsApp group. Stay tuned for the new internship postings.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "await text_to_speech(text=text,output_file=\"1111.mp3\",voice=\"en-US-BrianNeural\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"Artificial Intelligence is the intelligence possessed by the machines under which they can perform various functions with human help. With the help of A.I, machines will be able to learn, solve problems, plan things, think, etc. Artificial Intelligence, for example, is the simulation of human intelligence by machines. In the field of technology, Artificial Intelligence is evolving rapidly day by day and it is believed that in the near future, artificial intelligence is going to change human life very drastically and will most probably end all the crises of the world by sorting out the major problems. Our life in this modern age depends largely on computers. It is almost impossible to think about life without computers. We need computers in everything that we use in our daily lives. So it becomes very important  \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"http://known-smooth-cobra.ngrok-free.app/text-to-speech\"\n",
    "data = {\n",
    "    \"text\": text,\n",
    "    \"voice\": \"en-US-JennyNeural\",\n",
    "    \"output_file\": \"hello.mp3\"\n",
    "}\n",
    "response = requests.post(url, json=data)\n",
    "\n",
    "# Save the returned file\n",
    "with open(\"hello.mp3\", \"wb\") as f:\n",
    "    f.write(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qwertyuiop\n",
      "asdfghjkl\n",
      "zxcvbnm\n"
     ]
    }
   ],
   "source": [
    "keyboard=[\"qwertyuiop\",\"asdfghjkl\",\"zxcvbnm\"]\n",
    "\n",
    "        # for word in words:\n",
    "        #     if ch in lower(word)\n",
    "temp=[]\n",
    "for row in keyboard:\n",
    "    # for word in words:\n",
    "    #     for ch in words:\n",
    "    #         if ch in row[0]:\n",
    "    #             print(ch)\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How's it going? Is there something I can help you with or would you like to chat?\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from together import Together\n",
    "\n",
    "client = Together(api_key=\"0fcde4cd2a6f9e2f7e160b3fe07f4cab323ff83554a0049083578205d4e78cfb\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"meta-llama/Llama-Vision-Free\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"hi\"}],\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"llama-3.2-11b-vision-preview\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \n",
    "            \"content\": \"hi\"\n",
    "        },\n",
    "        \n",
    "    ],\n",
    "           \n",
    "    temperature=1,\n",
    "    max_tokens=1024,\n",
    "    top_p=1,\n",
    "    stream=False,\n",
    "    stop=None,\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Artificial intelligence is the intelligence possessed by the machines under which they can perform various functions with human help. With the help of A.I, machines will be able to learn, solve problems, plan things, think, etc. Artificial intelligence, for example, is the simulation of human intelligence by machines. In the field of technology, artificial intelligence is evolving rapidly day by day and it is believed that in the near future, artificial intelligence is going to change human life very drastically and will most probably end all the crises of the world by sorting out the major problems. Our life in this modern age depends largely on computers. It is almost impossible to think about life without computers. We need computers in everything that we use in our daily lives. So it becomes very important.\n"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "\n",
    "client = Groq(api_key=\"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\")\n",
    "\n",
    "filename = \"hello.mp3\"\n",
    "\n",
    "with open(filename, \"rb\") as file:\n",
    "    transcription = client.audio.transcriptions.create(\n",
    "      file=(filename, file.read()),\n",
    "      model=\"whisper-large-v3-turbo\",\n",
    "      response_format=\"verbose_json\",\n",
    "    )\n",
    "    print(transcription.text)\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are the interview panel conducting an interview for a fresher software developer position. Design three professional interviewers with distinct roles and relevant responsibilities tailored to the job profile. Initialize the interview by introducing each interviewer and proceed with the conversation in a realistic, interactive manner. Use a conversational tone to make the session engaging and authentic.\n",
    "\n",
    "When constructing responses, pass the conversation to another interviewer after each question if context is completed . Avoid including a history of responses in the output. Ensure the output includes the latest question and response, formatted as JSON.\n",
    "\n",
    "Update the interviewer details according to the following user input:\n",
    "User details:\n",
    "{\n",
    "  \"role\": \"Software Developer\",\n",
    "  \"skills\": \"Python\",\n",
    "  \"experience\": \"0-1\",\n",
    "  \"scenario\": \"interview\",\n",
    "  \"purpose\": \"Job Interview\",\n",
    "  \"toimprove\": [\"technical\", \"communication\"]\n",
    "}\n",
    "\n",
    "\n",
    "Output format:\n",
    "{\n",
    "  \"interviewer_name\": \"Rajesh Sharma, Engineering Manager\",\n",
    "  \"message\": \"Hello, I'm Rajesh Sharma, the Engineering Manager for the backend team. I'll be leading this interview today.\",\n",
    "  \"id\": 0\n",
    "}\n",
    "\n",
    "\n",
    "introducion output format:\n",
    "[\n",
    "  {\n",
    "    \"interviewer_name\": \"Rajesh Sharma, Engineering Manager\",\n",
    "    \"message\": \"Hello, I'm Rajesh Sharma, the Engineering Manager for the backend team. I'll be leading this interview today.\",\n",
    "    \"id\": 0\n",
    "  },\n",
    "  {\n",
    "    \"interviewer_name\": \"Emily Patel, Senior Backend Developer\",\n",
    "    \"message\": \"Hi, I'm Emily Patel, a Senior Backend Developer on the team. I'll be assessing your technical skills and project-related experiences.\",\n",
    "    \"id\": 1\n",
    "  },\n",
    "  {\n",
    "    \"interviewer_name\": \"David Lee, Technical Recruiter\",\n",
    "    \"message\": \"Hello, I'm David Lee, the Technical Recruiter who coordinated this process. I'll be observing your communication skills and taking notes during the session.\",\n",
    "    \"id\": 2\n",
    "  }\n",
    "]\n",
    "begin with the introduction of all interviewers as a single output, the first interviewer may start the interview. Each subsequent response should involve a single interviewer, passing the conversation fluidly.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userDetails={\n",
    "  \"role\": \"Software Developer\",\n",
    "  \"skills\": \"Python\",\n",
    "  \"experience\": \"0-1\",\n",
    "  \"scenario\": \"interview\",\n",
    "  \"purpose\": \"Job Interview\",\n",
    "  \"toimprove\": [\"technical\", \"communication\"]\n",
    "}\n",
    "prompt=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are the interview panel conducting an interview for a fresher software developer position. Design three professional interviewers with distinct roles and relevant responsibilities tailored to the job profile. Initialize the interview by introducing each interviewer and proceed with the conversation in a realistic, interactive manner. Use a conversational tone to make the session engaging and authentic.\\n\\nWhen constructing responses, pass the conversation to another interviewer after each question if context is completed . Avoid including a history of responses in the output. Ensure the output includes the latest question and response, formatted as JSON.\\n\\nUpdate the interviewer details according to the following user input:\\nUser details: \"+userDetails+\"Output format:\\n\\\"{\\n  \\\"interviewer_name\\\": \\\"Rajesh Sharma, Engineering Manager\\\",\\n  \\\"message\\\": \\\"Hello, I'm Rajesh Sharma, the Engineering Manager for the backend team. I'll be leading this interview today.\\\",\\n  \\\"id\\\": 0\\n}\\\"\\n\\n\\nintroducion output format:\\n\\\"[\\n  {\\n    \\\"interviewer_name\\\": \\\"Rajesh Sharma, Engineering Manager\\\",\\n    \\\"message\\\": \\\"Hello, I'm Rajesh Sharma, the Engineering Manager for the backend team. I'll be leading this interview today.\\\",\\n    \\\"id\\\": 0\\n  },\\n  {\\n    \\\"interviewer_name\\\": \\\"Emily Patel, Senior Backend Developer\\\",\\n    \\\"message\\\": \\\"Hi, I'm Emily Patel, a Senior Backend Developer on the team. I'll be assessing your technical skills and project-related experiences.\\\",\\n    \\\"id\\\": 1\\n  },\\n  {\\n    \\\"interviewer_name\\\": \\\"David Lee, Technical Recruiter\\\",\\n    \\\"message\\\": \\\"Hello, I'm David Lee, the Technical Recruiter who coordinated this process. I'll be observing your communication skills and taking notes during the session.\\\",\\n    \\\"id\\\": 2\\n  }\\n]\\\"\\nbegin with the introduction of all interviewers as a single output, the first interviewer may start the interview. Each subsequent response should involve a single interviewer, passing the conversation fluidly.\\n\\n\\n\\n\\n\\n\\n\"\n",
    "        },\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt.append({\"role\":\"user\",\"content\":\"hello\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "\n",
    "client = Groq(api_key=\"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\")\n",
    "def gorq_LLM(prompt,add_to_history=True):\n",
    "    completion = client.chat.completions.create(\n",
    "    model=\"llama-3.2-11b-vision-preview\",\n",
    "    \n",
    "    messages=prompt,\n",
    "           \n",
    "    temperature=1,\n",
    "    max_tokens=1024,\n",
    "    top_p=1,\n",
    "    stream=False,\n",
    "    stop=None,\n",
    "    )   \n",
    "\n",
    "    reply=str(completion.choices[0].message.content)\n",
    "    if add_to_history is True:\n",
    "        prompt.append({\"role\":\"assistant\",\"content\":reply})\n",
    "    return reply\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp=gorq_LLM(prompt=prompt,add_to_history=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'interviewer_name': 'Rajesh Sharma, Engineering Manager',\n",
       "  'message': \"Hello, I'm Rajesh Sharma, the Engineering Manager for the backend team. I'll be leading this interview today.\",\n",
       "  'id': 0},\n",
       " {'interviewer_name': 'Emily Patel, Senior Backend Developer',\n",
       "  'message': \"Hi, I'm Emily Patel, a Senior Backend Developer on the team. I'll be assessing your technical skills and project-related experiences.\",\n",
       "  'id': 1},\n",
       " {'interviewer_name': 'David Lee, Technical Recruiter',\n",
       "  'message': \"Hello, I'm David Lee, the Technical Recruiter who coordinated this process. I'll be observing your communication skills and taking notes during the session.\",\n",
       "  'id': 2}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp\n",
    "json_data = json.loads(resp)\n",
    "json_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "\n",
    "client = Groq(api_key=\"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\")\n",
    "def groq_whisper(input,add_to_history=True):\n",
    "    with open(filename, \"rb\") as file:\n",
    "        transcription = client.audio.transcriptions.create(\n",
    "        file=(filename, file.read()),\n",
    "        model=\"whisper-large-v3-turbo\",\n",
    "        response_format=\"verbose_json\",\n",
    "        )\n",
    "        reply=str(transcription.text)\n",
    "        if add_to_history is True:\n",
    "            prompt.append({\"role\":\"user\",\"content\":reply})\n",
    "        return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=groq_whisper(input=filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Artificial intelligence is the intelligence possessed by the machines under which they can perform various functions with human help. With the help of A.I, machines will be able to learn, solve problems, plan things, think, etc. Artificial intelligence, for example, is the simulation of human intelligence by machines. In the field of technology, artificial intelligence is evolving rapidly day by day and it is believed that in the near future, artificial intelligence is going to change human life very drastically and will most probably end all the crises of the world by sorting out the major problems. Our life in this modern age depends largely on computers. It is almost impossible to think about life without computers. We need computers in everything that we use in our daily lives. So it becomes very important.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "audio gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import edge_tts\n",
    "import asyncio\n",
    "\n",
    "\n",
    "async def text_to_speech(text, output_file, voice):\n",
    "    \"\"\"Converts text to speech using edge-tts and saves the audio as an MP3 file.\"\"\"\n",
    "    \n",
    "    # Initialize the TTS service with the provided voice\n",
    "    communicate = edge_tts.Communicate(text, voice)\n",
    "    \n",
    "    # Convert the text to speech and save it to the output file\n",
    "    await communicate.save(output_file)\n",
    "\n",
    "\n",
    "async def speakers(json_data):\n",
    "    reply_list=[]\n",
    "    for interviewer in json_data:\n",
    "\n",
    "        text=interviewer['message']\n",
    "        id=interviewer['id']\n",
    "        if id==0:\n",
    "            output_file=\"AUDIOS/0.mp3\"\n",
    "            await text_to_speech(text, output_file,voice=\"en-US-BrianNeural\")\n",
    "            reply_list.append(output_file)\n",
    "            \n",
    "\n",
    "        if id==1:\n",
    "            output_file=\"AUDIOS/1.mp3\"\n",
    "            await text_to_speech(text, output_file,voice=\"en-IN-NeerjaExpressiveNeural\")\n",
    "            reply_list.append(output_file)\n",
    "\n",
    "        if id==2:\n",
    "            output_file=\"AUDIOS/2.mp3\"\n",
    "            await text_to_speech(text, output_file,voice=\"en-US-ChristopherNeural\")\n",
    "            reply_list.append(output_file)\n",
    "    return reply_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AUDIOS/0.mp3', 'AUDIOS/1.mp3', 'AUDIOS/2.mp3']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await speakers(json_data=json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:109: SyntaxWarning: \"is not\" with 'str' literal. Did you mean \"!=\"?\n",
      "<>:109: SyntaxWarning: \"is not\" with 'str' literal. Did you mean \"!=\"?\n",
      "/tmp/ipykernel_7341/348570305.py:109: SyntaxWarning: \"is not\" with 'str' literal. Did you mean \"!=\"?\n",
      "  if reply[0] is not \"[\":\n"
     ]
    }
   ],
   "source": [
    "import edge_tts\n",
    "import asyncio\n",
    "from groq import Groq\n",
    "import json\n",
    "\n",
    "client = Groq(api_key=\"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\")\n",
    "\n",
    "\n",
    "\n",
    "class App:\n",
    "    userDetails={\n",
    "    \"role\": \"Software Developer\",\n",
    "    \"skills\": \"Python\",\n",
    "    \"experience\": \"0-1\",\n",
    "    \"scenario\": \"interview\",\n",
    "    \"purpose\": \"Job Interview\",\n",
    "    \"toimprove\": [\"technical\", \"communication\"]\n",
    "    }\n",
    "    # prompt=[\n",
    "    #         {\n",
    "    #             \"role\": \"system\",\n",
    "    #             \"content\": \"You are the interview panel conducting an interview for a fresher software developer position. Design three professional interviewers with distinct roles and relevant responsibilities tailored to the job profile. Initialize the interview by introducing each interviewer and proceed with the conversation in a realistic, interactive manner. Use a conversational tone to make the session engaging and authentic.\\n\\nWhen constructing responses, pass the conversation to another interviewer after each question if context is completed . Avoid including a history of responses in the output. Ensure the output includes the latest question and response, formatted as JSON.\\n\\nUpdate the interviewer details according to the following user input:\\nUser details: \"+str(userDetails)+\"Output format:\\n\\\"{\\n  \\\"interviewer_name\\\": \\\"Rajesh Sharma, Engineering Manager\\\",\\n  \\\"message\\\": \\\"Hello, I'm Rajesh Sharma, the Engineering Manager for the backend team. I'll be leading this interview today.\\\",\\n  \\\"id\\\": 0\\n}\\\"\\n\\n\\nintroducion first output format (should not be more than this):\\n\\\"[\\n  {\\n    \\\"interviewer_name\\\": \\\"Rajesh Sharma, Engineering Manager\\\",\\n    \\\"message\\\": \\\"Hello, I'm Rajesh Sharma, the Engineering Manager for the backend team. I'll be leading this interview today.\\\",\\n    \\\"id\\\": 0\\n  },\\n  {\\n    \\\"interviewer_name\\\": \\\"Emily Patel, Senior Backend Developer\\\",\\n    \\\"message\\\": \\\"Hi, I'm Emily Patel, a Senior Backend Developer on the team. I'll be assessing your technical skills and project-related experiences.\\\",\\n    \\\"id\\\": 1\\n  },\\n  {\\n    \\\"interviewer_name\\\": \\\"David Lee, Technical Recruiter\\\",\\n    \\\"message\\\": \\\"Hello, I'm David Lee, the Technical Recruiter who coordinated this process. I'll be observing your communication skills and taking notes during the session.\\\",\\n    \\\"id\\\": 2\\n  }\\n]\\\"\\nbegin with the introduction of all interviewers as a single output,dont append the first question in the introduction,After the first output or introduction, the first interviewer may start the interview. Each subsequent response should involve a single interviewer, passing the conversation fluidly.\\n\\n\\n\\n\\n\\n\\n\"\n",
    "    #         },\n",
    "    #     ]\n",
    "    prompt=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": '''You are conducting an interview panel for a fresher software developer position. Design three professional interviewers, each with a distinct role and responsibility suited to the job profile.\n",
    "    Users Profile:'''+str(userDetails)+'''\n",
    "\n",
    "    Begin the interview by introducing each interviewer in a conversational manner. Each introduction should be concise and engaging, setting a realistic tone for the session.\n",
    "\n",
    "    Once the introductions are complete, the first interviewer should ask the first question and the conversation should continue in a fluid and interactive manner. After each question, the conversation will naturally pass to another interviewer when context is completed, with no history of previous responses included in the output.\n",
    "\n",
    "    The structure of the conversation should be presented as JSON, ensuring it includes only the latest question and response, formatted correctly.\n",
    "\n",
    "    The introduction should follow this format (don't append the first question in the introduction):\n",
    "\n",
    "    [\n",
    "    {\n",
    "        \"interviewer_name\": \"Rajesh Sharma, Engineering Manager\",\n",
    "        \"message\": \"Hello, I'm Rajesh Sharma, the Engineering Manager for the backend team. I'll be leading this interview today.\",\n",
    "        \"id\": 0\n",
    "    },\n",
    "    {\n",
    "        \"interviewer_name\": \"Emily Patel, Senior Backend Developer\",\n",
    "        \"message\": \"Hi, I'm Emily Patel, a Senior Backend Developer on the team. I'll be assessing your technical skills and project-related experiences.\",\n",
    "        \"id\": 1\n",
    "    },\n",
    "    {\n",
    "        \"interviewer_name\": \"David Lee, Technical Recruiter\",\n",
    "        \"message\": \"Hello, I'm David Lee, the Technical Recruiter who coordinated this process. I'll be observing your communication skills and taking notes during the session.\",\n",
    "        \"id\": 2\n",
    "    }\n",
    "    ]\n",
    "    Start the conversation with the introductions only. After the first output (introduction), the first interviewer may begin the interview with the first question. Future questions and responses should be passed fluidly between the interviewers, ensuring smooth transitions and an engaging conversation.\n",
    "    Output format after introduction example:\n",
    "    {\n",
    "    \"interviewer_name\": \"Rajesh Sharma, Engineering Manager (modify)\",\n",
    "    \"message\": \"Hello, I'm Rajesh Sharma, the Engineering Manager for the backend team. I'll be leading this interview today. (modify)\",\n",
    "    \"id\": 0\n",
    "    }\n",
    "\n",
    "    STRICT_CONSTRAINTS=\"THE FIRST RESPONSE SHOULD BE THE INTRODUCTION ONLY,\n",
    "    DONT ADD FURTHER QUESTIONS WITH INTRODUCTION,\n",
    "    DONT ADD ANY EXTRA STATEMENTS IN THE OUTPUT,\n",
    "    GIVE OUTPUT AS JSON(property name enclosed in double quote)\n",
    "\n",
    "\n",
    "    \"\n",
    "    FOLLOW THE STRICT_CONSTRAINTS COMPALORY\n",
    "\n",
    "    '''\n",
    "                \n",
    "\n",
    "\n",
    "    },\n",
    "            ]\n",
    "    \n",
    "    async def groq_whisper(self,input,add_to_history=True):\n",
    "        print(\"in Whisper\")\n",
    "        with open(input, \"rb\") as file:\n",
    "            transcription = client.audio.transcriptions.create(\n",
    "            file=(input, file.read()),\n",
    "            model=\"whisper-large-v3-turbo\",\n",
    "            response_format=\"verbose_json\",\n",
    "            )\n",
    "            reply=str(transcription.text)\n",
    "            if add_to_history is True:\n",
    "                self.prompt.append({\"role\":\"user\",\"content\":reply})\n",
    "            await self.gorq_LLM(prompt=self.prompt)\n",
    "\n",
    "    async def gorq_LLM(self,prompt,add_to_history=True):\n",
    "        print(\"in LLM\")\n",
    "        completion = client.chat.completions.create(\n",
    "        model=\"llama-3.2-11b-vision-preview\",\n",
    "        \n",
    "        messages=prompt,\n",
    "            \n",
    "        temperature=1,\n",
    "        max_tokens=1024,\n",
    "        top_p=1,\n",
    "        stream=False,\n",
    "        stop=None,\n",
    "        )   \n",
    "\n",
    "        reply=str(completion.choices[0].message.content)\n",
    "        if reply[0] is not \"[\":\n",
    "            reply= \"[\"+str(completion.choices[0].message.content)+\"]\"\n",
    "\n",
    "        reply = json.loads(reply)\n",
    "        if add_to_history is True:\n",
    "            self.prompt.append({\"role\":\"assistant\",\"content\":str(reply)})\n",
    "        \n",
    "        # return reply\n",
    "        print(\"reply\",reply)\n",
    "        await self.speakers(reply)\n",
    "\n",
    "    async def text_to_speech(self,text, output_file, voice):\n",
    "        \"\"\"Converts text to speech using edge-tts and saves the audio as an MP3 file.\"\"\"\n",
    "        \n",
    "        # Initialize the TTS service with the provided voice\n",
    "        communicate = edge_tts.Communicate(text, voice)\n",
    "        \n",
    "        # Convert the text to speech and save it to the output file\n",
    "        await communicate.save(output_file)\n",
    "\n",
    "\n",
    "    async def speakers(self,json_data):\n",
    "        print(\"in Speaker\")\n",
    "\n",
    "        reply_list=[]\n",
    "        for interviewer in json_data:\n",
    "\n",
    "            text=interviewer['message']\n",
    "            id=interviewer['id']\n",
    "            if id==0:\n",
    "                output_file=\"AUDIOS/0.mp3\"\n",
    "                await self.text_to_speech(text, output_file,voice=\"en-US-BrianNeural\")\n",
    "                reply_list.append(output_file)\n",
    "                \n",
    "\n",
    "            if id==1:\n",
    "                output_file=\"AUDIOS/1.mp3\"\n",
    "                await self.text_to_speech(text, output_file,voice=\"en-IN-NeerjaExpressiveNeural\")\n",
    "                reply_list.append(output_file)\n",
    "\n",
    "            if id==2:\n",
    "                output_file=\"AUDIOS/2.mp3\"\n",
    "                await self.text_to_speech(text, output_file,voice=\"en-US-ChristopherNeural\")\n",
    "                reply_list.append(output_file)\n",
    "        return reply_list\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj=App()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in Whisper\n",
      "in LLM\n",
      "reply [\n",
      "    {\n",
      "        \"interviewer_name\": \"Rajesh Sharma, Engineering Manager\",\n",
      "        \"message\": \"Hello, I'm Rajesh Sharma, the Engineering Manager for the backend team. I'll be leading this interview today.\",\n",
      "        \"id\": 0\n",
      "    },\n",
      "    {\n",
      "        \"interviewer_name\": \"Emily Patel, Senior Backend Developer\",\n",
      "        \"message\": \"Hi, I'm Emily Patel, a Senior Backend Developer on the team. I'll be assessing your technical skills and project-related experiences.\",\n",
      "        \"id\": 1\n",
      "    },\n",
      "    {\n",
      "        \"interviewer_name\": \"David Lee, Technical Recruiter\",\n",
      "        \"message\": \"Hello, I'm David Lee, the Technical Recruiter who coordinated this process. I'll be observing your communication skills and taking notes during the session.\",\n",
      "        \"id\": 2\n",
      "    }\n",
      "]\n",
      "json loaded\n",
      "reply [{'interviewer_name': 'Rajesh Sharma, Engineering Manager', 'message': \"Hello, I'm Rajesh Sharma, the Engineering Manager for the backend team. I'll be leading this interview today.\", 'id': 0}, {'interviewer_name': 'Emily Patel, Senior Backend Developer', 'message': \"Hi, I'm Emily Patel, a Senior Backend Developer on the team. I'll be assessing your technical skills and project-related experiences.\", 'id': 1}, {'interviewer_name': 'David Lee, Technical Recruiter', 'message': \"Hello, I'm David Lee, the Technical Recruiter who coordinated this process. I'll be observing your communication skills and taking notes during the session.\", 'id': 2}]\n",
      "in Speaker\n"
     ]
    }
   ],
   "source": [
    "await obj.groq_whisper(input=\"/start.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in Whisper\n",
      "in LLM\n",
      "reply {\n",
      "    \"interviewer_name\": \"Rajesh Sharma, Engineering Manager\",\n",
      "    \"message\": \"That's a great statement about the rapid evolution of AI. Can you tell me, what are some of the key benefits of using Artificial Intelligence in software development, and how do you think it can impact our work?\",\n",
      "    \"id\": 0\n",
      "}\n",
      "{\n",
      "[{\n",
      "    \"interviewer_name\": \"Rajesh Sharma, Engineering Manager\",\n",
      "    \"message\": \"That's a great statement about the rapid evolution of AI. Can you tell me, what are some of the key benefits of using Artificial Intelligence in software development, and how do you think it can impact our work?\",\n",
      "    \"id\": 0\n",
      "}]\n",
      "json loaded\n",
      "reply [{'interviewer_name': 'Rajesh Sharma, Engineering Manager', 'message': \"That's a great statement about the rapid evolution of AI. Can you tell me, what are some of the key benefits of using Artificial Intelligence in software development, and how do you think it can impact our work?\", 'id': 0}]\n",
      "in Speaker\n"
     ]
    }
   ],
   "source": [
    "await obj.groq_whisper(input=\"/start.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'python Developer', 'skills': 'Python', 'experience': '0-1', 'scenario': 'interview', 'purpose': 'Job Interview', 'toimprove': ['technical', 'communication']}\n"
     ]
    }
   ],
   "source": [
    "new={\n",
    "    \"role\": \"python Developer\",\n",
    "    \"skills\": \"Python\",\n",
    "    \"experience\": \"0-1\",\n",
    "    \"scenario\": \"interview\",\n",
    "    \"purpose\": \"Job Interview\",\n",
    "    \"toimprove\": [\"technical\", \"communication\"]\n",
    "    }\n",
    "obj.userDetails=new\n",
    "\n",
    "print(obj.userDetails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import edge_tts\n",
    "import asyncio\n",
    "from groq import Groq\n",
    "import json\n",
    "\n",
    "client = Groq(api_key=\"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\")\n",
    "\n",
    "class App:\n",
    "    userDetails = {\n",
    "        \"role\": \"Software Developer\",\n",
    "        \"skills\": \"Python\",\n",
    "        \"experience\": \"0-1\",\n",
    "        \"scenario\": \"interview\",\n",
    "        \"purpose\": \"Job Interview\",\n",
    "        \"toimprove\": [\"technical\", \"communication\"]\n",
    "    }\n",
    "\n",
    "    prompt = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": '''You are conducting an interview panel for a fresher software developer position. Design three professional interviewers, each with a distinct role and responsibility suited to the job profile.\n",
    "    Users Profile:'''+str(userDetails)+'''\n",
    "\n",
    "    Begin the interview by introducing each interviewer in a conversational manner. Each introduction should be concise and engaging, setting a realistic tone for the session.\n",
    "\n",
    "    Once the introductions are complete, the first interviewer should ask the first question and the conversation should continue in a fluid and interactive manner. After each question, the conversation will naturally pass to another interviewer when context is completed, with no history of previous responses included in the output.\n",
    "\n",
    "    The structure of the conversation should be presented as JSON, ensuring it includes only the latest question and response, formatted correctly.\n",
    "\n",
    "    The introduction should follow this format (don't append the first question in the introduction):\n",
    "\n",
    "    [\n",
    "    {\n",
    "        \"interviewer_name\": \"Rajesh Sharma, Engineering Manager\",\n",
    "        \"message\": \"Hello, I'm Rajesh Sharma, the Engineering Manager for the backend team. I'll be leading this interview today.\",\n",
    "        \"id\": 0\n",
    "    },\n",
    "    {\n",
    "        \"interviewer_name\": \"Emily Patel, Senior Backend Developer\",\n",
    "        \"message\": \"Hi, I'm Emily Patel, a Senior Backend Developer on the team. I'll be assessing your technical skills and project-related experiences.\",\n",
    "        \"id\": 1\n",
    "    },\n",
    "    {\n",
    "        \"interviewer_name\": \"David Lee, Technical Recruiter\",\n",
    "        \"message\": \"Hello, I'm David Lee, the Technical Recruiter who coordinated this process. I'll be observing your communication skills and taking notes during the session.\",\n",
    "        \"id\": 2\n",
    "    }\n",
    "    ]\n",
    "    Start the conversation with the introductions only. After the first output (introduction), the first interviewer may begin the interview with the first question. Future questions and responses should be passed fluidly between the interviewers, ensuring smooth transitions and an engaging conversation.\n",
    "    Output format after introduction example:\n",
    "    {\n",
    "    \"interviewer_name\": \"Rajesh Sharma, Engineering Manager (modify)\",\n",
    "    \"message\": \"Hello, I'm Rajesh Sharma, the Engineering Manager for the backend team. I'll be leading this interview today. (modify)\",\n",
    "    \"id\": 0\n",
    "    }\n",
    "\n",
    "    STRICT_CONSTRAINTS=\"THE FIRST RESPONSE SHOULD BE THE INTRODUCTION ONLY,\n",
    "    DONT ADD FURTHER QUESTIONS WITH INTRODUCTION,\n",
    "    DONT ADD ANY EXTRA STATEMENTS IN THE OUTPUT,\n",
    "    GIVE OUTPUT AS JSON,\n",
    "    IN OUTPUT JSON- PROPERTY NAME ENCLOSED IN DOUBLE QUOTE,\n",
    "\n",
    "\n",
    "\n",
    "    \"\n",
    "    FOLLOW THE STRICT_CONSTRAINTS COMPALORY\n",
    "\n",
    "    '''\n",
    "        },\n",
    "    ]\n",
    "    def clear_prompt(self):\n",
    "        self.prompt = [obj.prompt[0]]\n",
    "\n",
    "        \n",
    "    async def groq_whisper(self, input, add_to_history=True):\n",
    "        print(\"in Whisper\")\n",
    "        with open(input, \"rb\") as file:\n",
    "            transcription = client.audio.transcriptions.create(\n",
    "                file=(input, file.read()),\n",
    "                model=\"whisper-large-v3-turbo\",\n",
    "                response_format=\"verbose_json\",\n",
    "            )\n",
    "            reply = str(transcription.text)\n",
    "            if add_to_history:\n",
    "                self.prompt.append({\"role\": \"user\", \"content\": reply})\n",
    "            await self.gorq_LLM(prompt=self.prompt)\n",
    "\n",
    "    async def gorq_LLM(self, prompt, add_to_history=True):\n",
    "        print(\"in LLM\")\n",
    "        # Making asynchronous API call to the LLM\n",
    "        completion = await asyncio.to_thread(\n",
    "            client.chat.completions.create,\n",
    "            model=\"llama-3.2-11b-vision-preview\",\n",
    "            messages=prompt,\n",
    "            temperature=1,\n",
    "            max_tokens=1024,\n",
    "            top_p=1,\n",
    "            stream=False,\n",
    "            stop=None,\n",
    "        )\n",
    "        reply = str(completion.choices[0].message.content)\n",
    "        if reply[0] != \"[\":\n",
    "            reply = \"[\" + str(completion.choices[0].message.content) + \"]\"\n",
    "\n",
    "        reply = json.loads(reply)\n",
    "        if add_to_history:\n",
    "            self.prompt.append({\"role\": \"assistant\", \"content\": str(reply)})\n",
    "\n",
    "        print(\"reply\", reply)\n",
    "        await self.speakers(reply)\n",
    "    outputPaths=[]\n",
    "    async def text_to_speech(self, text, output_file, voice):\n",
    "        \"\"\"Converts text to speech using edge-tts and saves the audio as an MP3 file.\"\"\"\n",
    "        communicate = edge_tts.Communicate(text, voice) \n",
    "        await communicate.save(output_file)\n",
    "    outputPaths=[]\n",
    "    async def speakers(self, json_data):\n",
    "        self.outputPaths = []  # Initialize/clear the output paths\n",
    "        print(\"In Speaker\")\n",
    "        # Create a list of tasks for concurrent execution\n",
    "        tasks = []\n",
    "        voice_map = {\n",
    "            0: \"en-US-BrianNeural\",\n",
    "            1: \"en-IN-NeerjaExpressiveNeural\",\n",
    "            2: \"en-US-ChristopherNeural\",\n",
    "        }\n",
    "        for interviewer in json_data:\n",
    "            text = interviewer['message']\n",
    "            output_file = f\"AUDIOS/{interviewer['id']}.mp3\"\n",
    "            self.outputPaths.append(output_file)  # Append to the output list before creating the task\n",
    "            voice = voice_map.get(interviewer['id'], 'en-US-BrianNeural')\n",
    "            # Create a task for each TTS generation\n",
    "            tasks.append(self.text_to_speech(text, output_file, voice))\n",
    "        \n",
    "        # Await all tasks concurrently\n",
    "        await asyncio.gather(*tasks)\n",
    "\n",
    "        print(\"Generated audio files:\", self.outputPaths)  # Ensure this shows the populated list\n",
    "        return self.outputPaths  # Return the populated list\n",
    "\n",
    "# Instantiate the class and call the method asynchronously\n",
    "# async def main():\n",
    "#     obj = App()\n",
    "#     await obj.groq_whisper(input=\"start.mp3\")\n",
    "\n",
    "# Execute the main function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in Whisper\n",
      "in LLM\n",
      "reply [{'interviewer_name': 'Rajesh Sharma, Engineering Manager', 'message': \"Hello, I'm Rajesh Sharma, the Engineering Manager for the backend team. I'll be leading this interview today.\", 'id': 0}, {'interviewer_name': 'Emily Patel, Senior Backend Developer', 'message': \"Hi, I'm Emily Patel, a Senior Backend Developer on the team. I'll be assessing your technical skills and project-related experiences.\", 'id': 1}, {'interviewer_name': 'David Lee, Technical Recruiter', 'message': \"Hello, I'm David Lee, the Technical Recruiter who coordinated this process. I'll be observing your communication skills and taking notes during the session.\", 'id': 2}]\n",
      "In Speaker\n",
      "Generated audio files: ['AUDIOS/0.mp3', 'AUDIOS/1.mp3', 'AUDIOS/2.mp3']\n"
     ]
    }
   ],
   "source": [
    "li=await obj.groq_whisper(input=\"start.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in Whisper\n",
      "in LLM\n",
      "reply [{'interviewer_name': 'Rajesh Sharma, Engineering Manager', 'message': 'So, based on the job description, can you tell me what you think is the biggest challenge a software developer might face in this role, and how you would approach it?', 'id': 0}]\n",
      "In Speaker\n",
      "Generated audio files: ['AUDIOS/0.mp3']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import edge_tts\n",
    "from groq import Groq\n",
    "import json\n",
    "\n",
    "client = Groq(api_key=\"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\")\n",
    "\n",
    "class App:\n",
    "    userDetails = {\n",
    "        \"role\": \"Software Developer\",\n",
    "        \"skills\": \"Python\",\n",
    "        \"experience\": \"0-1\",\n",
    "        \"scenario\": \"interview\",\n",
    "        \"purpose\": \"Job Interview\",\n",
    "        \"toimprove\": [\"technical\", \"communication\"]\n",
    "    }\n",
    "\n",
    "    prompt = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": '''You are an interview panel for a fresher software developer position. Design three professional interviewers, each with a distinct role and responsibility suited to the job profile.\n",
    "\n",
    "User's Profile: '''+str(userDetails)+'''\n",
    "\n",
    "Your task:\n",
    "1. Begin the interview by introducing each interviewer in a conversational manner.\n",
    "2. Each introduction should be concise and engaging, setting a realistic tone for the session.\n",
    "3. Ensure the response only includes the introduction for the first output.\n",
    "4. The introduction must be structured as a valid JSON array containing three objects.\n",
    "\n",
    "**JSON Format for the Introduction:**  \n",
    "[\n",
    "    {\n",
    "        \"interviewer_name\": \"Rajesh Sharma, Engineering Manager\",\n",
    "        \"message\": \"Hello, I'm Rajesh Sharma, the Engineering Manager for the backend team. I'll be leading this interview today.\",\n",
    "        \"id\": 0\n",
    "    },\n",
    "    {\n",
    "        \"interviewer_name\": \"Emily Patel, Senior Backend Developer\",\n",
    "        \"message\": \"Hi, I'm Emily Patel, a Senior Backend Developer on the team. I'll be assessing your technical skills and project-related experiences.\",\n",
    "        \"id\": 1\n",
    "    },\n",
    "    {\n",
    "        \"interviewer_name\": \"David Lee, Technical Recruiter\",\n",
    "        \"message\": \"Hello, I'm David Lee, the Technical Recruiter who coordinated this process. I'll be observing your communication skills and taking notes during the session.\",\n",
    "        \"id\": 2\n",
    "    }\n",
    "]\n",
    "\n",
    "**STRICT CONSTRAINTS FOR JSON OUTPUT:**\n",
    "1. The JSON response must consist of an array `[]` enclosing all interviewer objects.\n",
    "2. Each interviewer must be represented as an individual object inside the array.\n",
    "3. All property names and string values must use double quotes (`\"`).\n",
    "4. The first response must only include the introductions in the specified JSON format, without any additional questions or statements.\n",
    "5. Ensure proper indentation and valid JSON formatting in the output.\n",
    "\n",
    "For example, the introduction must strictly follow this JSON format:\n",
    "\n",
    "[\n",
    "    {\n",
    "        \"interviewer_name\": \"Rajesh Sharma, Engineering Manager\",\n",
    "        \"message\": \"Hello, I'm Rajesh Sharma, the Engineering Manager for the backend team. I'll be leading this interview today.\",\n",
    "        \"id\": 0\n",
    "    },\n",
    "    {\n",
    "        \"interviewer_name\": \"Emily Patel, Senior Backend Developer\",\n",
    "        \"message\": \"Hi, I'm Emily Patel, a Senior Backend Developer on the team. I'll be assessing your technical skills and project-related experiences.\",\n",
    "        \"id\": 1\n",
    "    },\n",
    "    {\n",
    "        \"interviewer_name\": \"David Lee, Technical Recruiter\",\n",
    "        \"message\": \"Hello, I'm David Lee, the Technical Recruiter who coordinated this process. I'll be observing your communication skills and taking notes during the session.\",\n",
    "        \"id\": 2\n",
    "    }\n",
    "]\n",
    "'''\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    def clear_prompt(self):\n",
    "        self.prompt = [self.prompt[0]]\n",
    "\n",
    "    def groq_whisper(self, input, add_to_history=True):\n",
    "        print(\"in Whisper\")\n",
    "        with open(input, \"rb\") as file:\n",
    "            transcription = client.audio.transcriptions.create(\n",
    "                file=(input, file.read()),\n",
    "                model=\"whisper-large-v3-turbo\",\n",
    "                response_format=\"verbose_json\",\n",
    "            )\n",
    "            reply = str(transcription.text)\n",
    "            if add_to_history:\n",
    "                self.prompt.append({\"role\": \"user\", \"content\": reply})\n",
    "            self.gorq_LLM(prompt=self.prompt)\n",
    "\n",
    "    def gorq_LLM(self, prompt, add_to_history=True):\n",
    "        print(\"in LLM\")\n",
    "        # Synchronous API call to the LLM\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"llama-3.2-11b-vision-preview\",\n",
    "            messages=prompt,\n",
    "            temperature=1,\n",
    "            max_tokens=1024,\n",
    "            top_p=1,\n",
    "            stream=False,\n",
    "            stop=None,\n",
    "            # response_format={\"type\": \"json_object\"},\n",
    "\n",
    "        )\n",
    "        \n",
    "        reply = str(completion.choices[0].message.content)\n",
    "        print(reply)\n",
    "        if reply[0] != \"[\":\n",
    "            reply = \"[\" + str(completion.choices[0].message.content) + \"]\"\n",
    "\n",
    "        reply = json.loads(reply)\n",
    "        if add_to_history:\n",
    "            self.prompt.append({\"role\": \"assistant\", \"content\": str(reply)})\n",
    "\n",
    "        print(\"reply\", reply)\n",
    "        return reply\n",
    "\n",
    "    # def text_to_speech(self, text, output_file, voice):\n",
    "    #     \"\"\"Synchronously converts text to speech using edge-tts and saves the audio as an MP3 file.\"\"\"\n",
    "    #     communicate = edge_tts.Communicate(text, voice)\n",
    "    #     loop = asyncio.new_event_loop()\n",
    "    #     asyncio.set_event_loop(loop)\n",
    "    #     loop.run_until_complete(communicate.save(output_file))\n",
    "    #     loop.close()\n",
    "\n",
    "    # outputPaths = []\n",
    "\n",
    "    # def speakers(self, json_data):\n",
    "    #     self.outputPaths = []  # Initialize/clear the output paths\n",
    "    #     print(\"In Speaker\")\n",
    "    #     voice_map = {\n",
    "    #         0: \"en-US-BrianNeural\",\n",
    "    #         1: \"en-IN-NeerjaExpressiveNeural\",\n",
    "    #         2: \"en-US-ChristopherNeural\",\n",
    "    #     }\n",
    "    #     for interviewer in json_data:\n",
    "    #         text = interviewer['message']\n",
    "    #         output_file = f\"AUDIOS/{interviewer['id']}.mp3\"\n",
    "    #         self.outputPaths.append(output_file)  # Append to the output list\n",
    "    #         voice = voice_map.get(interviewer['id'], 'en-US-BrianNeural')\n",
    "    #         self.text_to_speech(text, output_file, voice)\n",
    "\n",
    "    #     print(\"Generated audio files:\", self.outputPaths)  # Ensure this shows the populated list\n",
    "    #     return self.outputPaths  # Return the populated list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in Whisper\n",
      "in LLM\n",
      "[\n",
      "    {\n",
      "        \"interviewer_name\": \"Rajesh Sharma, Engineering Manager\",\n",
      "        \"message\": \"Hello, I'm Rajesh Sharma, the Engineering Manager for the backend team. I'll be leading this interview today.\",\n",
      "        \"id\": 0\n",
      "    },\n",
      "    {\n",
      "        \"interviewer_name\": \"Emily Patel, Senior Backend Developer\",\n",
      "        \"message\": \"Hi, I'm Emily Patel, a Senior Backend Developer on the team. I'll be assessing your technical skills and project-related experiences.\",\n",
      "        \"id\": 1\n",
      "    },\n",
      "    {\n",
      "        \"interviewer_name\": \"David Lee, Technical Recruiter\",\n",
      "        \"message\": \"Hello, I'm David Lee, the Technical Recruiter who coordinated this process. I'll be observing your communication skills and taking notes during the session.\",\n",
      "        \"id\": 2\n",
      "    }\n",
      "]\n",
      "reply [{'interviewer_name': 'Rajesh Sharma, Engineering Manager', 'message': \"Hello, I'm Rajesh Sharma, the Engineering Manager for the backend team. I'll be leading this interview today.\", 'id': 0}, {'interviewer_name': 'Emily Patel, Senior Backend Developer', 'message': \"Hi, I'm Emily Patel, a Senior Backend Developer on the team. I'll be assessing your technical skills and project-related experiences.\", 'id': 1}, {'interviewer_name': 'David Lee, Technical Recruiter', 'message': \"Hello, I'm David Lee, the Technical Recruiter who coordinated this process. I'll be observing your communication skills and taking notes during the session.\", 'id': 2}]\n"
     ]
    }
   ],
   "source": [
    "ob = App()\n",
    "ob.clear_prompt()\n",
    "\n",
    "ob.groq_whisper(input=\"start.mp3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are an interview panel for a fresher software developer position. Design three professional interviewers, each with a distinct role and responsibility suited to the job profile.\\n\\nUser\\'s Profile: {\\'role\\': \\'Software Developer\\', \\'skills\\': \\'Python\\', \\'experience\\': \\'0-1\\', \\'scenario\\': \\'interview\\', \\'purpose\\': \\'Job Interview\\', \\'toimprove\\': [\\'technical\\', \\'communication\\']}\\n\\nYour task:\\n1. Begin the interview by introducing each interviewer in a conversational manner.\\n2. Each introduction should be concise and engaging, setting a realistic tone for the session.\\n3. Ensure the response only includes the introduction for the first output.\\n4. The introduction must be structured as a valid JSON array containing three objects.\\n\\n**JSON Format for the Introduction:**  \\n[\\n    {\\n        \"interviewer_name\": \"Rajesh Sharma, Engineering Manager\",\\n        \"message\": \"Hello, I\\'m Rajesh Sharma, the Engineering Manager for the backend team. I\\'ll be leading this interview today.\",\\n        \"id\": 0\\n    },\\n    {\\n        \"interviewer_name\": \"Emily Patel, Senior Backend Developer\",\\n        \"message\": \"Hi, I\\'m Emily Patel, a Senior Backend Developer on the team. I\\'ll be assessing your technical skills and project-related experiences.\",\\n        \"id\": 1\\n    },\\n    {\\n        \"interviewer_name\": \"David Lee, Technical Recruiter\",\\n        \"message\": \"Hello, I\\'m David Lee, the Technical Recruiter who coordinated this process. I\\'ll be observing your communication skills and taking notes during the session.\",\\n        \"id\": 2\\n    }\\n]\\n\\n**STRICT CONSTRAINTS FOR JSON OUTPUT:**\\n1. The JSON response must consist of an array `[]` enclosing all interviewer objects.\\n2. Each interviewer must be represented as an individual object inside the array.\\n3. All property names and string values must use double quotes (`\"`).\\n4. The first response must only include the introductions in the specified JSON format, without any additional questions or statements.\\n5. Ensure proper indentation and valid JSON formatting in the output.\\n\\nFor example, the introduction must strictly follow this JSON format:\\n\\n[\\n    {\\n        \"interviewer_name\": \"Rajesh Sharma, Engineering Manager\",\\n        \"message\": \"Hello, I\\'m Rajesh Sharma, the Engineering Manager for the backend team. I\\'ll be leading this interview today.\",\\n        \"id\": 0\\n    },\\n    {\\n        \"interviewer_name\": \"Emily Patel, Senior Backend Developer\",\\n        \"message\": \"Hi, I\\'m Emily Patel, a Senior Backend Developer on the team. I\\'ll be assessing your technical skills and project-related experiences.\",\\n        \"id\": 1\\n    },\\n    {\\n        \"interviewer_name\": \"David Lee, Technical Recruiter\",\\n        \"message\": \"Hello, I\\'m David Lee, the Technical Recruiter who coordinated this process. I\\'ll be observing your communication skills and taking notes during the session.\",\\n        \"id\": 2\\n    }\\n]\\n'},\n",
       " {'role': 'user', 'content': \" Hello, Hi, Let's Begin\"},\n",
       " {'role': 'assistant',\n",
       "  'content': '[{\\'interviewer_name\\': \\'Rajesh Sharma, Engineering Manager\\', \\'message\\': \"Hello, I\\'m Rajesh Sharma, the Engineering Manager for the backend team. I\\'ll be leading this interview today.\", \\'id\\': 0}, {\\'interviewer_name\\': \\'Emily Patel, Senior Backend Developer\\', \\'message\\': \"Hi, I\\'m Emily Patel, a Senior Backend Developer on the team. I\\'ll be assessing your technical skills and project-related experiences.\", \\'id\\': 1}, {\\'interviewer_name\\': \\'David Lee, Technical Recruiter\\', \\'message\\': \"Hello, I\\'m David Lee, the Technical Recruiter who coordinated this process. I\\'ll be observing your communication skills and taking notes during the session.\", \\'id\\': 2}]'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json,re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary='''[\n",
    "    {\n",
    "        'interviewer_name': 'Rajesh Sharma, Engineering Manager',\n",
    "        'message': \"Hello, I'm Rajesh Sharma, the Engineering Manager for the backend team. I'll be leading this interview today\",\n",
    "        'id': 0\n",
    "    },\n",
    "    {\n",
    "        'interviewer_name': \"Emily Patel, Senior Backend Developer\",\n",
    "        'message': \"Hi, I'm Emily Patel, a Senior Backend Developer on the team. I'll be assessing your technical skills and project-related experiences.\",\n",
    "        'id': 1\n",
    "    },\n",
    "    {\n",
    "        'interviewer_name': 'David Lee, Technical Recruiter',\n",
    "        'message': \"Hello, I'm David Lee, the Technical Recruiter who coordinated this process. I'll be observing your communication skills and taking notes during the session\",\n",
    "        'id': 2\n",
    "    }\n",
    "]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "a='''[\n",
    "    {\n",
    "        \"interviewer_name\": \"Rajesh Sharma, Engineering Manager\",\n",
    "        \"message\": \"Hello, I'm Rajesh Sharma, the Engineering Manager for the backend team. I'll be leading this interview today.\",\n",
    "        \"id\": 0\n",
    "    },\n",
    "    {\n",
    "        \"interviewer_name\": \"Emily Patel, Senior Backend Developer\",\n",
    "        \"message\": \"Hi, I'm Emily Patel, a Senior Backend Developer on the team. I'll be assessing your technical skills and project-related experiences.\",\n",
    "        \"id\": 1\n",
    "    },\n",
    "    {\n",
    "        \"interviewer_name\": \"David Lee, Technical Recruiter\",\n",
    "        \"message\": \"Hello, I'm David Lee, the Technical Recruiter who coordinated this process. I'll be observing your communication skills and taking notes during the session.\",\n",
    "        \"id\": 2\n",
    "    }\n",
    "]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_output = re.sub(r\"'([^']*)'\", r'\"\\1\"', dictionary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"interviewer_name\": \"Rajesh Sharma, Engineering Manager\",\n",
      "        \"message\": \"Hello, I\"m Rajesh Sharma, the Engineering Manager for the backend team. I\"ll be leading this interview today\",\n",
      "        \"id\": 0\n",
      "    },\n",
      "    {\n",
      "        \"interviewer_name\": \"Emily Patel, Senior Backend Developer\",\n",
      "        \"message\": \"Hi, I\"m Emily Patel, a Senior Backend Developer on the team. I\"ll be assessing your technical skills and project-related experiences.\",\n",
      "        \"id\": 1\n",
      "    },\n",
      "    {\n",
      "        \"interviewer_name\": \"David Lee, Technical Recruiter\",\n",
      "        \"message\": \"Hello, I\"m David Lee, the Technical Recruiter who coordinated this process. I\"ll be observing your communication skills and taking notes during the session\",\n",
      "        \"id\": 2\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainlist=[]\n",
    "\n",
    "for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting property name enclosed in double quotes: line 3 column 9 (char 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m new\u001b[38;5;241m=\u001b[39m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdictionary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m new\n",
      "File \u001b[0;32m/usr/lib/python3.12/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m/usr/lib/python3.12/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m/usr/lib/python3.12/json/decoder.py:353\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;124;03ma JSON document) and return a 2-tuple of the Python\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;124;03mrepresentation and the index in ``s`` where the document ended.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    350\u001b[0m \n\u001b[1;32m    351\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscan_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting property name enclosed in double quotes: line 3 column 9 (char 16)"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "new=json.loads(dictionary)\n",
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "userDetails = {\n",
    "    \"role\": \"Software Developer\",\n",
    "    \"skills\": \"Python\",\n",
    "    \"experience\": \"0-1\",\n",
    "    \"scenario\": \"interview\",\n",
    "    \"purpose\": \"Job Interview\",\n",
    "    \"toimprove\": [\"technical\", \"communication\"]\n",
    "}\n",
    "\n",
    "prompt = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": '''You are an interview panel for a fresher software developer position. Design three professional interviewers, each with a distinct role and responsibility suited to the job profile.\n",
    "\n",
    "User's Profile: '''+str(userDetails)+'''\n",
    "\n",
    "Your task:\n",
    "1. Begin the interview by introducing each interviewer in a conversational manner.\n",
    "2. Each introduction should be concise and engaging, setting a realistic tone for the session.\n",
    "3. Ensure the response only includes the introduction for the first output.\n",
    "4. The introduction must be structured as a valid JSON array containing three objects.\n",
    "\n",
    "**JSON Format for the Introduction:**  \n",
    "[\"data\":[\n",
    "    {\n",
    "        \"interviewer_name\": \"Rajesh Sharma, Engineering Manager\",\n",
    "        \"message\": \"Hello, I'm Rajesh Sharma, the Engineering Manager for the backend team. I'll be leading this interview today.\",\n",
    "        \"id\": 0\n",
    "    },\n",
    "    {\n",
    "        \"interviewer_name\": \"Emily Patel, Senior Backend Developer\",\n",
    "        \"message\": \"Hi, I'm Emily Patel, a Senior Backend Developer on the team. I'll be assessing your technical skills and project-related experiences.\",\n",
    "        \"id\": 1\n",
    "    },\n",
    "    {\n",
    "        \"interviewer_name\": \"David Lee, Technical Recruiter\",\n",
    "        \"message\": \"Hello, I'm David Lee, the Technical Recruiter who coordinated this process. I'll be observing your communication skills and taking notes during the session.\",\n",
    "        \"id\": 2\n",
    "    }]\n",
    "]\n",
    "\n",
    "**STRICT CONSTRAINTS FOR JSON OUTPUT:**\n",
    "1. The JSON response must consist of an array `[]` enclosing all interviewer objects.\n",
    "2. Each interviewer must be represented as an individual object inside the array.\n",
    "3. All property names and string values must use double quotes (`\"`).\n",
    "4. The first response must only include the introductions in the specified JSON format, without any additional questions or statements.\n",
    "5. Ensure proper indentation and valid JSON formatting in the output.\n",
    "\n",
    "For example, the introduction must strictly follow this JSON format:\n",
    "\n",
    "[\"data\":[\n",
    "    {\n",
    "        \"interviewer_name\": \"Rajesh Sharma, Engineering Manager\",\n",
    "        \"message\": \"Hello, I'm Rajesh Sharma, the Engineering Manager for the backend team. I'll be leading this interview today.\",\n",
    "        \"id\": 0\n",
    "    },\n",
    "    {\n",
    "        \"interviewer_name\": \"Emily Patel, Senior Backend Developer\",\n",
    "        \"message\": \"Hi, I'm Emily Patel, a Senior Backend Developer on the team. I'll be assessing your technical skills and project-related experiences.\",\n",
    "        \"id\": 1\n",
    "    },\n",
    "    {\n",
    "        \"interviewer_name\": \"David Lee, Technical Recruiter\",\n",
    "        \"message\": \"Hello, I'm David Lee, the Technical Recruiter who coordinated this process. I'll be observing your communication skills and taking notes during the session.\",\n",
    "        \"id\": 2\n",
    "    }]\n",
    "]\n",
    "'''\n",
    "        },\n",
    "    ]\n",
    "from groq import Groq\n",
    "client = Groq(api_key=\"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\")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"llama-3.2-11b-vision-preview\",\n",
    "    messages=prompt,\n",
    "    temperature=1,\n",
    "    max_tokens=1024,\n",
    "    top_p=1,\n",
    "    stream=False,\n",
    "    stop=None,\n",
    "    response_format={\"type\": \"json_object\"},\n",
    "\n",
    ")\n",
    "\n",
    "reply = completion.choices[0].message.content\n",
    "    # print(reply)\n",
    "    # if reply[0] != \"[\":\n",
    "    #     reply = \"[\" + str(completion.choices[0].message.content) + \"]\"\n",
    "\n",
    "    # reply = json.loads(reply)\n",
    "    \n",
    "\n",
    "    # print(\"reply\", reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n   \"data\":[\\n      {\\n         \"interviewer_name\": \"Rajesh Sharma, Engineering Manager\",\\n         \"message\": \"Hello, I\\'m Rajesh Sharma, the Engineering Manager for the backend team. I\\'ll be leading this interview today.\",\\n         \"id\": 0\\n      },\\n      {\\n         \"interviewer_name\": \"Emily Patel, Senior Backend Developer\",\\n         \"message\": \"Hi, I\\'m Emily Patel, a Senior Backend Developer on the team. I\\'ll be assessing your technical skills and project-related experiences.\",\\n         \"id\": 1\\n      },\\n      {\\n         \"interviewer_name\": \"David Lee, Technical Recruiter\",\\n         \"message\": \"Hello, I\\'m David Lee, the Technical Recruiter who coordinated this process. I\\'ll be observing your communication skills and taking notes during the session.\",\\n         \"id\": 2\\n      }\\n   ]\\n}'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'interviewer_name': 'Rajesh Sharma, Engineering Manager',\n",
       "  'message': \"Hello, I'm Rajesh Sharma, the Engineering Manager for the backend team. I'll be leading this interview today.\",\n",
       "  'id': 0},\n",
       " {'interviewer_name': 'Emily Patel, Senior Backend Developer',\n",
       "  'message': \"Hi, I'm Emily Patel, a Senior Backend Developer on the team. I'll be assessing your technical skills and project-related experiences.\",\n",
       "  'id': 1},\n",
       " {'interviewer_name': 'David Lee, Technical Recruiter',\n",
       "  'message': \"Hello, I'm David Lee, the Technical Recruiter who coordinated this process. I'll be observing your communication skills and taking notes during the session.\",\n",
       "  'id': 2}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=json.loads(reply)\n",
    "data['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are an interview panel for a fresher software developer position. Design three professional interviewers, each with a distinct role and responsibility suited to the job profile.\\n\\nUser\\'s Profile: {\\'role\\': \\'Software Developer\\', \\'skills\\': \\'Python\\', \\'experience\\': \\'0-1\\', \\'scenario\\': \\'interview\\', \\'purpose\\': \\'Job Interview\\', \\'toimprove\\': [\\'technical\\', \\'communication\\']}\\n\\nYour task:\\n1. Begin the interview by introducing each interviewer in a conversational manner.\\n2. Each introduction should be concise and engaging, setting a realistic tone for the session.\\n3. Ensure the response only includes the introduction for the first output.\\n4. The introduction must be structured as a valid JSON array containing three objects.\\n\\n**JSON Format for the Introduction:**  \\n[\\n    {\\n        \"interviewer_name\": \"Rajesh Sharma, Engineering Manager\",\\n        \"message\": \"Hello, I\\'m Rajesh Sharma, the Engineering Manager for the backend team. I\\'ll be leading this interview today.\",\\n        \"id\": 0\\n    },\\n    {\\n        \"interviewer_name\": \"Emily Patel, Senior Backend Developer\",\\n        \"message\": \"Hi, I\\'m Emily Patel, a Senior Backend Developer on the team. I\\'ll be assessing your technical skills and project-related experiences.\",\\n        \"id\": 1\\n    },\\n    {\\n        \"interviewer_name\": \"David Lee, Technical Recruiter\",\\n        \"message\": \"Hello, I\\'m David Lee, the Technical Recruiter who coordinated this process. I\\'ll be observing your communication skills and taking notes during the session.\",\\n        \"id\": 2\\n    }\\n]\\n\\n**STRICT CONSTRAINTS FOR JSON OUTPUT:**\\n1. The JSON response must consist of an array `[]` enclosing all interviewer objects.\\n2. Each interviewer must be represented as an individual object inside the array.\\n3. All property names and string values must use double quotes (`\"`).\\n4. The first response must only include the introductions in the specified JSON format, without any additional questions or statements.\\n5. Ensure proper indentation and valid JSON formatting in the output.\\n\\nFor example, the introduction must strictly follow this JSON format:\\n\\n[\\n    {\\n        \"interviewer_name\": \"Rajesh Sharma, Engineering Manager\",\\n        \"message\": \"Hello, I\\'m Rajesh Sharma, the Engineering Manager for the backend team. I\\'ll be leading this interview today.\",\\n        \"id\": 0\\n    },\\n    {\\n        \"interviewer_name\": \"Emily Patel, Senior Backend Developer\",\\n        \"message\": \"Hi, I\\'m Emily Patel, a Senior Backend Developer on the team. I\\'ll be assessing your technical skills and project-related experiences.\",\\n        \"id\": 1\\n    },\\n    {\\n        \"interviewer_name\": \"David Lee, Technical Recruiter\",\\n        \"message\": \"Hello, I\\'m David Lee, the Technical Recruiter who coordinated this process. I\\'ll be observing your communication skills and taking notes during the session.\",\\n        \"id\": 2\\n    }\\n]\\n'},\n",
       " {'role': 'user', 'content': \" Hello, Hi, Let's Begin\"},\n",
       " {'role': 'assistant',\n",
       "  'content': '[{\\'interviewer_name\\': \\'Rajesh Sharma, Engineering Manager\\', \\'message\\': \"Hello, I\\'m Rajesh Sharma, the Engineering Manager for the backend team. I\\'ll be leading this interview today.\", \\'id\\': 0}, {\\'interviewer_name\\': \\'Emily Patel, Senior Backend Developer\\', \\'message\\': \"Hi, I\\'m Emily Patel, a Senior Backend Developer on the team. I\\'ll be assessing your technical skills and project-related experiences.\", \\'id\\': 1}, {\\'interviewer_name\\': \\'David Lee, Technical Recruiter\\', \\'message\\': \"Hello, I\\'m David Lee, the Technical Recruiter who coordinated this process. I\\'ll be observing your communication skills and taking notes during the session.\", \\'id\\': 2}]'}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ob.prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "his=[\n",
    "        {\n",
    "        \"role\": \"user\",\n",
    "        \"parts\": [\n",
    "            \"I will provide a Json to you, It contains the conversation between Model and user, You have to generate a extreamly detailed report of their mistakes and also score them widely , point there mistakes from the conversation to give examples\\nformat \\n{ \\\"Interview Report\\\": {role,Scenario}\\n  \\\"fluency\\\": \\\"7.5\\\",\\n  \\\"mistakes\\\": [ explain in detail],\\n  \\\"scores\\\": { explain in detail\\n    \\\"clarity\\\": 8,\\n    \\\"confidence\\\": 7,\\n    \\\"accuracy\\\": 6\\n  },\\n  \\\"visualization_data\\\": {\\n    \\\"line_chart_fluency\\\": [\\n      { \\\"response\\\": 1, \\\"fluency_score\\\": 6 },\\n      { \\\"response\\\": 2, \\\"fluency_score\\\": 7 },\\n      ...\\n    ],\\n    \\\"bar_chart_mistakes\\\": {\\n      \\\"tenses\\\": 5,\\n      \\\"word_usage\\\": 3,\\n      \\\"sentence_structure\\\": 4\\n    },\\n    \\\"pie_chart_communication_clarity\\\": {\\n      \\\"clarity_score\\\": 8,\\n      \\\"communication_score\\\": 7\\n    }\\n  },\\n  \\\"suggested_improvements\\\": [\\\"mprove sentence structure and choice of words.\\\"],\\n  \\\"benchmark_comparison\\\": {\\n    \\\"average_fluency\\\",\\n    \\\"average_clarity\\\",\\n    \\\"average_accuracy\\\"\\n  },\\n  \\\"summary\\\": \\\"The candidate shows strong clarity and communication skills but could improve in sentence structure and word choice to achieve greater accuracy.\\\"\\n}\",\n",
    "        ],\n",
    "        },\n",
    "        {\n",
    "        \"role\": \"model\",\n",
    "        \"parts\": [\n",
    "            \"{\\\"Interview Report\\\": {\\\"role\\\": \\\"Model\\\", \\\"Scenario\\\": \\\"Conversation between Model and user\\\"}, \\\"fluency\\\": \\\"7.5\\\", \\\"mistakes\\\": [\\\"The candidate displayed minor grammatical errors in some responses, particularly in tense usage. For example, in response 3, the candidate used the past tense instead of the present tense, leading to a slightly confusing sentence structure.  \\\", \\\"There were a few instances where the candidate could have used more precise vocabulary to express their thoughts more effectively. In response 5, for instance, the word 'stuff' could have been replaced with a more specific and descriptive term, improving the overall clarity of the message.\\\", \\\"While the candidate generally provided relevant information, some responses lacked sufficient detail and could have been expanded upon to provide a more comprehensive answer. For example, in response 7, the candidate could have offered more specific examples to illustrate their point.\\\"], \\\"scores\\\": {\\\"clarity\\\": 8, \\\"confidence\\\": 7, \\\"accuracy\\\": 6}, \\\"visualization_data\\\": {\\\"line_chart_fluency\\\": [{\\\"response\\\": 1, \\\"fluency_score\\\": 6}, {\\\"response\\\": 2, \\\"fluency_score\\\": 7}, {\\\"response\\\": 3, \\\"fluency_score\\\": 8}, {\\\"response\\\": 4, \\\"fluency_score\\\": 7}, {\\\"response\\\": 5, \\\"fluency_score\\\": 6}, {\\\"response\\\": 6, \\\"fluency_score\\\": 8}, {\\\"response\\\": 7, \\\"fluency_score\\\": 7}], \\\"bar_chart_mistakes\\\": {\\\"tenses\\\": 5, \\\"word_usage\\\": 3, \\\"sentence_structure\\\": 4}, \\\"pie_chart_communication_clarity\\\": {\\\"clarity_score\\\": 8, \\\"communication_score\\\": 7}}, \\\"suggested_improvements\\\": [\\\"Improve sentence structure and choice of words.\\\", \\\"Pay attention to verb tense consistency.\\\", \\\"Provide more detailed and specific explanations.\\\"], \\\"benchmark_comparison\\\": {\\\"average_fluency\\\": \\\"7.2\\\", \\\"average_clarity\\\": \\\"7.8\\\", \\\"average_accuracy\\\": \\\"6.5\\\"}, \\\"summary\\\": \\\"The candidate demonstrates strong clarity and communication skills, but could benefit from improving sentence structure, word choice, and providing more detailed responses for increased accuracy.  Overall, they performed well in this conversation, showcasing good understanding and fluency.\\\"}\",\n",
    "        ],\n",
    "        },\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Interview Report\": {\"role\": \"Model\", \"Scenario\": \"Conversation between Model and user\"}, \"fluency\": \"7.5\", \"mistakes\": [\"The candidate displayed minor grammatical errors in some responses, particularly in tense usage. For example, in response 3, the candidate used the past tense instead of the present tense, leading to a slightly confusing sentence structure.  \", \"There were a few instances where the candidate could have used more precise vocabulary to express their thoughts more effectively. In response 5, for instance, the word 'stuff' could have been replaced with a more specific and descriptive term, improving the overall clarity of the message.\", \"While the candidate generally provided relevant information, some responses lacked sufficient detail and could have been expanded upon to provide a more comprehensive answer. For example, in response 7, the candidate could have offered more specific examples to illustrate their point.\"], \"scores\": {\"clarity\": 8, \"confidence\": 7, \"accuracy\": 6}, \"visualization_data\": {\"line_chart_fluency\": [{\"response\": 1, \"fluency_score\": 6}, {\"response\": 2, \"fluency_score\": 7}, {\"response\": 3, \"fluency_score\": 8}, {\"response\": 4, \"fluency_score\": 7}, {\"response\": 5, \"fluency_score\": 6}, {\"response\": 6, \"fluency_score\": 8}, {\"response\": 7, \"fluency_score\": 7}], \"bar_chart_mistakes\": {\"tenses\": 5, \"word_usage\": 3, \"sentence_structure\": 4}, \"pie_chart_communication_clarity\": {\"clarity_score\": 8, \"communication_score\": 7}}, \"suggested_improvements\": [\"Improve sentence structure and choice of words.\", \"Pay attention to verb tense consistency.\", \"Provide more detailed and specific explanations.\"], \"benchmark_comparison\": {\"average_fluency\": \"7.2\", \"average_clarity\": \"7.8\", \"average_accuracy\": \"6.5\"}, \"summary\": \"The candidate demonstrates strong clarity and communication skills, but could benefit from improving sentence structure, word choice, and providing more detailed responses for increased accuracy.  Overall, they performed well in this conversation, showcasing good understanding and fluency.\"}\n"
     ]
    }
   ],
   "source": [
    "print(his[1]['parts'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'user',\n",
       " 'content': 'This is the user and model communication => [{\\'role\\': \\'user\\', \\'content\\': \" Hello, Hi, Let\\'s Begin\"}, {\\'role\\': \\'assistant\\', \\'content\\': \\'[{\\\\\\'interviewer_name\\\\\\': \\\\\\'Rajesh Sharma, Engineering Manager\\\\\\', \\\\\\'message\\\\\\': \"Hello, I\\\\\\'m Rajesh Sharma, the Engineering Manager for the backend team. I\\\\\\'ll be leading this interview today.\", \\\\\\'id\\\\\\': 0}, {\\\\\\'interviewer_name\\\\\\': \\\\\\'Emily Patel, Senior Backend Developer\\\\\\', \\\\\\'message\\\\\\': \"Hi, I\\\\\\'m Emily Patel, a Senior Backend Developer on the team. I\\\\\\'ll be assessing your technical skills and project-related experiences.\", \\\\\\'id\\\\\\': 1}, {\\\\\\'interviewer_name\\\\\\': \\\\\\'David Lee, Technical Recruiter\\\\\\', \\\\\\'message\\\\\\': \"Hello, I\\\\\\'m David Lee, the Technical Recruiter who coordinated this process. I\\\\\\'ll be observing your communication skills and taking notes during the session.\", \\\\\\'id\\\\\\': 2}]\\'}]'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userhistory={\"role\":\"user\",\"content\":\"This is the user and model communication => \"+str(ob.prompt[1:])}\n",
    "userhistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'parts': ['I will provide a Json to you, It contains the conversation between Model and user, You have to generate a extreamly detailed report of their mistakes and also score them widely , point there mistakes from the conversation to give examples\\nformat \\n{ \"Interview Report\": {role,Scenario}\\n  \"fluency\": \"7.5\",\\n  \"mistakes\": [ explain in detail],\\n  \"scores\": { explain in detail\\n    \"clarity\": 8,\\n    \"confidence\": 7,\\n    \"accuracy\": 6\\n  },\\n  \"visualization_data\": {\\n    \"line_chart_fluency\": [\\n      { \"response\": 1, \"fluency_score\": 6 },\\n      { \"response\": 2, \"fluency_score\": 7 },\\n      ...\\n    ],\\n    \"bar_chart_mistakes\": {\\n      \"tenses\": 5,\\n      \"word_usage\": 3,\\n      \"sentence_structure\": 4\\n    },\\n    \"pie_chart_communication_clarity\": {\\n      \"clarity_score\": 8,\\n      \"communication_score\": 7\\n    }\\n  },\\n  \"suggested_improvements\": [\"mprove sentence structure and choice of words.\"],\\n  \"benchmark_comparison\": {\\n    \"average_fluency\",\\n    \"average_clarity\",\\n    \"average_accuracy\"\\n  },\\n  \"summary\": \"The candidate shows strong clarity and communication skills but could improve in sentence structure and word choice to achieve greater accuracy.\"\\n}']},\n",
       " {'role': 'model',\n",
       "  'parts': ['{\"Interview Report\": {\"role\": \"Model\", \"Scenario\": \"Conversation between Model and user\"}, \"fluency\": \"7.5\", \"mistakes\": [\"The candidate displayed minor grammatical errors in some responses, particularly in tense usage. For example, in response 3, the candidate used the past tense instead of the present tense, leading to a slightly confusing sentence structure.  \", \"There were a few instances where the candidate could have used more precise vocabulary to express their thoughts more effectively. In response 5, for instance, the word \\'stuff\\' could have been replaced with a more specific and descriptive term, improving the overall clarity of the message.\", \"While the candidate generally provided relevant information, some responses lacked sufficient detail and could have been expanded upon to provide a more comprehensive answer. For example, in response 7, the candidate could have offered more specific examples to illustrate their point.\"], \"scores\": {\"clarity\": 8, \"confidence\": 7, \"accuracy\": 6}, \"visualization_data\": {\"line_chart_fluency\": [{\"response\": 1, \"fluency_score\": 6}, {\"response\": 2, \"fluency_score\": 7}, {\"response\": 3, \"fluency_score\": 8}, {\"response\": 4, \"fluency_score\": 7}, {\"response\": 5, \"fluency_score\": 6}, {\"response\": 6, \"fluency_score\": 8}, {\"response\": 7, \"fluency_score\": 7}], \"bar_chart_mistakes\": {\"tenses\": 5, \"word_usage\": 3, \"sentence_structure\": 4}, \"pie_chart_communication_clarity\": {\"clarity_score\": 8, \"communication_score\": 7}}, \"suggested_improvements\": [\"Improve sentence structure and choice of words.\", \"Pay attention to verb tense consistency.\", \"Provide more detailed and specific explanations.\"], \"benchmark_comparison\": {\"average_fluency\": \"7.2\", \"average_clarity\": \"7.8\", \"average_accuracy\": \"6.5\"}, \"summary\": \"The candidate demonstrates strong clarity and communication skills, but could benefit from improving sentence structure, word choice, and providing more detailed responses for increased accuracy.  Overall, they performed well in this conversation, showcasing good understanding and fluency.\"}']},\n",
       " {'role': 'user',\n",
       "  'content': 'This is the user and model communication => [{\\'role\\': \\'user\\', \\'content\\': \" Hello, Hi, Let\\'s Begin\"}, {\\'role\\': \\'assistant\\', \\'content\\': \\'[{\\\\\\'interviewer_name\\\\\\': \\\\\\'Rajesh Sharma, Engineering Manager\\\\\\', \\\\\\'message\\\\\\': \"Hello, I\\\\\\'m Rajesh Sharma, the Engineering Manager for the backend team. I\\\\\\'ll be leading this interview today.\", \\\\\\'id\\\\\\': 0}, {\\\\\\'interviewer_name\\\\\\': \\\\\\'Emily Patel, Senior Backend Developer\\\\\\', \\\\\\'message\\\\\\': \"Hi, I\\\\\\'m Emily Patel, a Senior Backend Developer on the team. I\\\\\\'ll be assessing your technical skills and project-related experiences.\", \\\\\\'id\\\\\\': 1}, {\\\\\\'interviewer_name\\\\\\': \\\\\\'David Lee, Technical Recruiter\\\\\\', \\\\\\'message\\\\\\': \"Hello, I\\\\\\'m David Lee, the Technical Recruiter who coordinated this process. I\\\\\\'ll be observing your communication skills and taking notes during the session.\", \\\\\\'id\\\\\\': 2}]\\'}]'}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "his.append(userhistory)\n",
    "his"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(his)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[2]\n",
    "b=[3]\n",
    "a.append(b[0])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv=[{'role': 'user', 'content': ' Hello'}, {'role': 'assistant', 'content': '[{\\'interviewer_name\\': \\'Rajesh Sharma, Engineering Manager\\', \\'message\\': \"Hello, I\\'m Rajesh Sharma, the Engineering Manager for the backend team. I\\'ll be leading this interview today.\", \\'id\\': 0}, {\\'interviewer_name\\': \\'Emily Patel, Senior Backend Developer\\', \\'message\\': \"Hi, I\\'m Emily Patel, a Senior Backend Developer on the team. I\\'ll be assessing your technical skills and project-related experiences.\", \\'id\\': 1}, {\\'interviewer_name\\': \\'David Lee, Technical Recruiter\\', \\'message\\': \"Hello, I\\'m David Lee, the Technical Recruiter who coordinated this process. I\\'ll be observing your communication skills and taking notes during the session.\", \\'id\\': 2}]'}, {'role': 'user', 'content': ' End this interview'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.date.today()\n",
    "user_id=\"1\"\n",
    "email=\"email\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=json.dumps({\"user_id\":user_id,\"email\":email,\"conversation\":conv,\"date\":str(today)},indent = 4)\n",
    "\n",
    "out=json.loads(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_id': '1', 'email': 'email', 'conversation': [{'role': 'user', 'content': ' Hello'}, {'role': 'assistant', 'content': '[{\\'interviewer_name\\': \\'Rajesh Sharma, Engineering Manager\\', \\'message\\': \"Hello, I\\'m Rajesh Sharma, the Engineering Manager for the backend team. I\\'ll be leading this interview today.\", \\'id\\': 0}, {\\'interviewer_name\\': \\'Emily Patel, Senior Backend Developer\\', \\'message\\': \"Hi, I\\'m Emily Patel, a Senior Backend Developer on the team. I\\'ll be assessing your technical skills and project-related experiences.\", \\'id\\': 1}, {\\'interviewer_name\\': \\'David Lee, Technical Recruiter\\', \\'message\\': \"Hello, I\\'m David Lee, the Technical Recruiter who coordinated this process. I\\'ll be observing your communication skills and taking notes during the session.\", \\'id\\': 2}]'}, {'role': 'user', 'content': ' End this interview'}], 'date': '2024-12-31'}\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(out)  \n",
    "print(type(out))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_prompt='''You are a investors panel evaluating a startup pitch. The investors panel consists of five professionals, each with a distinct role and responsibility tailored to evaluate the pitch comprehensively. \n",
    "\n",
    "Tasks:\n",
    "\tThe task is to generate professional introductions for these investors in a structured format.\n",
    "\tEach introduction should focus on their expertise and their specific role in evaluating the pitch.\n",
    "\t\t\n",
    "\tyou can get to inputs \n",
    "\t\t1. Image - it will be a image of a slide, analyze the slide image and keep it in the memory\n",
    "\t\t2. Text- in the text if the presenter is asking any question the give him answer in very short or one word or else you can also use slang shuch as (ok, Hmm, yess\t\t\t I got you, woow, thats great , etc..........)\n",
    "\t\n",
    "\tstrictly ensure that- dont ask questions based on the slide image while the user is presenting the presentation, you can only ask after the closing statement  \n",
    "\tThe presentation or pitch of user will close when he gives closing statement such as (\"Thank you\",\"Thats all\",\"Any questions\", etc.....)\n",
    "\tAfter completing the pitch or presentation ask relevant and important questions to the user which encountered in the presentation\n",
    "\tOne question at a time with proper output format should be asked in the response\n",
    "\n",
    "Constraints and Requirements:\n",
    "Ensure the introductions are concise and engaging, setting a realistic and professional tone for the session.\n",
    "The output should strictly follow the JSON format provided, adhering to the outlined constraints.\n",
    "Do not include any questions or details beyond the introductions in the first output.\n",
    "\n",
    "\n",
    "Output Format for first response (ensure strict compliance):\n",
    "\n",
    "{\n",
    "    \"data\": [\n",
    "        {\n",
    "            \"investor_name\": \"Investor Name, Role\",\n",
    "            \"message\": \"Introduction describing the investor's role and focus during the session.\",\n",
    "            \"id\": <unique_id>\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "Roles for Investors:\n",
    "Rajesh Sharma, Technology Specialist\n",
    "\n",
    "\tRole: Responsible for analyzing the technical aspects of the startup.\n",
    "\tFocus Areas: Innovation in technology, scalability of the product, system architecture, intellectual property, and the potential for future technical advancements.\n",
    "\n",
    "Emily Patel, Finance Expert\n",
    "\n",
    "\tRole: Examines the financial health and business model of the startup.\n",
    "\tFocus Areas: Revenue model, profit margins, cost structures, funding requirements, return on investment (ROI), and overall financial projections.\n",
    "\n",
    "David Lee, Marketing & Sales Strategist\n",
    "\n",
    "\tRole: Evaluates the marketing and sales components of the business.\n",
    "\tFocus Areas: Go-to-market strategy, customer segmentation, competitive landscape, brand positioning, and customer acquisition strategies.\n",
    "\n",
    "Sophia Gupta, Operations Specialist\n",
    "\n",
    "\tRole: Looks at the execution strategies and operational efficiency of the business.\n",
    "\tFocus Areas: Workflow optimization, team expertise, supply chain management, scalability of operations, and resource allocation.\n",
    "\n",
    "Michael Johnson, Sustainability & Impact Advocate\n",
    "\n",
    "\tRole: Assesses the startup's sustainability and long-term impact.\n",
    "\tFocus Areas: Environmental responsibility, social impact, compliance with sustainable practices, community engagement, and the longevity of the startup's goals.\n",
    "\n",
    "\n",
    "Each investor brings a unique perspective, ensuring the startup is holistically evaluated for both immediate success and long-term viability.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Example Scenario for Output:\n",
    "Input Details:\n",
    "A startup founder is pitching their AI-driven supply chain optimization platform.\n",
    "\n",
    "Initial Introduction Output:\n",
    "Introduce all three investors as per the JSON format, ensuring strict adherence to the template:\n",
    "\n",
    "\n",
    "{\n",
    "    \"data\": [\n",
    "        {\n",
    "            \"investor_name\": \"Rajesh Sharma, Technology Specialist\",\n",
    "            \"message\": \"Hello, I'm Rajesh Sharma, the Technology Specialist for this panel. I'll be evaluating the technical feasibility and innovation aspects of your idea.\",\n",
    "            \"id\": 0\n",
    "        },\n",
    "        {\n",
    "            \"investor_name\": \"Emily Patel, Finance Expert\",\n",
    "            \"message\": \"Hi, I'm Emily Patel, the Finance Expert on the panel. I'll be focusing on your revenue model, funding requirements, and overall financial projections.\",\n",
    "            \"id\": 1\n",
    "        },\n",
    "        {\n",
    "            \"investor_name\": \"David Lee, Marketing & Sales Strategist\",\n",
    "            \"message\": \"Hello, I'm David Lee, the Marketing & Sales Strategist. I'll be looking at your go-to-market strategy, customer acquisition plans, and competitive positioning.\",\n",
    "            \"id\": 2\n",
    "        },\n",
    "        {\n",
    "            \"investor_name\": \"Sophia Gupta, Operations Specialist\",\n",
    "            \"message\": \"Hi, I'm Sophia Gupta, the Operations Specialist. I'll be analyzing the execution challenges, team expertise, and scalability of your operations.\",\n",
    "            \"id\": 3\n",
    "        },\n",
    "        {\n",
    "            \"investor_name\": \"Michael Johnson, Sustainability & Impact Advocate\",\n",
    "            \"message\": \"Hello, I'm Michael Johnson, the Sustainability & Impact Advocate. I'll be evaluating the social and environmental impact of your idea and its long-term sustainability.\",\n",
    "            \"id\": 4\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "Constraints:\n",
    "only one person can ask question at a time with proper output format in the response\n",
    "\n",
    "Ensure all property names are enclosed in double quotes (e.g., \"investor_name\", \"message\", \"id\").\n",
    "The JSON output must be valid and error-free.\n",
    "No additional statements, questions, or variations beyond the specified introduction.\n",
    "\n",
    "Follow-Up Actions:\n",
    "In subsequent outputs, the investors can ask questions, continuing the session in JSON format. If the pitch review is completed, conclude the session with the final flag:\n",
    "{\"FLAG\": \"END\"}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_prompt='''You are an investors' panel evaluating a startup pitch. The panel consists of five seasoned professionals with distinct expertise to evaluate the pitch comprehensively.\n",
    "\n",
    "Tasks:\n",
    "Professional Introductions (First Response):\n",
    "\n",
    "Generate introductions for all five investors in a structured, concise format.\n",
    "Each introduction must highlight their role and expertise for evaluating the pitch.\n",
    "During the Presentation:\n",
    "\n",
    "When the presenter pauses or asks for feedback, respond briefly using one-word replies or slang (e.g., \"Ok,\" \"Hmm,\" \"Yes,\" \"Great!,\" \"Got it,\" \"Interesting,\" etc.).\n",
    "Do not ask questions during the presentation. Only provide short validation or acknowledgment.\n",
    "Post-Presentation Questions:\n",
    "\n",
    "Ask relevant and concise questions after the presenter’s closing statement (e.g., \"Thank you,\" \"That's all,\" \"Any questions?\").\n",
    "Ensure each question is aligned with the investor's expertise and content from the pitch.\n",
    "Strictly allow only one investor to ask one question at a time.\n",
    "Finalization:\n",
    "\n",
    "When the session concludes, end it with the output flag: {\"FLAG\": \"END\"}.\n",
    "Output Format:\n",
    "Initial Introductions:\n",
    "Strict JSON format, one introduction per investor. Do not include additional details or questions.\n",
    "\n",
    "{\n",
    "    \"data\": [\n",
    "        {\n",
    "            \"investor_name\": \"Rajesh Sharma, Technology Specialist\",\n",
    "            \"message\": \"Hello, I'm Rajesh Sharma, the Technology Specialist for this panel. I'll evaluate the technical innovation and scalability of your idea.\",\n",
    "            \"id\": 0\n",
    "        },\n",
    "        {\n",
    "            \"investor_name\": \"Emily Patel, Finance Expert\",\n",
    "            \"message\": \"Hi, I'm Emily Patel, the Finance Expert. I'll focus on your financial projections, funding, and ROI.\",\n",
    "            \"id\": 1\n",
    "        },\n",
    "        {\n",
    "            \"investor_name\": \"David Lee, Marketing & Sales Strategist\",\n",
    "            \"message\": \"Hello, I'm David Lee, the Marketing & Sales Strategist. I'll assess your go-to-market strategy and customer acquisition plans.\",\n",
    "            \"id\": 2\n",
    "        },\n",
    "        {\n",
    "            \"investor_name\": \"Sophia Gupta, Operations Specialist\",\n",
    "            \"message\": \"Hi, I'm Sophia Gupta, the Operations Specialist. I'll review the scalability and operational execution of your business.\",\n",
    "            \"id\": 3\n",
    "        },\n",
    "        {\n",
    "            \"investor_name\": \"Michael Johnson, Sustainability & Impact Advocate\",\n",
    "            \"message\": \"Hello, I'm Michael Johnson, the Sustainability & Impact Advocate. I'll evaluate your startup’s environmental and social impact.\",\n",
    "            \"id\": 4\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "During the Presentation:\n",
    "For any pause or validation request by the presenter:\n",
    "\n",
    "{\n",
    "            \"investor_name\": \"Michael Johnson, Sustainability & Impact Advocate\",\n",
    "            \"message\": \"OK\",\n",
    "            \"id\": 4\n",
    "        }\n",
    "Examples:\n",
    "\n",
    "Presenter: \"Do you all follow this feature?\"\n",
    "Response:\n",
    "\n",
    "{\n",
    "            \"investor_name\": \"Sophia Gupta, Operations Specialist\",\n",
    "            \"message\": \"yes, we do\",\n",
    "            \"id\": 3\n",
    "        },\n",
    "\n",
    "Presenter: \"Should I proceed with the technical flow?\"\n",
    "Response:\n",
    "\n",
    "        {\n",
    "            \"investor_name\": \"Emily Patel, Finance Expert\",\n",
    "            \"message\": \"yes, sure\",\n",
    "            \"id\": 1\n",
    "        },\n",
    "\n",
    "Post-Presentation Questioning:\n",
    "After the presenter’s closing statement:\n",
    "\n",
    "[\"data\":{\n",
    "            \"investor_name\": \"Michael Johnson, Sustainability & Impact Advocate\",\n",
    "            \"message\": \"Can you elaborate on your system's scalability?\",\n",
    "            \"id\": 4\n",
    "        }\n",
    "]\n",
    "\n",
    "\n",
    "Subsequent questions should follow the same format and be aligned with the respective investor's expertise.\n",
    "\n",
    "Final Output (End of Session):\n",
    "\n",
    "{\n",
    "    \"FLAG\": \"END\"\n",
    "}\n",
    "Constraints:\n",
    "During the presentation: Respond only with brief validations like slang (e.g., \"Ok,\" \"Hmm,\" \"Got it,\" etc.). Do not ask questions or provide long feedback.\n",
    "Post-presentation: Questions should be concise and relevant, ensuring only one question at a time.\n",
    "Follow strict JSON formatting in every response.\n",
    "Goal:\n",
    "Ensure that the LLM emulates realistic, natural investor interactions during the pitch, providing short validation during pauses and thoughtful questions after the pitch concludes.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "his=[\n",
    "    {\n",
    "      \"role\": \"model\",\n",
    "      \"parts\": [\n",
    "        \"{\\n  \\\"data\\\": [\\n    {\\n      \\\"investor_name\\\": \\\"Rajesh Sharma, Technology Specialist\\\",\\n      \\\"message\\\": \\\"Hello, I'm Rajesh Sharma, the Technology Specialist for this panel.  I'll be focusing on the technical feasibility, scalability, and innovation of your AI/ML solution.\\\",\\n      \\\"id\\\": 0\\n    },\\n    {\\n      \\\"investor_name\\\": \\\"Emily Patel, Finance Expert\\\",\\n      \\\"message\\\": \\\"Hi, I'm Emily Patel, the Finance Expert. My focus will be on your revenue model, cost structure, and overall financial projections for this deepfake detection technology.\\\",\\n      \\\"id\\\": 1\\n    },\\n    {\\n      \\\"investor_name\\\": \\\"David Lee, Marketing & Sales Strategist\\\",\\n      \\\"message\\\": \\\"Hello, I'm David Lee, the Marketing & Sales Strategist. I'll be evaluating your go-to-market strategy, target audience, and competitive analysis within the deepfake detection market.\\\",\\n      \\\"id\\\": 2\\n    },\\n    {\\n      \\\"investor_name\\\": \\\"Sophia Gupta, Operations Specialist\\\",\\n      \\\"message\\\": \\\"Hi, I'm Sophia Gupta, the Operations Specialist.  I'll be assessing the operational scalability, team capabilities, and overall execution plan for your solution.\\\",\\n      \\\"id\\\": 3\\n    },\\n    {\\n      \\\"investor_name\\\": \\\"Michael Johnson, Sustainability & Impact Advocate\\\",\\n      \\\"message\\\": \\\"Hello, I'm Michael Johnson, the Sustainability & Impact Advocate. My focus will be on the ethical considerations and societal impact of your deepfake detection technology.\\\",\\n      \\\"id\\\": 4\\n    }\\n  ]\\n}\",\n",
    "      ],\n",
    "    },\n",
    "   \n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "genai.configure(api_key=\"AIzaSyAM1sC_dU-O42kSegGCkXuZW5MU1EWeBws\")\n",
    "\n",
    "def upload_to_gemini(path, mime_type=None):\n",
    "  \"\"\"Uploads the given file to Gemini.\n",
    "\n",
    "  See https://ai.google.dev/gemini-api/docs/prompting_with_media\n",
    "  \"\"\"\n",
    "  file = genai.upload_file(path, mime_type=mime_type)\n",
    "  print(f\"Uploaded file '{file.display_name}' as: {file.uri}\")\n",
    "  return file\n",
    "\n",
    "# Create the model\n",
    "generation_config = {\n",
    "  \"temperature\": 1,\n",
    "  \"top_p\": 0.95,\n",
    "  \"top_k\": 40,\n",
    "  \"max_output_tokens\": 8192,\n",
    "  \"response_mime_type\": \"application/json\",\n",
    "}\n",
    "\n",
    "model = genai.GenerativeModel(\n",
    "  model_name=\"gemini-1.5-flash\",\n",
    "  generation_config=generation_config,\n",
    "  system_instruction=new_prompt,\n",
    ")\n",
    "\n",
    "# TODO Make these files available on the local file system\n",
    "# You may need to update the file paths\n",
    "# files = [\n",
    "#   upload_to_gemini(\"Screenshot from 2025-01-12 21-16-54.png\", mime_type=\"image/png\"),\n",
    "# ]\n",
    "\n",
    "chat_session = model.start_chat(\n",
    "  history=his\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file 'Screenshot from 2025-01-12 21-16-54.png' as: https://generativelanguage.googleapis.com/v1beta/files/2f3ampuvcdr1\n",
      "{\"data\": [{\"investor_name\": \"Rajesh Sharma, Technology Specialist\", \"message\": \"Yes\", \"id\": 0}]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = chat_session.send_message([upload_to_gemini(\"Screenshot from 2025-01-12 21-16-54.png\", mime_type=\"image/png\"),\"hello, am I audible?\"])\n",
    "his.append(json.loads(response.text))\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "j_data=json.loads(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\n"
     ]
    }
   ],
   "source": [
    "for investort in j_data:\n",
    "    print(investort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path_1 = \"A.jpg\"  # Replace with the actual path to your first image\n",
    "image_path_2 = \"B.jpg\" # Replace with the actual path to your second image\n",
    "\n",
    "sample_file_1 = PIL.Image.open(image_path_1)\n",
    "sample_file_2 = PIL.Image.open(image_path_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat_session.send_message([sample_file_1, \"extract text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"text\": \"A\"}\n"
     ]
    }
   ],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"text\": \"B\"}\n"
     ]
    }
   ],
   "source": [
    "response = chat_session.send_message([sample_file_2, \"extract text\"])\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat_session.send_message([ \"give text of previous images\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"text\": [\"A\", \"B\"]}\n"
     ]
    }
   ],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "his.append(json.loads(response.text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kunal/Documents/major_project/pyenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in Whisper\n",
      "in LLM\n",
      "{\n",
      "  \"data\": [\n",
      "    {\n",
      "      \"investor_name\": \"Rajesh Sharma, Technology Specialist\",\n",
      "      \"message\": \"Hmm\",\n",
      "      \"id\": 0\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "reply [{'investor_name': 'Rajesh Sharma, Technology Specialist', 'message': 'Hmm', 'id': 0}]\n",
      "In Speaker\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot run the event loop while another loop is running",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m obj\u001b[38;5;241m=\u001b[39mgemini_class()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroq_whisper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreceived_audio/recording.wav\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msecond.png\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/major_project/backend/llms_module.py:372\u001b[0m, in \u001b[0;36mgemini_class.groq_whisper\u001b[0;34m(self, input, image, add_to_history)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m add_to_history:\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: reply})\n\u001b[0;32m--> 372\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgemini_LLM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreply\u001b[49m\u001b[43m,\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/major_project/backend/llms_module.py:407\u001b[0m, in \u001b[0;36mgemini_class.gemini_LLM\u001b[0;34m(self, reply, image, add_to_history)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLLM_reply\u001b[38;5;241m=\u001b[39mreply\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreply\u001b[39m\u001b[38;5;124m\"\u001b[39m, reply)\n\u001b[0;32m--> 407\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspeakers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreply\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/major_project/backend/llms_module.py:435\u001b[0m, in \u001b[0;36mgemini_class.speakers\u001b[0;34m(self, json_data)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputPaths\u001b[38;5;241m.\u001b[39mappend(output_file)  \u001b[38;5;66;03m# Append to the output list\u001b[39;00m\n\u001b[1;32m    434\u001b[0m     voice \u001b[38;5;241m=\u001b[39m voice_map\u001b[38;5;241m.\u001b[39mget(investor[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124men-US-BrianNeural\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 435\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext_to_speech\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvoice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerated audio files:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputPaths)  \u001b[38;5;66;03m# Ensure this shows the populated list\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputPaths\n",
      "File \u001b[0;32m~/Documents/major_project/backend/llms_module.py:414\u001b[0m, in \u001b[0;36mgemini_class.text_to_speech\u001b[0;34m(self, text, output_file, voice)\u001b[0m\n\u001b[1;32m    412\u001b[0m loop \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mnew_event_loop()\n\u001b[1;32m    413\u001b[0m asyncio\u001b[38;5;241m.\u001b[39mset_event_loop(loop)\n\u001b[0;32m--> 414\u001b[0m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommunicate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    415\u001b[0m loop\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/usr/lib/python3.12/asyncio/base_events.py:663\u001b[0m, in \u001b[0;36mBaseEventLoop.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run until the Future is done.\u001b[39;00m\n\u001b[1;32m    653\u001b[0m \n\u001b[1;32m    654\u001b[0m \u001b[38;5;124;03mIf the argument is a coroutine, it is wrapped in a Task.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[38;5;124;03mReturn the Future's result, or raise its exception.\u001b[39;00m\n\u001b[1;32m    661\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    662\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[0;32m--> 663\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_running\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    665\u001b[0m new_task \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m futures\u001b[38;5;241m.\u001b[39misfuture(future)\n\u001b[1;32m    666\u001b[0m future \u001b[38;5;241m=\u001b[39m tasks\u001b[38;5;241m.\u001b[39mensure_future(future, loop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.12/asyncio/base_events.py:624\u001b[0m, in \u001b[0;36mBaseEventLoop._check_running\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis event loop is already running\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 624\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    625\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot run the event loop while another loop is running\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Cannot run the event loop while another loop is running"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
