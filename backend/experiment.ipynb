{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kunal/Documents/speech project/improveai/env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyC0O4dCvtLxrXg3BMBciSzrXhO3Vkb5Irw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "UPLOAD_FOLDER = 'uploads'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile = genai.upload_file(UPLOAD_FOLDER + \"recorded_audio.mp3\")\n",
    "    \n",
    "# print(f\"{myfile=}\")\n",
    "\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "result = model.generate_content([myfile, \"Transcribthis audio clip, provide only plain text response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello I am Kunal what are you doing there \\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsond=[\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"parts\": [\n",
    "            \"You are the interviewers conducting an interview for a fresher backend developer position. Create three professional interviewers with distinct roles relevant to the interview. Initialize the interview by introducing the interviewers, and proceed with the questions in a conversational and realistic manner. Start with an introduction of all interviewers for example-  [\\n{\\n  \\\"interviewer_name\\\": \\\"Rajesh Sharma, Engineering Manager\\\",\\n  \\\"message\\\": \\\"Hello everyone, I'm Rajesh Sharma, the Engineering Manager for the backend team. I'll be leading this interview today.\\\",\\n  \\\"id\\\":0\\n\\n},\\n{\\n  \\\"interviewer_name\\\": \\\"Emily Patel, Senior Backend Developer\\\",\\n  \\\"message\\\": \\\"Hi, I'm Emily Patel, a Senior Backend Developer on the team. I'll be evaluating your technical skills and experience.\\\",\\n  \\\"id\\\":1\\n},\\n{\\n  \\\"interviewer_name\\\": \\\"David Lee, Technical Recruiter\\\",\\n  \\\"message\\\": \\\"Hello, I'm David Lee, the Technical Recruiter who worked with you to schedule this interview. I'll be taking notes and ensuring the process runs smoothly. Are You comfortable with the interview?\\\",\\n  \\\"id\\\":2\\n},\\n]\\n\\n\\n\\nProvide the output in the following JSON format\\n\\ngive output like - output={\\\"interviewer_name\\\": \\\"Rajesh Sharma, Engineering Manager\\\",\\\"message\\\": \\\"Hello\\\",\\\"id\\\":0}\\n\\nif want to pass the conversation to another interviewer also include the reply of the another interviewer\\n\\ntailor is for user preference - {'role': 'Software Developer', 'field': 'Python,JS', 'experience': '0-1', 'scenario': 'interview', 'purpose': 'Job', 'toimprove': ['technical', 'communication']}\"\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "jsond.append({\n",
    "        \"role\": \"bot\",\n",
    "        \"message\": \"response\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'parts': ['You are the interviewers conducting an interview for a fresher backend developer position. Create three professional interviewers with distinct roles relevant to the interview. Initialize the interview by introducing the interviewers, and proceed with the questions in a conversational and realistic manner. Start with an introduction of all interviewers for example-  [\\n{\\n  \"interviewer_name\": \"Rajesh Sharma, Engineering Manager\",\\n  \"message\": \"Hello everyone, I\\'m Rajesh Sharma, the Engineering Manager for the backend team. I\\'ll be leading this interview today.\",\\n  \"id\":0\\n\\n},\\n{\\n  \"interviewer_name\": \"Emily Patel, Senior Backend Developer\",\\n  \"message\": \"Hi, I\\'m Emily Patel, a Senior Backend Developer on the team. I\\'ll be evaluating your technical skills and experience.\",\\n  \"id\":1\\n},\\n{\\n  \"interviewer_name\": \"David Lee, Technical Recruiter\",\\n  \"message\": \"Hello, I\\'m David Lee, the Technical Recruiter who worked with you to schedule this interview. I\\'ll be taking notes and ensuring the process runs smoothly. Are You comfortable with the interview?\",\\n  \"id\":2\\n},\\n]\\n\\n\\n\\nProvide the output in the following JSON format\\n\\ngive output like - output={\"interviewer_name\": \"Rajesh Sharma, Engineering Manager\",\"message\": \"Hello\",\"id\":0}\\n\\nif want to pass the conversation to another interviewer also include the reply of the another interviewer\\n\\ntailor is for user preference - {\\'role\\': \\'Software Developer\\', \\'field\\': \\'Python,JS\\', \\'experience\\': \\'0-1\\', \\'scenario\\': \\'interview\\', \\'purpose\\': \\'Job\\', \\'toimprove\\': [\\'technical\\', \\'communication\\']}']},\n",
       " {'role': 'bot', 'message': 'response'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "HISTORY_FILE_PATH = 'session_data.json'\n",
    "import os,json\n",
    "def load_history():\n",
    "    \"\"\"Load conversation history from a JSON file.\"\"\"\n",
    "    if os.path.exists(HISTORY_FILE_PATH):\n",
    "        with open(HISTORY_FILE_PATH, 'r') as f:\n",
    "            return json.load(f)\n",
    "    return []  # Ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'message': ['You are the interviewers conducting an interview for a fresher backend developer position. Create three professional interviewers with distinct roles relevant to the interview. Initialize the interview by introducing the interviewers, and proceed with the questions in a conversational and realistic manner. Start with an introduction of all interviewers for example-  [\\n{\\n  \"interviewer_name\": \"Rajesh Sharma, Engineering Manager\",\\n  \"message\": \"Hello everyone, I\\'m Rajesh Sharma, the Engineering Manager for the backend team. I\\'ll be leading this interview today.\",\\n  \"id\":0\\n\\n},\\n{\\n  \"interviewer_name\": \"Emily Patel, Senior Backend Developer\",\\n  \"message\": \"Hi, I\\'m Emily Patel, a Senior Backend Developer on the team. I\\'ll be evaluating your technical skills and experience.\",\\n  \"id\":1\\n},\\n{\\n  \"interviewer_name\": \"David Lee, Technical Recruiter\",\\n  \"message\": \"Hello, I\\'m David Lee, the Technical Recruiter who worked with you to schedule this interview. I\\'ll be taking notes and ensuring the process runs smoothly. Are You comfortable with the interview?\",\\n  \"id\":2\\n},\\n]\\n\\n\\n\\nProvide the output in the following JSON format\\n\\ngive output like - output={\"interviewer_name\": \"Rajesh Sharma, Engineering Manager\",\"message\": \"Hello\",\"id\":0}\\n\\nif want to pass the conversation to another interviewer also include the reply of the another interviewer\\n\\ntailor is for user preference - {\\'role\\': \\'Software Developer\\', \\'field\\': \\'Python\\', \\'experience\\': \\'0-1\\', \\'scenario\\': \\'interview\\', \\'purpose\\': \\'Job\\', \\'toimprove\\': [\\'technical\\', \\'communication\\']}']},\n",
       " {'role': 'user', 'message': 'Hello'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h=load_history()\n",
    "type(h)\n",
    "h.append({\n",
    "    \"role\": \"user\",\n",
    "    \"message\": \"Hello\"\n",
    "})\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'interviewer_name': 'Rajesh Sharma, Engineering Manager',\n",
       "  'message': \"Hello everyone, I'm Rajesh Sharma, the Engineering Manager for the backend team. I'll be leading this interview today.\",\n",
       "  'id': 0},\n",
       " {'interviewer_name': 'Emily Patel, Senior Backend Developer',\n",
       "  'message': \"Hi, I'm Emily Patel, a Senior Backend Developer on the team. I'll be evaluating your technical skills and experience.\",\n",
       "  'id': 1},\n",
       " {'interviewer_name': 'David Lee, Technical Recruiter',\n",
       "  'message': \"Hello, I'm David Lee, the Technical Recruiter who worked with you to schedule this interview. I'll be taking notes and ensuring the process runs smoothly. Are you comfortable with the interview?\",\n",
       "  'id': 2}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d=\"[{\\\"interviewer_name\\\": \\\"Rajesh Sharma, Engineering Manager\\\", \\\"message\\\": \\\"Hello everyone, I'm Rajesh Sharma, the Engineering Manager for the backend team. I'll be leading this interview today.\\\", \\\"id\\\": 0}, {\\\"interviewer_name\\\": \\\"Emily Patel, Senior Backend Developer\\\", \\\"message\\\": \\\"Hi, I'm Emily Patel, a Senior Backend Developer on the team. I'll be evaluating your technical skills and experience.\\\", \\\"id\\\": 1}, {\\\"interviewer_name\\\": \\\"David Lee, Technical Recruiter\\\", \\\"message\\\": \\\"Hello, I'm David Lee, the Technical Recruiter who worked with you to schedule this interview. I'll be taking notes and ensuring the process runs smoothly. Are you comfortable with the interview?\\\", \\\"id\\\": 2}]\\n\"\n",
    "json_data = json.loads(d)\n",
    "json_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import edge_tts\n",
    "import asyncio\n",
    "\n",
    "async def text_to_speech(text, output_file, voice):\n",
    "    \"\"\"Converts text to speech using edge-tts and saves the audio as an MP3 file.\"\"\"\n",
    "    \n",
    "    # Initialize the TTS service with the provided voice\n",
    "    communicate = edge_tts.Communicate(text, voice)\n",
    "    \n",
    "    # Convert the text to speech and save it to the output file\n",
    "    await communicate.save(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def speakers():\n",
    "    reply_list=[]\n",
    "    for interviewer in json_data:\n",
    "\n",
    "        text=interviewer['message']\n",
    "        id=interviewer['id']\n",
    "        if id==0:\n",
    "            output_file=\"AUDIOS/0.mp3\"\n",
    "            await text_to_speech(text, output_file,voice=\"en-US-BrianNeural\")\n",
    "            reply_list.append(output_file)\n",
    "            \n",
    "\n",
    "        if id==1:\n",
    "            output_file=\"AUDIOS/1.mp3\"\n",
    "            await text_to_speech(text, output_file,voice=\"en-IN-NeerjaExpressiveNeural\")\n",
    "            reply_list.append(output_file)\n",
    "\n",
    "        if id==2:\n",
    "            output_file=\"AUDIOS/2.mp3\"\n",
    "            await text_to_speech(text, output_file,voice=\"en-US-ChristopherNeural\")\n",
    "            reply_list.append(output_file)\n",
    "    return reply_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AUDIOS/0.mp3', 'AUDIOS/1.mp3', 'AUDIOS/2.mp3']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "reply_list = await speakers()\n",
    "print(reply_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "text_to_speech() missing 1 required positional argument: 'voice'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;66;03m# If there's already an event loop running (e.g., in a Jupyter notebook)\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m main()\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m:\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;66;03m# Fallback for environments where asyncio.run() would work (non-notebook)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m         asyncio\u001b[38;5;241m.\u001b[39mrun(main())\n",
      "Cell \u001b[0;32mIn[59], line 10\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m output_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/AUDIOS/output_speech.mp3\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Run the asynchronous text-to-speech task\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[43mtext_to_speech\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: text_to_speech() missing 1 required positional argument: 'voice'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Main function to run the TTS asynchronously\n",
    "async def main():\n",
    "    # Text that you want to convert to speech\n",
    "    text = \"Take your content creation to the next level with our cutting-edge Text-to-Video Converter! Transform your words into stunning, professional-quality videos in just a few clicks.\"\n",
    "    \n",
    "    # Output file path (e.g., an MP3 file)\n",
    "    output_file = \"/AUDIOS/output_speech.mp3\"\n",
    "    \n",
    "    # Run the asynchronous text-to-speech task\n",
    "    await text_to_speech(text, output_file)\n",
    "\n",
    "# Check if running in an event loop\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # If there's already an event loop running (e.g., in a Jupyter notebook)\n",
    "        await main()\n",
    "    except RuntimeError:\n",
    "        # Fallback for environments where asyncio.run() would work (non-notebook)\n",
    "        asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<coroutine object main at 0x7bf9803979f0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "a={'interviewer_name': 'Rajesh Sharma, Engineering Manager', 'message': \"Great! Let's get started.  Since you have 1-2 years of experience, we'd like to understand your experience with Python. Can you tell us about a recent project where you used Python for backend development?\", 'id': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n"
     ]
    }
   ],
   "source": [
    "if type(a) is list:\n",
    "    print(\"yes\")\n",
    "if type(a) is dict:\n",
    "    print(\"no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tmp/hello.txt\", \"w\") as file:\n",
    "    # Write \"Hello\" to the file\n",
    "    file.write(\"Hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hello its v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import threading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "list1=[]\n",
    "\n",
    "def run1(s,e):\n",
    "    for i in range(s,e):\n",
    "        list1.append(i)   \n",
    "\n",
    "        print(i)\n",
    "\n",
    "\n",
    "thread = threading.Thread(target=run1, args=(0,10,))\n",
    "thread.start()\n",
    "\n",
    "thread = threading.Thread(target=run1, args=(10,20,))\n",
    "thread.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedWriter name='recording.wav'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_file = open(\"recording.wav\", \"wb\")\n",
    "audio_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not '_io.BufferedWriter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m audio_np \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrombuffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint16\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: a bytes-like object is required, not '_io.BufferedWriter'"
     ]
    }
   ],
   "source": [
    "audio_np = np.frombuffer(audio_file, dtype=np.int16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faker\n",
      "  Downloading Faker-33.1.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.4 in /home/kunal/Documents/speech project/improveai/env/lib/python3.12/site-packages (from faker) (2.9.0.post0)\n",
      "Requirement already satisfied: typing-extensions in /home/kunal/Documents/speech project/improveai/env/lib/python3.12/site-packages (from faker) (4.12.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/kunal/Documents/speech project/improveai/env/lib/python3.12/site-packages (from python-dateutil>=2.4->faker) (1.16.0)\n",
      "Downloading Faker-33.1.0-py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hInstalling collected packages: faker\n",
      "Successfully installed faker-33.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random number: 5539599\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Generate a random number between 1 and 10 (inclusive)\n",
    "random_number = random.randint(1, 9999999)\n",
    "\n",
    "print(\"Random number:\", random_number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.mp3', '1.mp3', '2.mp3']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# List contents of the current directory\n",
    "path = \"AUDIOS/\"\n",
    "\n",
    "contents = os.listdir(path)\n",
    "contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del arr[:3]\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyaudio\n",
      "  Using cached PyAudio-0.2.14-cp312-cp312-linux_x86_64.whl\n",
      "Installing collected packages: pyaudio\n",
      "Successfully installed pyaudio-0.2.14\n"
     ]
    }
   ],
   "source": [
    "!pip install pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib pcm_dsnoop.c:567:(snd_pcm_dsnoop_open) unable to open slave\n",
      "ALSA lib pcm_dmix.c:1000:(snd_pcm_dmix_open) unable to open slave\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "Cannot connect to server socket err = No such file or directory\n",
      "Cannot connect to server request channel\n",
      "jack server is not running or cannot be started\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
      "Cannot connect to server socket err = No such file or directory\n",
      "Cannot connect to server request channel\n",
      "jack server is not running or cannot be started\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib pcm_a52.c:1001:(_snd_pcm_a52_open) a52 is only for playback\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "ALSA lib pcm_dmix.c:1000:(snd_pcm_dmix_open) unable to open slave\n",
      "Cannot connect to server socket err = No such file or directory\n",
      "Cannot connect to server request channel\n",
      "jack server is not running or cannot be started\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m . . . . . .\u001b[0m\n",
      "\n",
      "\u001b[92m\u001b[0m\n",
      "\n",
      "\u001b[92m\u001b[0m\n",
      "\n",
      "\u001b[92m\u001b[0m\n",
      "\n",
      "\u001b[92m\u001b[0m\n",
      "\n",
      "\u001b[92m\u001b[0m\n",
      "\n",
      "\u001b[92m\u001b[0m\n",
      "\n",
      "\u001b[92m\u001b[0m\n",
      "\n",
      "\u001b[92m\u001b[0m\n",
      "\n",
      "Stopping...\n",
      "LOG: . . . . . .         \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import wave\n",
    "import pyaudio\n",
    "from faster_whisper import WhisperModel\n",
    "\n",
    "# Define colors for terminal output\n",
    "NEON_GREEN = \"\\033[92m\"\n",
    "RESET_COLOR = \"\\033[0m\"\n",
    "\n",
    "def record_chunk(p, stream, file_path, chunk_length=1):\n",
    "    \"\"\"\n",
    "    Records a chunk of audio and saves it to the specified file.\n",
    "\n",
    "    :param p: PyAudio object\n",
    "    :param stream: PyAudio stream object\n",
    "    :param file_path: Path to save the recorded audio\n",
    "    :param chunk_length: Length of the audio chunk in seconds\n",
    "    \"\"\"\n",
    "    frames = []\n",
    "    for _ in range(0, int(16000 / 1024 * chunk_length)):\n",
    "        data = stream.read(1024)\n",
    "        frames.append(data)\n",
    "\n",
    "    wf = wave.open(file_path, 'wb')\n",
    "    wf.setnchannels(1)\n",
    "    wf.setsampwidth(p.get_sample_size(pyaudio.paInt16))\n",
    "    wf.setframerate(16000)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "\n",
    "def transcribe_chunk(model, file_path):\n",
    "    \"\"\"\n",
    "    Transcribes the given audio file using the Whisper model.\n",
    "\n",
    "    :param model: WhisperModel object\n",
    "    :param file_path: Path to the audio file to transcribe\n",
    "    :return: Transcription of the audio file\n",
    "    \"\"\"\n",
    "    segments, _ = model.transcribe(file_path)\n",
    "    return ''.join(segment.text for segment in segments)\n",
    "\n",
    "def main2():\n",
    "    \"\"\"\n",
    "    Main function to record audio in chunks, transcribe it, and accumulate the transcription.\n",
    "    \"\"\"\n",
    "    model_size = \"base.en\"\n",
    "    model = WhisperModel(model_size,  compute_type=\"float32\")\n",
    "\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=pyaudio.paInt16, channels=1, rate=16000, input=True, frames_per_buffer=1024)\n",
    "\n",
    "    accumulated_transcription = \"\"  # Initialize an empty string to accumulate transcriptions\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            chunk_file = \"temp_chunk.wav\"\n",
    "            record_chunk(p, stream, chunk_file)\n",
    "            transcription = transcribe_chunk(model, chunk_file)\n",
    "\n",
    "            print(NEON_GREEN + transcription + RESET_COLOR)\n",
    "            print()\n",
    "            os.remove(chunk_file)\n",
    "\n",
    "            # Append the new transcription to the accumulated transcription\n",
    "            accumulated_transcription += transcription + \" \"\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Stopping...\")\n",
    "\n",
    "        # Write the accumulated transcription to the log file\n",
    "        with open(\"log.txt\", \"w\") as log_file:\n",
    "            log_file.write(accumulated_transcription)\n",
    "\n",
    "    finally:\n",
    "        print(\"LOG:\" + accumulated_transcription)\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "        p.terminate()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main2()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "a=1\n",
    "def add():\n",
    "    global a\n",
    "    a+=1\n",
    "\n",
    "add()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "add()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import edge_tts\n",
    "import asyncio\n",
    "\n",
    "async def text_to_speech(text, output_file, voice):\n",
    "    \"\"\"Converts text to speech using edge-tts and saves the audio as an MP3 file.\"\"\"\n",
    "    \n",
    "    # Initialize the TTS service with the provided voice\n",
    "    communicate = edge_tts.Communicate(text, voice)\n",
    "    \n",
    "    # Convert the text to speech and save it to the output file\n",
    "    await communicate.save(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"We inform you that you've been selected to be one of the talent pool candidates for Artificial Intelligence / Machine Learning, Full stack development, Back end development specialties. New international internship openings will be regularly shared in our private WhatsApp group, and you will have a chance to participate in the interview for 2 months, non-paid, remote, full-time internship conducted by one of the Callus's partner international companies. If you prove yourself to be valuable to the company, you will have a chance to secure a full-time remote paid position at the company at the end of the 2-months internship, with the starting median salary ranging from 50K INR to 100K INR / month.This email is a formal invitation for you to join the selected members-only private WhatsApp group. Stay tuned for the new internship postings.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "await text_to_speech(text=text,output_file=\"1111.mp3\",voice=\"en-US-BrianNeural\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"Artificial Intelligence is the intelligence possessed by the machines under which they can perform various functions with human help. With the help of A.I, machines will be able to learn, solve problems, plan things, think, etc. Artificial Intelligence, for example, is the simulation of human intelligence by machines. In the field of technology, Artificial Intelligence is evolving rapidly day by day and it is believed that in the near future, artificial intelligence is going to change human life very drastically and will most probably end all the crises of the world by sorting out the major problems. Our life in this modern age depends largely on computers. It is almost impossible to think about life without computers. We need computers in everything that we use in our daily lives. So it becomes very important  \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"http://known-smooth-cobra.ngrok-free.app/text-to-speech\"\n",
    "data = {\n",
    "    \"text\": text,\n",
    "    \"voice\": \"en-US-JennyNeural\",\n",
    "    \"output_file\": \"hello.mp3\"\n",
    "}\n",
    "response = requests.post(url, json=data)\n",
    "\n",
    "# Save the returned file\n",
    "with open(\"hello.mp3\", \"wb\") as f:\n",
    "    f.write(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qwertyuiop\n",
      "asdfghjkl\n",
      "zxcvbnm\n"
     ]
    }
   ],
   "source": [
    "keyboard=[\"qwertyuiop\",\"asdfghjkl\",\"zxcvbnm\"]\n",
    "\n",
    "        # for word in words:\n",
    "        #     if ch in lower(word)\n",
    "temp=[]\n",
    "for row in keyboard:\n",
    "    # for word in words:\n",
    "    #     for ch in words:\n",
    "    #         if ch in row[0]:\n",
    "    #             print(ch)\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How's it going? Is there something I can help you with or would you like to chat?\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from together import Together\n",
    "\n",
    "client = Together(api_key=\"0fcde4cd2a6f9e2f7e160b3fe07f4cab323ff83554a0049083578205d4e78cfb\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"meta-llama/Llama-Vision-Free\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"hi\"}],\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"llama-3.2-11b-vision-preview\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \n",
    "            \"content\": \"hi\"\n",
    "        },\n",
    "        \n",
    "    ],\n",
    "           \n",
    "    temperature=1,\n",
    "    max_tokens=1024,\n",
    "    top_p=1,\n",
    "    stream=False,\n",
    "    stop=None,\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Artificial intelligence is the intelligence possessed by the machines under which they can perform various functions with human help. With the help of A.I, machines will be able to learn, solve problems, plan things, think, etc. Artificial intelligence, for example, is the simulation of human intelligence by machines. In the field of technology, artificial intelligence is evolving rapidly day by day and it is believed that in the near future, artificial intelligence is going to change human life very drastically and will most probably end all the crises of the world by sorting out the major problems. Our life in this modern age depends largely on computers. It is almost impossible to think about life without computers. We need computers in everything that we use in our daily lives. So it becomes very important.\n"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "\n",
    "client = Groq(api_key=\"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\")\n",
    "\n",
    "filename = \"hello.mp3\"\n",
    "\n",
    "with open(filename, \"rb\") as file:\n",
    "    transcription = client.audio.transcriptions.create(\n",
    "      file=(filename, file.read()),\n",
    "      model=\"whisper-large-v3-turbo\",\n",
    "      response_format=\"verbose_json\",\n",
    "    )\n",
    "    print(transcription.text)\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are the interview panel conducting an interview for a fresher software developer position. Design three professional interviewers with distinct roles and relevant responsibilities tailored to the job profile. Initialize the interview by introducing each interviewer and proceed with the conversation in a realistic, interactive manner. Use a conversational tone to make the session engaging and authentic.\n",
    "\n",
    "When constructing responses, pass the conversation to another interviewer after each question if context is completed . Avoid including a history of responses in the output. Ensure the output includes the latest question and response, formatted as JSON.\n",
    "\n",
    "Update the interviewer details according to the following user input:\n",
    "User details:\n",
    "{\n",
    "  \"role\": \"Software Developer\",\n",
    "  \"skills\": \"Python\",\n",
    "  \"experience\": \"0-1\",\n",
    "  \"scenario\": \"interview\",\n",
    "  \"purpose\": \"Job Interview\",\n",
    "  \"toimprove\": [\"technical\", \"communication\"]\n",
    "}\n",
    "\n",
    "\n",
    "Output format:\n",
    "{\n",
    "  \"interviewer_name\": \"Rajesh Sharma, Engineering Manager\",\n",
    "  \"message\": \"Hello, I'm Rajesh Sharma, the Engineering Manager for the backend team. I'll be leading this interview today.\",\n",
    "  \"id\": 0\n",
    "}\n",
    "\n",
    "\n",
    "introducion output format:\n",
    "[\n",
    "  {\n",
    "    \"interviewer_name\": \"Rajesh Sharma, Engineering Manager\",\n",
    "    \"message\": \"Hello, I'm Rajesh Sharma, the Engineering Manager for the backend team. I'll be leading this interview today.\",\n",
    "    \"id\": 0\n",
    "  },\n",
    "  {\n",
    "    \"interviewer_name\": \"Emily Patel, Senior Backend Developer\",\n",
    "    \"message\": \"Hi, I'm Emily Patel, a Senior Backend Developer on the team. I'll be assessing your technical skills and project-related experiences.\",\n",
    "    \"id\": 1\n",
    "  },\n",
    "  {\n",
    "    \"interviewer_name\": \"David Lee, Technical Recruiter\",\n",
    "    \"message\": \"Hello, I'm David Lee, the Technical Recruiter who coordinated this process. I'll be observing your communication skills and taking notes during the session.\",\n",
    "    \"id\": 2\n",
    "  }\n",
    "]\n",
    "begin with the introduction of all interviewers as a single output, the first interviewer may start the interview. Each subsequent response should involve a single interviewer, passing the conversation fluidly.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userDetails={\n",
    "  \"role\": \"Software Developer\",\n",
    "  \"skills\": \"Python\",\n",
    "  \"experience\": \"0-1\",\n",
    "  \"scenario\": \"interview\",\n",
    "  \"purpose\": \"Job Interview\",\n",
    "  \"toimprove\": [\"technical\", \"communication\"]\n",
    "}\n",
    "prompt=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are the interview panel conducting an interview for a fresher software developer position. Design three professional interviewers with distinct roles and relevant responsibilities tailored to the job profile. Initialize the interview by introducing each interviewer and proceed with the conversation in a realistic, interactive manner. Use a conversational tone to make the session engaging and authentic.\\n\\nWhen constructing responses, pass the conversation to another interviewer after each question if context is completed . Avoid including a history of responses in the output. Ensure the output includes the latest question and response, formatted as JSON.\\n\\nUpdate the interviewer details according to the following user input:\\nUser details: \"+userDetails+\"Output format:\\n\\\"{\\n  \\\"interviewer_name\\\": \\\"Rajesh Sharma, Engineering Manager\\\",\\n  \\\"message\\\": \\\"Hello, I'm Rajesh Sharma, the Engineering Manager for the backend team. I'll be leading this interview today.\\\",\\n  \\\"id\\\": 0\\n}\\\"\\n\\n\\nintroducion output format:\\n\\\"[\\n  {\\n    \\\"interviewer_name\\\": \\\"Rajesh Sharma, Engineering Manager\\\",\\n    \\\"message\\\": \\\"Hello, I'm Rajesh Sharma, the Engineering Manager for the backend team. I'll be leading this interview today.\\\",\\n    \\\"id\\\": 0\\n  },\\n  {\\n    \\\"interviewer_name\\\": \\\"Emily Patel, Senior Backend Developer\\\",\\n    \\\"message\\\": \\\"Hi, I'm Emily Patel, a Senior Backend Developer on the team. I'll be assessing your technical skills and project-related experiences.\\\",\\n    \\\"id\\\": 1\\n  },\\n  {\\n    \\\"interviewer_name\\\": \\\"David Lee, Technical Recruiter\\\",\\n    \\\"message\\\": \\\"Hello, I'm David Lee, the Technical Recruiter who coordinated this process. I'll be observing your communication skills and taking notes during the session.\\\",\\n    \\\"id\\\": 2\\n  }\\n]\\\"\\nbegin with the introduction of all interviewers as a single output, the first interviewer may start the interview. Each subsequent response should involve a single interviewer, passing the conversation fluidly.\\n\\n\\n\\n\\n\\n\\n\"\n",
    "        },\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt.append({\"role\":\"user\",\"content\":\"hello\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "\n",
    "client = Groq(api_key=\"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\")\n",
    "def gorq_LLM(prompt,add_to_history=True):\n",
    "    completion = client.chat.completions.create(\n",
    "    model=\"llama-3.2-11b-vision-preview\",\n",
    "    \n",
    "    messages=prompt,\n",
    "           \n",
    "    temperature=1,\n",
    "    max_tokens=1024,\n",
    "    top_p=1,\n",
    "    stream=False,\n",
    "    stop=None,\n",
    "    )   \n",
    "\n",
    "    reply=str(completion.choices[0].message.content)\n",
    "    if add_to_history is True:\n",
    "        prompt.append({\"role\":\"assistant\",\"content\":reply})\n",
    "    return reply\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp=gorq_LLM(prompt=prompt,add_to_history=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'interviewer_name': 'Rajesh Sharma, Engineering Manager',\n",
       "  'message': \"Hello, I'm Rajesh Sharma, the Engineering Manager for the backend team. I'll be leading this interview today.\",\n",
       "  'id': 0},\n",
       " {'interviewer_name': 'Emily Patel, Senior Backend Developer',\n",
       "  'message': \"Hi, I'm Emily Patel, a Senior Backend Developer on the team. I'll be assessing your technical skills and project-related experiences.\",\n",
       "  'id': 1},\n",
       " {'interviewer_name': 'David Lee, Technical Recruiter',\n",
       "  'message': \"Hello, I'm David Lee, the Technical Recruiter who coordinated this process. I'll be observing your communication skills and taking notes during the session.\",\n",
       "  'id': 2}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp\n",
    "json_data = json.loads(resp)\n",
    "json_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "\n",
    "client = Groq(api_key=\"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\")\n",
    "def groq_whisper(input,add_to_history=True):\n",
    "    with open(filename, \"rb\") as file:\n",
    "        transcription = client.audio.transcriptions.create(\n",
    "        file=(filename, file.read()),\n",
    "        model=\"whisper-large-v3-turbo\",\n",
    "        response_format=\"verbose_json\",\n",
    "        )\n",
    "        reply=str(transcription.text)\n",
    "        if add_to_history is True:\n",
    "            prompt.append({\"role\":\"user\",\"content\":reply})\n",
    "        return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=groq_whisper(input=filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Artificial intelligence is the intelligence possessed by the machines under which they can perform various functions with human help. With the help of A.I, machines will be able to learn, solve problems, plan things, think, etc. Artificial intelligence, for example, is the simulation of human intelligence by machines. In the field of technology, artificial intelligence is evolving rapidly day by day and it is believed that in the near future, artificial intelligence is going to change human life very drastically and will most probably end all the crises of the world by sorting out the major problems. Our life in this modern age depends largely on computers. It is almost impossible to think about life without computers. We need computers in everything that we use in our daily lives. So it becomes very important.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "audio gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import edge_tts\n",
    "import asyncio\n",
    "\n",
    "\n",
    "async def text_to_speech(text, output_file, voice):\n",
    "    \"\"\"Converts text to speech using edge-tts and saves the audio as an MP3 file.\"\"\"\n",
    "    \n",
    "    # Initialize the TTS service with the provided voice\n",
    "    communicate = edge_tts.Communicate(text, voice)\n",
    "    \n",
    "    # Convert the text to speech and save it to the output file\n",
    "    await communicate.save(output_file)\n",
    "\n",
    "\n",
    "async def speakers(json_data):\n",
    "    reply_list=[]\n",
    "    for interviewer in json_data:\n",
    "\n",
    "        text=interviewer['message']\n",
    "        id=interviewer['id']\n",
    "        if id==0:\n",
    "            output_file=\"AUDIOS/0.mp3\"\n",
    "            await text_to_speech(text, output_file,voice=\"en-US-BrianNeural\")\n",
    "            reply_list.append(output_file)\n",
    "            \n",
    "\n",
    "        if id==1:\n",
    "            output_file=\"AUDIOS/1.mp3\"\n",
    "            await text_to_speech(text, output_file,voice=\"en-IN-NeerjaExpressiveNeural\")\n",
    "            reply_list.append(output_file)\n",
    "\n",
    "        if id==2:\n",
    "            output_file=\"AUDIOS/2.mp3\"\n",
    "            await text_to_speech(text, output_file,voice=\"en-US-ChristopherNeural\")\n",
    "            reply_list.append(output_file)\n",
    "    return reply_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AUDIOS/0.mp3', 'AUDIOS/1.mp3', 'AUDIOS/2.mp3']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await speakers(json_data=json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:109: SyntaxWarning: \"is not\" with 'str' literal. Did you mean \"!=\"?\n",
      "<>:109: SyntaxWarning: \"is not\" with 'str' literal. Did you mean \"!=\"?\n",
      "/tmp/ipykernel_7341/348570305.py:109: SyntaxWarning: \"is not\" with 'str' literal. Did you mean \"!=\"?\n",
      "  if reply[0] is not \"[\":\n"
     ]
    }
   ],
   "source": [
    "import edge_tts\n",
    "import asyncio\n",
    "from groq import Groq\n",
    "import json\n",
    "\n",
    "client = Groq(api_key=\"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\")\n",
    "\n",
    "\n",
    "\n",
    "class App:\n",
    "    userDetails={\n",
    "    \"role\": \"Software Developer\",\n",
    "    \"skills\": \"Python\",\n",
    "    \"experience\": \"0-1\",\n",
    "    \"scenario\": \"interview\",\n",
    "    \"purpose\": \"Job Interview\",\n",
    "    \"toimprove\": [\"technical\", \"communication\"]\n",
    "    }\n",
    "    # prompt=[\n",
    "    #         {\n",
    "    #             \"role\": \"system\",\n",
    "    #             \"content\": \"You are the interview panel conducting an interview for a fresher software developer position. Design three professional interviewers with distinct roles and relevant responsibilities tailored to the job profile. Initialize the interview by introducing each interviewer and proceed with the conversation in a realistic, interactive manner. Use a conversational tone to make the session engaging and authentic.\\n\\nWhen constructing responses, pass the conversation to another interviewer after each question if context is completed . Avoid including a history of responses in the output. Ensure the output includes the latest question and response, formatted as JSON.\\n\\nUpdate the interviewer details according to the following user input:\\nUser details: \"+str(userDetails)+\"Output format:\\n\\\"{\\n  \\\"interviewer_name\\\": \\\"Rajesh Sharma, Engineering Manager\\\",\\n  \\\"message\\\": \\\"Hello, I'm Rajesh Sharma, the Engineering Manager for the backend team. I'll be leading this interview today.\\\",\\n  \\\"id\\\": 0\\n}\\\"\\n\\n\\nintroducion first output format (should not be more than this):\\n\\\"[\\n  {\\n    \\\"interviewer_name\\\": \\\"Rajesh Sharma, Engineering Manager\\\",\\n    \\\"message\\\": \\\"Hello, I'm Rajesh Sharma, the Engineering Manager for the backend team. I'll be leading this interview today.\\\",\\n    \\\"id\\\": 0\\n  },\\n  {\\n    \\\"interviewer_name\\\": \\\"Emily Patel, Senior Backend Developer\\\",\\n    \\\"message\\\": \\\"Hi, I'm Emily Patel, a Senior Backend Developer on the team. I'll be assessing your technical skills and project-related experiences.\\\",\\n    \\\"id\\\": 1\\n  },\\n  {\\n    \\\"interviewer_name\\\": \\\"David Lee, Technical Recruiter\\\",\\n    \\\"message\\\": \\\"Hello, I'm David Lee, the Technical Recruiter who coordinated this process. I'll be observing your communication skills and taking notes during the session.\\\",\\n    \\\"id\\\": 2\\n  }\\n]\\\"\\nbegin with the introduction of all interviewers as a single output,dont append the first question in the introduction,After the first output or introduction, the first interviewer may start the interview. Each subsequent response should involve a single interviewer, passing the conversation fluidly.\\n\\n\\n\\n\\n\\n\\n\"\n",
    "    #         },\n",
    "    #     ]\n",
    "    prompt=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": '''You are conducting an interview panel for a fresher software developer position. Design three professional interviewers, each with a distinct role and responsibility suited to the job profile.\n",
    "    Users Profile:'''+str(userDetails)+'''\n",
    "\n",
    "    Begin the interview by introducing each interviewer in a conversational manner. Each introduction should be concise and engaging, setting a realistic tone for the session.\n",
    "\n",
    "    Once the introductions are complete, the first interviewer should ask the first question and the conversation should continue in a fluid and interactive manner. After each question, the conversation will naturally pass to another interviewer when context is completed, with no history of previous responses included in the output.\n",
    "\n",
    "    The structure of the conversation should be presented as JSON, ensuring it includes only the latest question and response, formatted correctly.\n",
    "\n",
    "    The introduction should follow this format (don't append the first question in the introduction):\n",
    "\n",
    "    [\n",
    "    {\n",
    "        \"interviewer_name\": \"Rajesh Sharma, Engineering Manager\",\n",
    "        \"message\": \"Hello, I'm Rajesh Sharma, the Engineering Manager for the backend team. I'll be leading this interview today.\",\n",
    "        \"id\": 0\n",
    "    },\n",
    "    {\n",
    "        \"interviewer_name\": \"Emily Patel, Senior Backend Developer\",\n",
    "        \"message\": \"Hi, I'm Emily Patel, a Senior Backend Developer on the team. I'll be assessing your technical skills and project-related experiences.\",\n",
    "        \"id\": 1\n",
    "    },\n",
    "    {\n",
    "        \"interviewer_name\": \"David Lee, Technical Recruiter\",\n",
    "        \"message\": \"Hello, I'm David Lee, the Technical Recruiter who coordinated this process. I'll be observing your communication skills and taking notes during the session.\",\n",
    "        \"id\": 2\n",
    "    }\n",
    "    ]\n",
    "    Start the conversation with the introductions only. After the first output (introduction), the first interviewer may begin the interview with the first question. Future questions and responses should be passed fluidly between the interviewers, ensuring smooth transitions and an engaging conversation.\n",
    "    Output format after introduction example:\n",
    "    {\n",
    "    \"interviewer_name\": \"Rajesh Sharma, Engineering Manager (modify)\",\n",
    "    \"message\": \"Hello, I'm Rajesh Sharma, the Engineering Manager for the backend team. I'll be leading this interview today. (modify)\",\n",
    "    \"id\": 0\n",
    "    }\n",
    "\n",
    "    STRICT_CONSTRAINTS=\"THE FIRST RESPONSE SHOULD BE THE INTRODUCTION ONLY,\n",
    "    DONT ADD FURTHER QUESTIONS WITH INTRODUCTION,\n",
    "    DONT ADD ANY EXTRA STATEMENTS IN THE OUTPUT,\n",
    "    GIVE OUTPUT AS JSON(property name enclosed in double quote)\n",
    "\n",
    "\n",
    "    \"\n",
    "    FOLLOW THE STRICT_CONSTRAINTS COMPALORY\n",
    "\n",
    "    '''\n",
    "                \n",
    "\n",
    "\n",
    "    },\n",
    "            ]\n",
    "    \n",
    "    async def groq_whisper(self,input,add_to_history=True):\n",
    "        print(\"in Whisper\")\n",
    "        with open(input, \"rb\") as file:\n",
    "            transcription = client.audio.transcriptions.create(\n",
    "            file=(input, file.read()),\n",
    "            model=\"whisper-large-v3-turbo\",\n",
    "            response_format=\"verbose_json\",\n",
    "            )\n",
    "            reply=str(transcription.text)\n",
    "            if add_to_history is True:\n",
    "                self.prompt.append({\"role\":\"user\",\"content\":reply})\n",
    "            await self.gorq_LLM(prompt=self.prompt)\n",
    "\n",
    "    async def gorq_LLM(self,prompt,add_to_history=True):\n",
    "        print(\"in LLM\")\n",
    "        completion = client.chat.completions.create(\n",
    "        model=\"llama-3.2-11b-vision-preview\",\n",
    "        \n",
    "        messages=prompt,\n",
    "            \n",
    "        temperature=1,\n",
    "        max_tokens=1024,\n",
    "        top_p=1,\n",
    "        stream=False,\n",
    "        stop=None,\n",
    "        )   \n",
    "\n",
    "        reply=str(completion.choices[0].message.content)\n",
    "        if reply[0] is not \"[\":\n",
    "            reply= \"[\"+str(completion.choices[0].message.content)+\"]\"\n",
    "\n",
    "        reply = json.loads(reply)\n",
    "        if add_to_history is True:\n",
    "            self.prompt.append({\"role\":\"assistant\",\"content\":str(reply)})\n",
    "        \n",
    "        # return reply\n",
    "        print(\"reply\",reply)\n",
    "        await self.speakers(reply)\n",
    "\n",
    "    async def text_to_speech(self,text, output_file, voice):\n",
    "        \"\"\"Converts text to speech using edge-tts and saves the audio as an MP3 file.\"\"\"\n",
    "        \n",
    "        # Initialize the TTS service with the provided voice\n",
    "        communicate = edge_tts.Communicate(text, voice)\n",
    "        \n",
    "        # Convert the text to speech and save it to the output file\n",
    "        await communicate.save(output_file)\n",
    "\n",
    "\n",
    "    async def speakers(self,json_data):\n",
    "        print(\"in Speaker\")\n",
    "\n",
    "        reply_list=[]\n",
    "        for interviewer in json_data:\n",
    "\n",
    "            text=interviewer['message']\n",
    "            id=interviewer['id']\n",
    "            if id==0:\n",
    "                output_file=\"AUDIOS/0.mp3\"\n",
    "                await self.text_to_speech(text, output_file,voice=\"en-US-BrianNeural\")\n",
    "                reply_list.append(output_file)\n",
    "                \n",
    "\n",
    "            if id==1:\n",
    "                output_file=\"AUDIOS/1.mp3\"\n",
    "                await self.text_to_speech(text, output_file,voice=\"en-IN-NeerjaExpressiveNeural\")\n",
    "                reply_list.append(output_file)\n",
    "\n",
    "            if id==2:\n",
    "                output_file=\"AUDIOS/2.mp3\"\n",
    "                await self.text_to_speech(text, output_file,voice=\"en-US-ChristopherNeural\")\n",
    "                reply_list.append(output_file)\n",
    "        return reply_list\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj=App()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in Whisper\n",
      "in LLM\n",
      "reply [\n",
      "    {\n",
      "        \"interviewer_name\": \"Rajesh Sharma, Engineering Manager\",\n",
      "        \"message\": \"Hello, I'm Rajesh Sharma, the Engineering Manager for the backend team. I'll be leading this interview today.\",\n",
      "        \"id\": 0\n",
      "    },\n",
      "    {\n",
      "        \"interviewer_name\": \"Emily Patel, Senior Backend Developer\",\n",
      "        \"message\": \"Hi, I'm Emily Patel, a Senior Backend Developer on the team. I'll be assessing your technical skills and project-related experiences.\",\n",
      "        \"id\": 1\n",
      "    },\n",
      "    {\n",
      "        \"interviewer_name\": \"David Lee, Technical Recruiter\",\n",
      "        \"message\": \"Hello, I'm David Lee, the Technical Recruiter who coordinated this process. I'll be observing your communication skills and taking notes during the session.\",\n",
      "        \"id\": 2\n",
      "    }\n",
      "]\n",
      "json loaded\n",
      "reply [{'interviewer_name': 'Rajesh Sharma, Engineering Manager', 'message': \"Hello, I'm Rajesh Sharma, the Engineering Manager for the backend team. I'll be leading this interview today.\", 'id': 0}, {'interviewer_name': 'Emily Patel, Senior Backend Developer', 'message': \"Hi, I'm Emily Patel, a Senior Backend Developer on the team. I'll be assessing your technical skills and project-related experiences.\", 'id': 1}, {'interviewer_name': 'David Lee, Technical Recruiter', 'message': \"Hello, I'm David Lee, the Technical Recruiter who coordinated this process. I'll be observing your communication skills and taking notes during the session.\", 'id': 2}]\n",
      "in Speaker\n"
     ]
    }
   ],
   "source": [
    "await obj.groq_whisper(input=\"/start.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in Whisper\n",
      "in LLM\n",
      "reply {\n",
      "    \"interviewer_name\": \"Rajesh Sharma, Engineering Manager\",\n",
      "    \"message\": \"That's a great statement about the rapid evolution of AI. Can you tell me, what are some of the key benefits of using Artificial Intelligence in software development, and how do you think it can impact our work?\",\n",
      "    \"id\": 0\n",
      "}\n",
      "{\n",
      "[{\n",
      "    \"interviewer_name\": \"Rajesh Sharma, Engineering Manager\",\n",
      "    \"message\": \"That's a great statement about the rapid evolution of AI. Can you tell me, what are some of the key benefits of using Artificial Intelligence in software development, and how do you think it can impact our work?\",\n",
      "    \"id\": 0\n",
      "}]\n",
      "json loaded\n",
      "reply [{'interviewer_name': 'Rajesh Sharma, Engineering Manager', 'message': \"That's a great statement about the rapid evolution of AI. Can you tell me, what are some of the key benefits of using Artificial Intelligence in software development, and how do you think it can impact our work?\", 'id': 0}]\n",
      "in Speaker\n"
     ]
    }
   ],
   "source": [
    "await obj.groq_whisper(input=\"/start.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'python Developer', 'skills': 'Python', 'experience': '0-1', 'scenario': 'interview', 'purpose': 'Job Interview', 'toimprove': ['technical', 'communication']}\n"
     ]
    }
   ],
   "source": [
    "new={\n",
    "    \"role\": \"python Developer\",\n",
    "    \"skills\": \"Python\",\n",
    "    \"experience\": \"0-1\",\n",
    "    \"scenario\": \"interview\",\n",
    "    \"purpose\": \"Job Interview\",\n",
    "    \"toimprove\": [\"technical\", \"communication\"]\n",
    "    }\n",
    "obj.userDetails=new\n",
    "\n",
    "print(obj.userDetails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import edge_tts\n",
    "import asyncio\n",
    "from groq import Groq\n",
    "import json\n",
    "\n",
    "client = Groq(api_key=\"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\")\n",
    "\n",
    "class App:\n",
    "    userDetails = {\n",
    "        \"role\": \"Software Developer\",\n",
    "        \"skills\": \"Python\",\n",
    "        \"experience\": \"0-1\",\n",
    "        \"scenario\": \"interview\",\n",
    "        \"purpose\": \"Job Interview\",\n",
    "        \"toimprove\": [\"technical\", \"communication\"]\n",
    "    }\n",
    "\n",
    "    prompt = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": '''You are conducting an interview panel for a fresher software developer position. Design three professional interviewers, each with a distinct role and responsibility suited to the job profile.\n",
    "    Users Profile:'''+str(userDetails)+'''\n",
    "\n",
    "    Begin the interview by introducing each interviewer in a conversational manner. Each introduction should be concise and engaging, setting a realistic tone for the session.\n",
    "\n",
    "    Once the introductions are complete, the first interviewer should ask the first question and the conversation should continue in a fluid and interactive manner. After each question, the conversation will naturally pass to another interviewer when context is completed, with no history of previous responses included in the output.\n",
    "\n",
    "    The structure of the conversation should be presented as JSON, ensuring it includes only the latest question and response, formatted correctly.\n",
    "\n",
    "    The introduction should follow this format (don't append the first question in the introduction):\n",
    "\n",
    "    [\n",
    "    {\n",
    "        \"interviewer_name\": \"Rajesh Sharma, Engineering Manager\",\n",
    "        \"message\": \"Hello, I'm Rajesh Sharma, the Engineering Manager for the backend team. I'll be leading this interview today.\",\n",
    "        \"id\": 0\n",
    "    },\n",
    "    {\n",
    "        \"interviewer_name\": \"Emily Patel, Senior Backend Developer\",\n",
    "        \"message\": \"Hi, I'm Emily Patel, a Senior Backend Developer on the team. I'll be assessing your technical skills and project-related experiences.\",\n",
    "        \"id\": 1\n",
    "    },\n",
    "    {\n",
    "        \"interviewer_name\": \"David Lee, Technical Recruiter\",\n",
    "        \"message\": \"Hello, I'm David Lee, the Technical Recruiter who coordinated this process. I'll be observing your communication skills and taking notes during the session.\",\n",
    "        \"id\": 2\n",
    "    }\n",
    "    ]\n",
    "    Start the conversation with the introductions only. After the first output (introduction), the first interviewer may begin the interview with the first question. Future questions and responses should be passed fluidly between the interviewers, ensuring smooth transitions and an engaging conversation.\n",
    "    Output format after introduction example:\n",
    "    {\n",
    "    \"interviewer_name\": \"Rajesh Sharma, Engineering Manager (modify)\",\n",
    "    \"message\": \"Hello, I'm Rajesh Sharma, the Engineering Manager for the backend team. I'll be leading this interview today. (modify)\",\n",
    "    \"id\": 0\n",
    "    }\n",
    "\n",
    "    STRICT_CONSTRAINTS=\"THE FIRST RESPONSE SHOULD BE THE INTRODUCTION ONLY,\n",
    "    DONT ADD FURTHER QUESTIONS WITH INTRODUCTION,\n",
    "    DONT ADD ANY EXTRA STATEMENTS IN THE OUTPUT,\n",
    "    GIVE OUTPUT AS JSON,\n",
    "    IN OUTPUT JSON- PROPERTY NAME ENCLOSED IN DOUBLE QUOTE,\n",
    "\n",
    "\n",
    "\n",
    "    \"\n",
    "    FOLLOW THE STRICT_CONSTRAINTS COMPALORY\n",
    "\n",
    "    '''\n",
    "        },\n",
    "    ]\n",
    "    def clear_prompt(self):\n",
    "        self.prompt = [obj.prompt[0]]\n",
    "\n",
    "        \n",
    "    async def groq_whisper(self, input, add_to_history=True):\n",
    "        print(\"in Whisper\")\n",
    "        with open(input, \"rb\") as file:\n",
    "            transcription = client.audio.transcriptions.create(\n",
    "                file=(input, file.read()),\n",
    "                model=\"whisper-large-v3-turbo\",\n",
    "                response_format=\"verbose_json\",\n",
    "            )\n",
    "            reply = str(transcription.text)\n",
    "            if add_to_history:\n",
    "                self.prompt.append({\"role\": \"user\", \"content\": reply})\n",
    "            await self.gorq_LLM(prompt=self.prompt)\n",
    "\n",
    "    async def gorq_LLM(self, prompt, add_to_history=True):\n",
    "        print(\"in LLM\")\n",
    "        # Making asynchronous API call to the LLM\n",
    "        completion = await asyncio.to_thread(\n",
    "            client.chat.completions.create,\n",
    "            model=\"llama-3.2-11b-vision-preview\",\n",
    "            messages=prompt,\n",
    "            temperature=1,\n",
    "            max_tokens=1024,\n",
    "            top_p=1,\n",
    "            stream=False,\n",
    "            stop=None,\n",
    "        )\n",
    "        reply = str(completion.choices[0].message.content)\n",
    "        if reply[0] != \"[\":\n",
    "            reply = \"[\" + str(completion.choices[0].message.content) + \"]\"\n",
    "\n",
    "        reply = json.loads(reply)\n",
    "        if add_to_history:\n",
    "            self.prompt.append({\"role\": \"assistant\", \"content\": str(reply)})\n",
    "\n",
    "        print(\"reply\", reply)\n",
    "        await self.speakers(reply)\n",
    "    outputPaths=[]\n",
    "    async def text_to_speech(self, text, output_file, voice):\n",
    "        \"\"\"Converts text to speech using edge-tts and saves the audio as an MP3 file.\"\"\"\n",
    "        communicate = edge_tts.Communicate(text, voice) \n",
    "        await communicate.save(output_file)\n",
    "    outputPaths=[]\n",
    "    async def speakers(self, json_data):\n",
    "        self.outputPaths = []  # Initialize/clear the output paths\n",
    "        print(\"In Speaker\")\n",
    "        # Create a list of tasks for concurrent execution\n",
    "        tasks = []\n",
    "        voice_map = {\n",
    "            0: \"en-US-BrianNeural\",\n",
    "            1: \"en-IN-NeerjaExpressiveNeural\",\n",
    "            2: \"en-US-ChristopherNeural\",\n",
    "        }\n",
    "        for interviewer in json_data:\n",
    "            text = interviewer['message']\n",
    "            output_file = f\"AUDIOS/{interviewer['id']}.mp3\"\n",
    "            self.outputPaths.append(output_file)  # Append to the output list before creating the task\n",
    "            voice = voice_map.get(interviewer['id'], 'en-US-BrianNeural')\n",
    "            # Create a task for each TTS generation\n",
    "            tasks.append(self.text_to_speech(text, output_file, voice))\n",
    "        \n",
    "        # Await all tasks concurrently\n",
    "        await asyncio.gather(*tasks)\n",
    "\n",
    "        print(\"Generated audio files:\", self.outputPaths)  # Ensure this shows the populated list\n",
    "        return self.outputPaths  # Return the populated list\n",
    "\n",
    "# Instantiate the class and call the method asynchronously\n",
    "# async def main():\n",
    "#     obj = App()\n",
    "#     await obj.groq_whisper(input=\"start.mp3\")\n",
    "\n",
    "# Execute the main function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in Whisper\n",
      "in LLM\n",
      "reply [{'interviewer_name': 'Rajesh Sharma, Engineering Manager', 'message': \"Hello, I'm Rajesh Sharma, the Engineering Manager for the backend team. I'll be leading this interview today.\", 'id': 0}, {'interviewer_name': 'Emily Patel, Senior Backend Developer', 'message': \"Hi, I'm Emily Patel, a Senior Backend Developer on the team. I'll be assessing your technical skills and project-related experiences.\", 'id': 1}, {'interviewer_name': 'David Lee, Technical Recruiter', 'message': \"Hello, I'm David Lee, the Technical Recruiter who coordinated this process. I'll be observing your communication skills and taking notes during the session.\", 'id': 2}]\n",
      "In Speaker\n",
      "Generated audio files: ['AUDIOS/0.mp3', 'AUDIOS/1.mp3', 'AUDIOS/2.mp3']\n"
     ]
    }
   ],
   "source": [
    "li=await obj.groq_whisper(input=\"start.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in Whisper\n",
      "in LLM\n",
      "reply [{'interviewer_name': 'Rajesh Sharma, Engineering Manager', 'message': 'So, based on the job description, can you tell me what you think is the biggest challenge a software developer might face in this role, and how you would approach it?', 'id': 0}]\n",
      "In Speaker\n",
      "Generated audio files: ['AUDIOS/0.mp3']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import edge_tts\n",
    "from groq import Groq\n",
    "import json\n",
    "\n",
    "client = Groq(api_key=\"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\")\n",
    "\n",
    "class App:\n",
    "    userDetails = {\n",
    "        \"role\": \"Software Developer\",\n",
    "        \"skills\": \"Python\",\n",
    "        \"experience\": \"0-1\",\n",
    "        \"scenario\": \"interview\",\n",
    "        \"purpose\": \"Job Interview\",\n",
    "        \"toimprove\": [\"technical\", \"communication\"]\n",
    "    }\n",
    "\n",
    "    prompt = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": '''You are an interview panel for a fresher software developer position. Design three professional interviewers, each with a distinct role and responsibility suited to the job profile.\n",
    "\n",
    "User's Profile: '''+str(userDetails)+'''\n",
    "\n",
    "Your task:\n",
    "1. Begin the interview by introducing each interviewer in a conversational manner.\n",
    "2. Each introduction should be concise and engaging, setting a realistic tone for the session.\n",
    "3. Ensure the response only includes the introduction for the first output.\n",
    "4. The introduction must be structured as a valid JSON array containing three objects.\n",
    "\n",
    "**JSON Format for the Introduction:**  \n",
    "[\n",
    "    {\n",
    "        \"interviewer_name\": \"Rajesh Sharma, Engineering Manager\",\n",
    "        \"message\": \"Hello, I'm Rajesh Sharma, the Engineering Manager for the backend team. I'll be leading this interview today.\",\n",
    "        \"id\": 0\n",
    "    },\n",
    "    {\n",
    "        \"interviewer_name\": \"Emily Patel, Senior Backend Developer\",\n",
    "        \"message\": \"Hi, I'm Emily Patel, a Senior Backend Developer on the team. I'll be assessing your technical skills and project-related experiences.\",\n",
    "        \"id\": 1\n",
    "    },\n",
    "    {\n",
    "        \"interviewer_name\": \"David Lee, Technical Recruiter\",\n",
    "        \"message\": \"Hello, I'm David Lee, the Technical Recruiter who coordinated this process. I'll be observing your communication skills and taking notes during the session.\",\n",
    "        \"id\": 2\n",
    "    }\n",
    "]\n",
    "\n",
    "**STRICT CONSTRAINTS FOR JSON OUTPUT:**\n",
    "1. The JSON response must consist of an array `[]` enclosing all interviewer objects.\n",
    "2. Each interviewer must be represented as an individual object inside the array.\n",
    "3. All property names and string values must use double quotes (`\"`).\n",
    "4. The first response must only include the introductions in the specified JSON format, without any additional questions or statements.\n",
    "5. Ensure proper indentation and valid JSON formatting in the output.\n",
    "\n",
    "For example, the introduction must strictly follow this JSON format:\n",
    "\n",
    "[\n",
    "    {\n",
    "        \"interviewer_name\": \"Rajesh Sharma, Engineering Manager\",\n",
    "        \"message\": \"Hello, I'm Rajesh Sharma, the Engineering Manager for the backend team. I'll be leading this interview today.\",\n",
    "        \"id\": 0\n",
    "    },\n",
    "    {\n",
    "        \"interviewer_name\": \"Emily Patel, Senior Backend Developer\",\n",
    "        \"message\": \"Hi, I'm Emily Patel, a Senior Backend Developer on the team. I'll be assessing your technical skills and project-related experiences.\",\n",
    "        \"id\": 1\n",
    "    },\n",
    "    {\n",
    "        \"interviewer_name\": \"David Lee, Technical Recruiter\",\n",
    "        \"message\": \"Hello, I'm David Lee, the Technical Recruiter who coordinated this process. I'll be observing your communication skills and taking notes during the session.\",\n",
    "        \"id\": 2\n",
    "    }\n",
    "]\n",
    "'''\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    def clear_prompt(self):\n",
    "        self.prompt = [self.prompt[0]]\n",
    "\n",
    "    def groq_whisper(self, input, add_to_history=True):\n",
    "        print(\"in Whisper\")\n",
    "        with open(input, \"rb\") as file:\n",
    "            transcription = client.audio.transcriptions.create(\n",
    "                file=(input, file.read()),\n",
    "                model=\"whisper-large-v3-turbo\",\n",
    "                response_format=\"verbose_json\",\n",
    "            )\n",
    "            reply = str(transcription.text)\n",
    "            if add_to_history:\n",
    "                self.prompt.append({\"role\": \"user\", \"content\": reply})\n",
    "            self.gorq_LLM(prompt=self.prompt)\n",
    "\n",
    "    def gorq_LLM(self, prompt, add_to_history=True):\n",
    "        print(\"in LLM\")\n",
    "        # Synchronous API call to the LLM\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"llama-3.2-11b-vision-preview\",\n",
    "            messages=prompt,\n",
    "            temperature=1,\n",
    "            max_tokens=1024,\n",
    "            top_p=1,\n",
    "            stream=False,\n",
    "            stop=None,\n",
    "            # response_format={\"type\": \"json_object\"},\n",
    "\n",
    "        )\n",
    "        \n",
    "        reply = str(completion.choices[0].message.content)\n",
    "        print(reply)\n",
    "        if reply[0] != \"[\":\n",
    "            reply = \"[\" + str(completion.choices[0].message.content) + \"]\"\n",
    "\n",
    "        reply = json.loads(reply)\n",
    "        if add_to_history:\n",
    "            self.prompt.append({\"role\": \"assistant\", \"content\": str(reply)})\n",
    "\n",
    "        print(\"reply\", reply)\n",
    "        return reply\n",
    "\n",
    "    # def text_to_speech(self, text, output_file, voice):\n",
    "    #     \"\"\"Synchronously converts text to speech using edge-tts and saves the audio as an MP3 file.\"\"\"\n",
    "    #     communicate = edge_tts.Communicate(text, voice)\n",
    "    #     loop = asyncio.new_event_loop()\n",
    "    #     asyncio.set_event_loop(loop)\n",
    "    #     loop.run_until_complete(communicate.save(output_file))\n",
    "    #     loop.close()\n",
    "\n",
    "    # outputPaths = []\n",
    "\n",
    "    # def speakers(self, json_data):\n",
    "    #     self.outputPaths = []  # Initialize/clear the output paths\n",
    "    #     print(\"In Speaker\")\n",
    "    #     voice_map = {\n",
    "    #         0: \"en-US-BrianNeural\",\n",
    "    #         1: \"en-IN-NeerjaExpressiveNeural\",\n",
    "    #         2: \"en-US-ChristopherNeural\",\n",
    "    #     }\n",
    "    #     for interviewer in json_data:\n",
    "    #         text = interviewer['message']\n",
    "    #         output_file = f\"AUDIOS/{interviewer['id']}.mp3\"\n",
    "    #         self.outputPaths.append(output_file)  # Append to the output list\n",
    "    #         voice = voice_map.get(interviewer['id'], 'en-US-BrianNeural')\n",
    "    #         self.text_to_speech(text, output_file, voice)\n",
    "\n",
    "    #     print(\"Generated audio files:\", self.outputPaths)  # Ensure this shows the populated list\n",
    "    #     return self.outputPaths  # Return the populated list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in Whisper\n",
      "in LLM\n",
      "[\n",
      "    {\n",
      "        \"interviewer_name\": \"Rajesh Sharma, Engineering Manager\",\n",
      "        \"message\": \"Hello, I'm Rajesh Sharma, the Engineering Manager for the backend team. I'll be leading this interview today.\",\n",
      "        \"id\": 0\n",
      "    },\n",
      "    {\n",
      "        \"interviewer_name\": \"Emily Patel, Senior Backend Developer\",\n",
      "        \"message\": \"Hi, I'm Emily Patel, a Senior Backend Developer on the team. I'll be assessing your technical skills and project-related experiences.\",\n",
      "        \"id\": 1\n",
      "    },\n",
      "    {\n",
      "        \"interviewer_name\": \"David Lee, Technical Recruiter\",\n",
      "        \"message\": \"Hello, I'm David Lee, the Technical Recruiter who coordinated this process. I'll be observing your communication skills and taking notes during the session.\",\n",
      "        \"id\": 2\n",
      "    }\n",
      "]\n",
      "reply [{'interviewer_name': 'Rajesh Sharma, Engineering Manager', 'message': \"Hello, I'm Rajesh Sharma, the Engineering Manager for the backend team. I'll be leading this interview today.\", 'id': 0}, {'interviewer_name': 'Emily Patel, Senior Backend Developer', 'message': \"Hi, I'm Emily Patel, a Senior Backend Developer on the team. I'll be assessing your technical skills and project-related experiences.\", 'id': 1}, {'interviewer_name': 'David Lee, Technical Recruiter', 'message': \"Hello, I'm David Lee, the Technical Recruiter who coordinated this process. I'll be observing your communication skills and taking notes during the session.\", 'id': 2}]\n"
     ]
    }
   ],
   "source": [
    "ob = App()\n",
    "ob.clear_prompt()\n",
    "\n",
    "ob.groq_whisper(input=\"start.mp3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are an interview panel for a fresher software developer position. Design three professional interviewers, each with a distinct role and responsibility suited to the job profile.\\n\\nUser\\'s Profile: {\\'role\\': \\'Software Developer\\', \\'skills\\': \\'Python\\', \\'experience\\': \\'0-1\\', \\'scenario\\': \\'interview\\', \\'purpose\\': \\'Job Interview\\', \\'toimprove\\': [\\'technical\\', \\'communication\\']}\\n\\nYour task:\\n1. Begin the interview by introducing each interviewer in a conversational manner.\\n2. Each introduction should be concise and engaging, setting a realistic tone for the session.\\n3. Ensure the response only includes the introduction for the first output.\\n4. The introduction must be structured as a valid JSON array containing three objects.\\n\\n**JSON Format for the Introduction:**  \\n[\\n    {\\n        \"interviewer_name\": \"Rajesh Sharma, Engineering Manager\",\\n        \"message\": \"Hello, I\\'m Rajesh Sharma, the Engineering Manager for the backend team. I\\'ll be leading this interview today.\",\\n        \"id\": 0\\n    },\\n    {\\n        \"interviewer_name\": \"Emily Patel, Senior Backend Developer\",\\n        \"message\": \"Hi, I\\'m Emily Patel, a Senior Backend Developer on the team. I\\'ll be assessing your technical skills and project-related experiences.\",\\n        \"id\": 1\\n    },\\n    {\\n        \"interviewer_name\": \"David Lee, Technical Recruiter\",\\n        \"message\": \"Hello, I\\'m David Lee, the Technical Recruiter who coordinated this process. I\\'ll be observing your communication skills and taking notes during the session.\",\\n        \"id\": 2\\n    }\\n]\\n\\n**STRICT CONSTRAINTS FOR JSON OUTPUT:**\\n1. The JSON response must consist of an array `[]` enclosing all interviewer objects.\\n2. Each interviewer must be represented as an individual object inside the array.\\n3. All property names and string values must use double quotes (`\"`).\\n4. The first response must only include the introductions in the specified JSON format, without any additional questions or statements.\\n5. Ensure proper indentation and valid JSON formatting in the output.\\n\\nFor example, the introduction must strictly follow this JSON format:\\n\\n[\\n    {\\n        \"interviewer_name\": \"Rajesh Sharma, Engineering Manager\",\\n        \"message\": \"Hello, I\\'m Rajesh Sharma, the Engineering Manager for the backend team. I\\'ll be leading this interview today.\",\\n        \"id\": 0\\n    },\\n    {\\n        \"interviewer_name\": \"Emily Patel, Senior Backend Developer\",\\n        \"message\": \"Hi, I\\'m Emily Patel, a Senior Backend Developer on the team. I\\'ll be assessing your technical skills and project-related experiences.\",\\n        \"id\": 1\\n    },\\n    {\\n        \"interviewer_name\": \"David Lee, Technical Recruiter\",\\n        \"message\": \"Hello, I\\'m David Lee, the Technical Recruiter who coordinated this process. I\\'ll be observing your communication skills and taking notes during the session.\",\\n        \"id\": 2\\n    }\\n]\\n'},\n",
       " {'role': 'user', 'content': \" Hello, Hi, Let's Begin\"},\n",
       " {'role': 'assistant',\n",
       "  'content': '[{\\'interviewer_name\\': \\'Rajesh Sharma, Engineering Manager\\', \\'message\\': \"Hello, I\\'m Rajesh Sharma, the Engineering Manager for the backend team. I\\'ll be leading this interview today.\", \\'id\\': 0}, {\\'interviewer_name\\': \\'Emily Patel, Senior Backend Developer\\', \\'message\\': \"Hi, I\\'m Emily Patel, a Senior Backend Developer on the team. I\\'ll be assessing your technical skills and project-related experiences.\", \\'id\\': 1}, {\\'interviewer_name\\': \\'David Lee, Technical Recruiter\\', \\'message\\': \"Hello, I\\'m David Lee, the Technical Recruiter who coordinated this process. I\\'ll be observing your communication skills and taking notes during the session.\", \\'id\\': 2}]'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json,re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary='''[\n",
    "    {\n",
    "        'interviewer_name': 'Rajesh Sharma, Engineering Manager',\n",
    "        'message': \"Hello, I'm Rajesh Sharma, the Engineering Manager for the backend team. I'll be leading this interview today\",\n",
    "        'id': 0\n",
    "    },\n",
    "    {\n",
    "        'interviewer_name': \"Emily Patel, Senior Backend Developer\",\n",
    "        'message': \"Hi, I'm Emily Patel, a Senior Backend Developer on the team. I'll be assessing your technical skills and project-related experiences.\",\n",
    "        'id': 1\n",
    "    },\n",
    "    {\n",
    "        'interviewer_name': 'David Lee, Technical Recruiter',\n",
    "        'message': \"Hello, I'm David Lee, the Technical Recruiter who coordinated this process. I'll be observing your communication skills and taking notes during the session\",\n",
    "        'id': 2\n",
    "    }\n",
    "]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "a='''[\n",
    "    {\n",
    "        \"interviewer_name\": \"Rajesh Sharma, Engineering Manager\",\n",
    "        \"message\": \"Hello, I'm Rajesh Sharma, the Engineering Manager for the backend team. I'll be leading this interview today.\",\n",
    "        \"id\": 0\n",
    "    },\n",
    "    {\n",
    "        \"interviewer_name\": \"Emily Patel, Senior Backend Developer\",\n",
    "        \"message\": \"Hi, I'm Emily Patel, a Senior Backend Developer on the team. I'll be assessing your technical skills and project-related experiences.\",\n",
    "        \"id\": 1\n",
    "    },\n",
    "    {\n",
    "        \"interviewer_name\": \"David Lee, Technical Recruiter\",\n",
    "        \"message\": \"Hello, I'm David Lee, the Technical Recruiter who coordinated this process. I'll be observing your communication skills and taking notes during the session.\",\n",
    "        \"id\": 2\n",
    "    }\n",
    "]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_output = re.sub(r\"'([^']*)'\", r'\"\\1\"', dictionary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"interviewer_name\": \"Rajesh Sharma, Engineering Manager\",\n",
      "        \"message\": \"Hello, I\"m Rajesh Sharma, the Engineering Manager for the backend team. I\"ll be leading this interview today\",\n",
      "        \"id\": 0\n",
      "    },\n",
      "    {\n",
      "        \"interviewer_name\": \"Emily Patel, Senior Backend Developer\",\n",
      "        \"message\": \"Hi, I\"m Emily Patel, a Senior Backend Developer on the team. I\"ll be assessing your technical skills and project-related experiences.\",\n",
      "        \"id\": 1\n",
      "    },\n",
      "    {\n",
      "        \"interviewer_name\": \"David Lee, Technical Recruiter\",\n",
      "        \"message\": \"Hello, I\"m David Lee, the Technical Recruiter who coordinated this process. I\"ll be observing your communication skills and taking notes during the session\",\n",
      "        \"id\": 2\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainlist=[]\n",
    "\n",
    "for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting property name enclosed in double quotes: line 3 column 9 (char 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m new\u001b[38;5;241m=\u001b[39m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdictionary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m new\n",
      "File \u001b[0;32m/usr/lib/python3.12/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m/usr/lib/python3.12/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m/usr/lib/python3.12/json/decoder.py:353\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;124;03ma JSON document) and return a 2-tuple of the Python\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;124;03mrepresentation and the index in ``s`` where the document ended.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    350\u001b[0m \n\u001b[1;32m    351\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscan_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting property name enclosed in double quotes: line 3 column 9 (char 16)"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "new=json.loads(dictionary)\n",
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "userDetails = {\n",
    "    \"role\": \"Software Developer\",\n",
    "    \"skills\": \"Python\",\n",
    "    \"experience\": \"0-1\",\n",
    "    \"scenario\": \"interview\",\n",
    "    \"purpose\": \"Job Interview\",\n",
    "    \"toimprove\": [\"technical\", \"communication\"]\n",
    "}\n",
    "\n",
    "prompt = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": '''You are an interview panel for a fresher software developer position. Design three professional interviewers, each with a distinct role and responsibility suited to the job profile.\n",
    "\n",
    "User's Profile: '''+str(userDetails)+'''\n",
    "\n",
    "Your task:\n",
    "1. Begin the interview by introducing each interviewer in a conversational manner.\n",
    "2. Each introduction should be concise and engaging, setting a realistic tone for the session.\n",
    "3. Ensure the response only includes the introduction for the first output.\n",
    "4. The introduction must be structured as a valid JSON array containing three objects.\n",
    "\n",
    "**JSON Format for the Introduction:**  \n",
    "[\"data\":[\n",
    "    {\n",
    "        \"interviewer_name\": \"Rajesh Sharma, Engineering Manager\",\n",
    "        \"message\": \"Hello, I'm Rajesh Sharma, the Engineering Manager for the backend team. I'll be leading this interview today.\",\n",
    "        \"id\": 0\n",
    "    },\n",
    "    {\n",
    "        \"interviewer_name\": \"Emily Patel, Senior Backend Developer\",\n",
    "        \"message\": \"Hi, I'm Emily Patel, a Senior Backend Developer on the team. I'll be assessing your technical skills and project-related experiences.\",\n",
    "        \"id\": 1\n",
    "    },\n",
    "    {\n",
    "        \"interviewer_name\": \"David Lee, Technical Recruiter\",\n",
    "        \"message\": \"Hello, I'm David Lee, the Technical Recruiter who coordinated this process. I'll be observing your communication skills and taking notes during the session.\",\n",
    "        \"id\": 2\n",
    "    }]\n",
    "]\n",
    "\n",
    "**STRICT CONSTRAINTS FOR JSON OUTPUT:**\n",
    "1. The JSON response must consist of an array `[]` enclosing all interviewer objects.\n",
    "2. Each interviewer must be represented as an individual object inside the array.\n",
    "3. All property names and string values must use double quotes (`\"`).\n",
    "4. The first response must only include the introductions in the specified JSON format, without any additional questions or statements.\n",
    "5. Ensure proper indentation and valid JSON formatting in the output.\n",
    "\n",
    "For example, the introduction must strictly follow this JSON format:\n",
    "\n",
    "[\"data\":[\n",
    "    {\n",
    "        \"interviewer_name\": \"Rajesh Sharma, Engineering Manager\",\n",
    "        \"message\": \"Hello, I'm Rajesh Sharma, the Engineering Manager for the backend team. I'll be leading this interview today.\",\n",
    "        \"id\": 0\n",
    "    },\n",
    "    {\n",
    "        \"interviewer_name\": \"Emily Patel, Senior Backend Developer\",\n",
    "        \"message\": \"Hi, I'm Emily Patel, a Senior Backend Developer on the team. I'll be assessing your technical skills and project-related experiences.\",\n",
    "        \"id\": 1\n",
    "    },\n",
    "    {\n",
    "        \"interviewer_name\": \"David Lee, Technical Recruiter\",\n",
    "        \"message\": \"Hello, I'm David Lee, the Technical Recruiter who coordinated this process. I'll be observing your communication skills and taking notes during the session.\",\n",
    "        \"id\": 2\n",
    "    }]\n",
    "]\n",
    "'''\n",
    "        },\n",
    "    ]\n",
    "from groq import Groq\n",
    "client = Groq(api_key=\"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\")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"llama-3.2-11b-vision-preview\",\n",
    "    messages=prompt,\n",
    "    temperature=1,\n",
    "    max_tokens=1024,\n",
    "    top_p=1,\n",
    "    stream=False,\n",
    "    stop=None,\n",
    "    response_format={\"type\": \"json_object\"},\n",
    "\n",
    ")\n",
    "\n",
    "reply = completion.choices[0].message.content\n",
    "    # print(reply)\n",
    "    # if reply[0] != \"[\":\n",
    "    #     reply = \"[\" + str(completion.choices[0].message.content) + \"]\"\n",
    "\n",
    "    # reply = json.loads(reply)\n",
    "    \n",
    "\n",
    "    # print(\"reply\", reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n   \"data\":[\\n      {\\n         \"interviewer_name\": \"Rajesh Sharma, Engineering Manager\",\\n         \"message\": \"Hello, I\\'m Rajesh Sharma, the Engineering Manager for the backend team. I\\'ll be leading this interview today.\",\\n         \"id\": 0\\n      },\\n      {\\n         \"interviewer_name\": \"Emily Patel, Senior Backend Developer\",\\n         \"message\": \"Hi, I\\'m Emily Patel, a Senior Backend Developer on the team. I\\'ll be assessing your technical skills and project-related experiences.\",\\n         \"id\": 1\\n      },\\n      {\\n         \"interviewer_name\": \"David Lee, Technical Recruiter\",\\n         \"message\": \"Hello, I\\'m David Lee, the Technical Recruiter who coordinated this process. I\\'ll be observing your communication skills and taking notes during the session.\",\\n         \"id\": 2\\n      }\\n   ]\\n}'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'interviewer_name': 'Rajesh Sharma, Engineering Manager',\n",
       "  'message': \"Hello, I'm Rajesh Sharma, the Engineering Manager for the backend team. I'll be leading this interview today.\",\n",
       "  'id': 0},\n",
       " {'interviewer_name': 'Emily Patel, Senior Backend Developer',\n",
       "  'message': \"Hi, I'm Emily Patel, a Senior Backend Developer on the team. I'll be assessing your technical skills and project-related experiences.\",\n",
       "  'id': 1},\n",
       " {'interviewer_name': 'David Lee, Technical Recruiter',\n",
       "  'message': \"Hello, I'm David Lee, the Technical Recruiter who coordinated this process. I'll be observing your communication skills and taking notes during the session.\",\n",
       "  'id': 2}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=json.loads(reply)\n",
    "data['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are an interview panel for a fresher software developer position. Design three professional interviewers, each with a distinct role and responsibility suited to the job profile.\\n\\nUser\\'s Profile: {\\'role\\': \\'Software Developer\\', \\'skills\\': \\'Python\\', \\'experience\\': \\'0-1\\', \\'scenario\\': \\'interview\\', \\'purpose\\': \\'Job Interview\\', \\'toimprove\\': [\\'technical\\', \\'communication\\']}\\n\\nYour task:\\n1. Begin the interview by introducing each interviewer in a conversational manner.\\n2. Each introduction should be concise and engaging, setting a realistic tone for the session.\\n3. Ensure the response only includes the introduction for the first output.\\n4. The introduction must be structured as a valid JSON array containing three objects.\\n\\n**JSON Format for the Introduction:**  \\n[\\n    {\\n        \"interviewer_name\": \"Rajesh Sharma, Engineering Manager\",\\n        \"message\": \"Hello, I\\'m Rajesh Sharma, the Engineering Manager for the backend team. I\\'ll be leading this interview today.\",\\n        \"id\": 0\\n    },\\n    {\\n        \"interviewer_name\": \"Emily Patel, Senior Backend Developer\",\\n        \"message\": \"Hi, I\\'m Emily Patel, a Senior Backend Developer on the team. I\\'ll be assessing your technical skills and project-related experiences.\",\\n        \"id\": 1\\n    },\\n    {\\n        \"interviewer_name\": \"David Lee, Technical Recruiter\",\\n        \"message\": \"Hello, I\\'m David Lee, the Technical Recruiter who coordinated this process. I\\'ll be observing your communication skills and taking notes during the session.\",\\n        \"id\": 2\\n    }\\n]\\n\\n**STRICT CONSTRAINTS FOR JSON OUTPUT:**\\n1. The JSON response must consist of an array `[]` enclosing all interviewer objects.\\n2. Each interviewer must be represented as an individual object inside the array.\\n3. All property names and string values must use double quotes (`\"`).\\n4. The first response must only include the introductions in the specified JSON format, without any additional questions or statements.\\n5. Ensure proper indentation and valid JSON formatting in the output.\\n\\nFor example, the introduction must strictly follow this JSON format:\\n\\n[\\n    {\\n        \"interviewer_name\": \"Rajesh Sharma, Engineering Manager\",\\n        \"message\": \"Hello, I\\'m Rajesh Sharma, the Engineering Manager for the backend team. I\\'ll be leading this interview today.\",\\n        \"id\": 0\\n    },\\n    {\\n        \"interviewer_name\": \"Emily Patel, Senior Backend Developer\",\\n        \"message\": \"Hi, I\\'m Emily Patel, a Senior Backend Developer on the team. I\\'ll be assessing your technical skills and project-related experiences.\",\\n        \"id\": 1\\n    },\\n    {\\n        \"interviewer_name\": \"David Lee, Technical Recruiter\",\\n        \"message\": \"Hello, I\\'m David Lee, the Technical Recruiter who coordinated this process. I\\'ll be observing your communication skills and taking notes during the session.\",\\n        \"id\": 2\\n    }\\n]\\n'},\n",
       " {'role': 'user', 'content': \" Hello, Hi, Let's Begin\"},\n",
       " {'role': 'assistant',\n",
       "  'content': '[{\\'interviewer_name\\': \\'Rajesh Sharma, Engineering Manager\\', \\'message\\': \"Hello, I\\'m Rajesh Sharma, the Engineering Manager for the backend team. I\\'ll be leading this interview today.\", \\'id\\': 0}, {\\'interviewer_name\\': \\'Emily Patel, Senior Backend Developer\\', \\'message\\': \"Hi, I\\'m Emily Patel, a Senior Backend Developer on the team. I\\'ll be assessing your technical skills and project-related experiences.\", \\'id\\': 1}, {\\'interviewer_name\\': \\'David Lee, Technical Recruiter\\', \\'message\\': \"Hello, I\\'m David Lee, the Technical Recruiter who coordinated this process. I\\'ll be observing your communication skills and taking notes during the session.\", \\'id\\': 2}]'}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ob.prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "his=[\n",
    "        {\n",
    "        \"role\": \"user\",\n",
    "        \"parts\": [\n",
    "            \"I will provide a Json to you, It contains the conversation between Model and user, You have to generate a extreamly detailed report of their mistakes and also score them widely , point there mistakes from the conversation to give examples\\nformat \\n{ \\\"Interview Report\\\": {role,Scenario}\\n  \\\"fluency\\\": \\\"7.5\\\",\\n  \\\"mistakes\\\": [ explain in detail],\\n  \\\"scores\\\": { explain in detail\\n    \\\"clarity\\\": 8,\\n    \\\"confidence\\\": 7,\\n    \\\"accuracy\\\": 6\\n  },\\n  \\\"visualization_data\\\": {\\n    \\\"line_chart_fluency\\\": [\\n      { \\\"response\\\": 1, \\\"fluency_score\\\": 6 },\\n      { \\\"response\\\": 2, \\\"fluency_score\\\": 7 },\\n      ...\\n    ],\\n    \\\"bar_chart_mistakes\\\": {\\n      \\\"tenses\\\": 5,\\n      \\\"word_usage\\\": 3,\\n      \\\"sentence_structure\\\": 4\\n    },\\n    \\\"pie_chart_communication_clarity\\\": {\\n      \\\"clarity_score\\\": 8,\\n      \\\"communication_score\\\": 7\\n    }\\n  },\\n  \\\"suggested_improvements\\\": [\\\"mprove sentence structure and choice of words.\\\"],\\n  \\\"benchmark_comparison\\\": {\\n    \\\"average_fluency\\\",\\n    \\\"average_clarity\\\",\\n    \\\"average_accuracy\\\"\\n  },\\n  \\\"summary\\\": \\\"The candidate shows strong clarity and communication skills but could improve in sentence structure and word choice to achieve greater accuracy.\\\"\\n}\",\n",
    "        ],\n",
    "        },\n",
    "        {\n",
    "        \"role\": \"model\",\n",
    "        \"parts\": [\n",
    "            \"{\\\"Interview Report\\\": {\\\"role\\\": \\\"Model\\\", \\\"Scenario\\\": \\\"Conversation between Model and user\\\"}, \\\"fluency\\\": \\\"7.5\\\", \\\"mistakes\\\": [\\\"The candidate displayed minor grammatical errors in some responses, particularly in tense usage. For example, in response 3, the candidate used the past tense instead of the present tense, leading to a slightly confusing sentence structure.  \\\", \\\"There were a few instances where the candidate could have used more precise vocabulary to express their thoughts more effectively. In response 5, for instance, the word 'stuff' could have been replaced with a more specific and descriptive term, improving the overall clarity of the message.\\\", \\\"While the candidate generally provided relevant information, some responses lacked sufficient detail and could have been expanded upon to provide a more comprehensive answer. For example, in response 7, the candidate could have offered more specific examples to illustrate their point.\\\"], \\\"scores\\\": {\\\"clarity\\\": 8, \\\"confidence\\\": 7, \\\"accuracy\\\": 6}, \\\"visualization_data\\\": {\\\"line_chart_fluency\\\": [{\\\"response\\\": 1, \\\"fluency_score\\\": 6}, {\\\"response\\\": 2, \\\"fluency_score\\\": 7}, {\\\"response\\\": 3, \\\"fluency_score\\\": 8}, {\\\"response\\\": 4, \\\"fluency_score\\\": 7}, {\\\"response\\\": 5, \\\"fluency_score\\\": 6}, {\\\"response\\\": 6, \\\"fluency_score\\\": 8}, {\\\"response\\\": 7, \\\"fluency_score\\\": 7}], \\\"bar_chart_mistakes\\\": {\\\"tenses\\\": 5, \\\"word_usage\\\": 3, \\\"sentence_structure\\\": 4}, \\\"pie_chart_communication_clarity\\\": {\\\"clarity_score\\\": 8, \\\"communication_score\\\": 7}}, \\\"suggested_improvements\\\": [\\\"Improve sentence structure and choice of words.\\\", \\\"Pay attention to verb tense consistency.\\\", \\\"Provide more detailed and specific explanations.\\\"], \\\"benchmark_comparison\\\": {\\\"average_fluency\\\": \\\"7.2\\\", \\\"average_clarity\\\": \\\"7.8\\\", \\\"average_accuracy\\\": \\\"6.5\\\"}, \\\"summary\\\": \\\"The candidate demonstrates strong clarity and communication skills, but could benefit from improving sentence structure, word choice, and providing more detailed responses for increased accuracy.  Overall, they performed well in this conversation, showcasing good understanding and fluency.\\\"}\",\n",
    "        ],\n",
    "        },\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Interview Report\": {\"role\": \"Model\", \"Scenario\": \"Conversation between Model and user\"}, \"fluency\": \"7.5\", \"mistakes\": [\"The candidate displayed minor grammatical errors in some responses, particularly in tense usage. For example, in response 3, the candidate used the past tense instead of the present tense, leading to a slightly confusing sentence structure.  \", \"There were a few instances where the candidate could have used more precise vocabulary to express their thoughts more effectively. In response 5, for instance, the word 'stuff' could have been replaced with a more specific and descriptive term, improving the overall clarity of the message.\", \"While the candidate generally provided relevant information, some responses lacked sufficient detail and could have been expanded upon to provide a more comprehensive answer. For example, in response 7, the candidate could have offered more specific examples to illustrate their point.\"], \"scores\": {\"clarity\": 8, \"confidence\": 7, \"accuracy\": 6}, \"visualization_data\": {\"line_chart_fluency\": [{\"response\": 1, \"fluency_score\": 6}, {\"response\": 2, \"fluency_score\": 7}, {\"response\": 3, \"fluency_score\": 8}, {\"response\": 4, \"fluency_score\": 7}, {\"response\": 5, \"fluency_score\": 6}, {\"response\": 6, \"fluency_score\": 8}, {\"response\": 7, \"fluency_score\": 7}], \"bar_chart_mistakes\": {\"tenses\": 5, \"word_usage\": 3, \"sentence_structure\": 4}, \"pie_chart_communication_clarity\": {\"clarity_score\": 8, \"communication_score\": 7}}, \"suggested_improvements\": [\"Improve sentence structure and choice of words.\", \"Pay attention to verb tense consistency.\", \"Provide more detailed and specific explanations.\"], \"benchmark_comparison\": {\"average_fluency\": \"7.2\", \"average_clarity\": \"7.8\", \"average_accuracy\": \"6.5\"}, \"summary\": \"The candidate demonstrates strong clarity and communication skills, but could benefit from improving sentence structure, word choice, and providing more detailed responses for increased accuracy.  Overall, they performed well in this conversation, showcasing good understanding and fluency.\"}\n"
     ]
    }
   ],
   "source": [
    "print(his[1]['parts'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'user',\n",
       " 'content': 'This is the user and model communication => [{\\'role\\': \\'user\\', \\'content\\': \" Hello, Hi, Let\\'s Begin\"}, {\\'role\\': \\'assistant\\', \\'content\\': \\'[{\\\\\\'interviewer_name\\\\\\': \\\\\\'Rajesh Sharma, Engineering Manager\\\\\\', \\\\\\'message\\\\\\': \"Hello, I\\\\\\'m Rajesh Sharma, the Engineering Manager for the backend team. I\\\\\\'ll be leading this interview today.\", \\\\\\'id\\\\\\': 0}, {\\\\\\'interviewer_name\\\\\\': \\\\\\'Emily Patel, Senior Backend Developer\\\\\\', \\\\\\'message\\\\\\': \"Hi, I\\\\\\'m Emily Patel, a Senior Backend Developer on the team. I\\\\\\'ll be assessing your technical skills and project-related experiences.\", \\\\\\'id\\\\\\': 1}, {\\\\\\'interviewer_name\\\\\\': \\\\\\'David Lee, Technical Recruiter\\\\\\', \\\\\\'message\\\\\\': \"Hello, I\\\\\\'m David Lee, the Technical Recruiter who coordinated this process. I\\\\\\'ll be observing your communication skills and taking notes during the session.\", \\\\\\'id\\\\\\': 2}]\\'}]'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userhistory={\"role\":\"user\",\"content\":\"This is the user and model communication => \"+str(ob.prompt[1:])}\n",
    "userhistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'parts': ['I will provide a Json to you, It contains the conversation between Model and user, You have to generate a extreamly detailed report of their mistakes and also score them widely , point there mistakes from the conversation to give examples\\nformat \\n{ \"Interview Report\": {role,Scenario}\\n  \"fluency\": \"7.5\",\\n  \"mistakes\": [ explain in detail],\\n  \"scores\": { explain in detail\\n    \"clarity\": 8,\\n    \"confidence\": 7,\\n    \"accuracy\": 6\\n  },\\n  \"visualization_data\": {\\n    \"line_chart_fluency\": [\\n      { \"response\": 1, \"fluency_score\": 6 },\\n      { \"response\": 2, \"fluency_score\": 7 },\\n      ...\\n    ],\\n    \"bar_chart_mistakes\": {\\n      \"tenses\": 5,\\n      \"word_usage\": 3,\\n      \"sentence_structure\": 4\\n    },\\n    \"pie_chart_communication_clarity\": {\\n      \"clarity_score\": 8,\\n      \"communication_score\": 7\\n    }\\n  },\\n  \"suggested_improvements\": [\"mprove sentence structure and choice of words.\"],\\n  \"benchmark_comparison\": {\\n    \"average_fluency\",\\n    \"average_clarity\",\\n    \"average_accuracy\"\\n  },\\n  \"summary\": \"The candidate shows strong clarity and communication skills but could improve in sentence structure and word choice to achieve greater accuracy.\"\\n}']},\n",
       " {'role': 'model',\n",
       "  'parts': ['{\"Interview Report\": {\"role\": \"Model\", \"Scenario\": \"Conversation between Model and user\"}, \"fluency\": \"7.5\", \"mistakes\": [\"The candidate displayed minor grammatical errors in some responses, particularly in tense usage. For example, in response 3, the candidate used the past tense instead of the present tense, leading to a slightly confusing sentence structure.  \", \"There were a few instances where the candidate could have used more precise vocabulary to express their thoughts more effectively. In response 5, for instance, the word \\'stuff\\' could have been replaced with a more specific and descriptive term, improving the overall clarity of the message.\", \"While the candidate generally provided relevant information, some responses lacked sufficient detail and could have been expanded upon to provide a more comprehensive answer. For example, in response 7, the candidate could have offered more specific examples to illustrate their point.\"], \"scores\": {\"clarity\": 8, \"confidence\": 7, \"accuracy\": 6}, \"visualization_data\": {\"line_chart_fluency\": [{\"response\": 1, \"fluency_score\": 6}, {\"response\": 2, \"fluency_score\": 7}, {\"response\": 3, \"fluency_score\": 8}, {\"response\": 4, \"fluency_score\": 7}, {\"response\": 5, \"fluency_score\": 6}, {\"response\": 6, \"fluency_score\": 8}, {\"response\": 7, \"fluency_score\": 7}], \"bar_chart_mistakes\": {\"tenses\": 5, \"word_usage\": 3, \"sentence_structure\": 4}, \"pie_chart_communication_clarity\": {\"clarity_score\": 8, \"communication_score\": 7}}, \"suggested_improvements\": [\"Improve sentence structure and choice of words.\", \"Pay attention to verb tense consistency.\", \"Provide more detailed and specific explanations.\"], \"benchmark_comparison\": {\"average_fluency\": \"7.2\", \"average_clarity\": \"7.8\", \"average_accuracy\": \"6.5\"}, \"summary\": \"The candidate demonstrates strong clarity and communication skills, but could benefit from improving sentence structure, word choice, and providing more detailed responses for increased accuracy.  Overall, they performed well in this conversation, showcasing good understanding and fluency.\"}']},\n",
       " {'role': 'user',\n",
       "  'content': 'This is the user and model communication => [{\\'role\\': \\'user\\', \\'content\\': \" Hello, Hi, Let\\'s Begin\"}, {\\'role\\': \\'assistant\\', \\'content\\': \\'[{\\\\\\'interviewer_name\\\\\\': \\\\\\'Rajesh Sharma, Engineering Manager\\\\\\', \\\\\\'message\\\\\\': \"Hello, I\\\\\\'m Rajesh Sharma, the Engineering Manager for the backend team. I\\\\\\'ll be leading this interview today.\", \\\\\\'id\\\\\\': 0}, {\\\\\\'interviewer_name\\\\\\': \\\\\\'Emily Patel, Senior Backend Developer\\\\\\', \\\\\\'message\\\\\\': \"Hi, I\\\\\\'m Emily Patel, a Senior Backend Developer on the team. I\\\\\\'ll be assessing your technical skills and project-related experiences.\", \\\\\\'id\\\\\\': 1}, {\\\\\\'interviewer_name\\\\\\': \\\\\\'David Lee, Technical Recruiter\\\\\\', \\\\\\'message\\\\\\': \"Hello, I\\\\\\'m David Lee, the Technical Recruiter who coordinated this process. I\\\\\\'ll be observing your communication skills and taking notes during the session.\", \\\\\\'id\\\\\\': 2}]\\'}]'}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "his.append(userhistory)\n",
    "his"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(his)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[2]\n",
    "b=[3]\n",
    "a.append(b[0])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[{'role': 'user', 'content': ' Hello.'}, {'role': 'assistant', 'content': '[{\\'interviewer_name\\': \\'Rajesh Sharma, Engineering Manager\\', \\'message\\': \"Hello, I\\'m Rajesh Sharma, the Engineering Manager for the backend team. I\\'ll be leading this interview today.\", \\'id\\': 0}, {\\'interviewer_name\\': \\'Emily Patel, Senior Backend Developer\\', \\'message\\': \"Hi, I\\'m Emily Patel, a Senior Backend Developer on the team. I\\'ll be assessing your technical skills and project-related experiences.\", \\'id\\': 1}, {\\'interviewer_name\\': \\'David Lee, Technical Recruiter\\', \\'message\\': \"Hello, I\\'m David Lee, the Technical Recruiter who coordinated this process. I\\'ll be observing your communication skills and taking notes during the session.\", \\'id\\': 2}]'}, {'role': 'user', 'content': ' Ok, fine.'}, {'role': 'assistant', 'content': '[{\\'interviewer_name\\': \\'Rajesh Sharma, Engineering Manager\\', \\'message\\': \"Can you start by telling us a little about yourself and why you\\'re interested in this software developer position?\", \\'id\\': 0}]'}, {'role': 'user', 'content': \" No, I'm sorry.\"}, {'role': 'assistant', 'content': '[{\\'interviewer_name\\': \\'Emily Patel, Senior Backend Developer\\', \\'message\\': \"Don\\'t worry, it\\'s a normal nervous reaction. What I\\'d like to know is, what inspired you to learn programming, and why did you choose Python as your language of choice?\", \\'id\\': 1}]'}]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
